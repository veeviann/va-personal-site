[
  {
    "objectID": "hands-on/week02.html",
    "href": "hands-on/week02.html",
    "title": "Week 02 - Beyond ggplot2 Fundamentals",
    "section": "",
    "text": "The following content is created by following the tutorial on this chapter.\n\npacman::p_load(ggrepel, patchwork, ggthemes, hrbrthemes, tidyverse)\n\nexam_data &lt;- read_csv(\"../data/Exam_data.csv\")",
    "crumbs": [
      "Week 02"
    ]
  },
  {
    "objectID": "hands-on/week02.html#introduction",
    "href": "hands-on/week02.html#introduction",
    "title": "Week 02 - Beyond ggplot2 Fundamentals",
    "section": "",
    "text": "The following content is created by following the tutorial on this chapter.\n\npacman::p_load(ggrepel, patchwork, ggthemes, hrbrthemes, tidyverse)\n\nexam_data &lt;- read_csv(\"../data/Exam_data.csv\")",
    "crumbs": [
      "Week 02"
    ]
  },
  {
    "objectID": "hands-on/week02.html#beyond-ggplot2-annotation-ggrepel",
    "href": "hands-on/week02.html#beyond-ggplot2-annotation-ggrepel",
    "title": "Week 02 - Beyond ggplot2 Fundamentals",
    "section": "2.2 Beyond ggplot2 Annotation: ggrepel",
    "text": "2.2 Beyond ggplot2 Annotation: ggrepel\nThe ggrepel package extends ggplot2 by providing geoms (geom_text_repel() and geom_label_repel()) that prevent overlapping text labels. These labels automatically adjust their positions to avoid overlapping with one another, data points, and the edges of the plotting area. The purpose of this is to improve readability by avoiding overlapping labels compared to geom_label() or geom_text().\nIn the example below, we will replace geom_label() with geom_label_repel().\n\nDefaultWith ggrepelWith ggrepel (overlaps allowed)\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = MATHS, \n           y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm, \n              linewidth = 0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = MATHS, \n           y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm, \n              linewidth = 0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = MATHS, \n           y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm, \n              linewidth = 0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\",\n                   max.overlaps = nrow(exam_data)*0.2) +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\n\n\nThis example highlights a limitation: when too many labels overlap, the plot becomes cluttered and less informative. In the third tab, even annotating just 20% of the points results in an overcrowded graph. If identifying specific points is important, consider annotating only those points or subsetting the dataset to focus on key data. Alternatively, using hover text can be a more effective way to display identities without overwhelming the plot.",
    "crumbs": [
      "Week 02"
    ]
  },
  {
    "objectID": "hands-on/week02.html#beyond-ggplot2-themes",
    "href": "hands-on/week02.html#beyond-ggplot2-themes",
    "title": "Week 02 - Beyond ggplot2 Fundamentals",
    "section": "2.3 Beyond ggplot2 themes",
    "text": "2.3 Beyond ggplot2 themes\nThe examples below showcases the eight built-in themes in ggplot2.\n\ntheme_gray()theme_bw()theme_classic()theme_dark()theme_light()theme_linedraw()theme_minimal()theme_void()\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_histogram(bins = 20, \n                 boundary = 100) +\n  theme_gray() +\n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_histogram(bins = 20, \n                 boundary = 100) +\n  theme_bw() +\n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_histogram(bins = 20, \n                 boundary = 100) +\n  theme_classic() +\n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_histogram(bins = 20, \n                 boundary = 100) +\n  theme_dark() +\n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_histogram(bins = 20, \n                 boundary = 100) +\n  theme_light() +\n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_histogram(bins = 20, \n                 boundary = 100) +\n  theme_linedraw() +\n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_histogram(bins = 20, \n                 boundary = 100) +\n  theme_minimal() +\n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_histogram(bins = 20, \n                 boundary = 100) +\n  theme_void() +\n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe geom itself does not change with respect to the theme. Therefore, attributes like color and fill within the geom must be explicitly defined and are not automatically adjusted by the theme.\n\n\n\n2.3.1 ggtheme package\n\ntheme_economist()theme_wsj()theme_solarized()\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_histogram(bins = 20, \n                 boundary = 100,\n                 color = \"grey25\", \n                 fill = \"grey90\") +\n  theme_economist() +\n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_histogram(bins = 20, \n                 boundary = 100,\n                 color = \"grey25\", \n                 fill = \"grey90\") +\n  theme_wsj() +\n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_histogram(bins = 20, \n                 boundary = 100,\n                 color = \"grey25\", \n                 fill = \"grey90\") +\n  theme_solarized() +\n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.3.2 hrbrthemes package\nThe link from the page did not work so I refered to this page instead.\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_histogram(bins = 20, \n                 boundary = 100,\n                 color = \"grey25\", \n                 fill = \"grey90\") +\n  scale_color_ipsum() +\n  theme_ipsum(axis_title_size = 18,\n              base_size = 15,\n              grid = \"Y\") +\n  ggtitle(\"Distribution of Maths scores\")",
    "crumbs": [
      "Week 02"
    ]
  },
  {
    "objectID": "hands-on/week02.html#composing-graphs-using-patchwork",
    "href": "hands-on/week02.html#composing-graphs-using-patchwork",
    "title": "Week 02 - Beyond ggplot2 Fundamentals",
    "section": "2.4 Composing Graphs using patchwork",
    "text": "2.4 Composing Graphs using patchwork\nSometimes we need more than one graph to create a visually compelling narrative. In this section, we will be exploring different ggplot2 extensions to provide functions to compose figure with multiple graphs. The three graphs are as shown below.\n\nMath HistogramEnglish HistogramMath vs English Scatterplot\n\n\n\n\nShow the code\np1 &lt;- ggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_histogram(bins = 20, \n                 boundary = 100,\n                 color = \"grey25\", \n                 fill = \"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\") \n\np1\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\np2 &lt;- ggplot(data = exam_data, \n       aes(x = ENGLISH)) +\n  geom_histogram(bins = 20, \n                 boundary = 100,\n                 color = \"grey25\", \n                 fill = \"grey90\") +\n  coord_cartesian(xlim = c(0,100)) +\n  ggtitle(\"Distribution of English scores\") \n\np2\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\np3 &lt;- ggplot(data = exam_data, \n             aes(x = MATHS, y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm,\n              size = 0.5) + \n  coord_cartesian(xlim = c(0, 100),\n                  ylim = c(0, 100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\np3\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.1 patchwork operators\n\nTwo-Column Layout using the Plus Sign +.\nParenthesis () to create a subplot group.\nTwo-Row Layout using the Division Sign /\n‚Äú|‚Äù operator to place the plots beside each other\n\n\nTwo-plotsThree-plots\n\n\n\n\nShow the code\np1 + p2\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n(p1 / p2) | p3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.4.2 patchwork operators & extra functionalities\n\nWith tagsLayeringThemed\n\n\nAuto-tagging capabilities can be done by using plot_annotation() (eg. numbering the figures automatically).\n\n\nShow the code\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_economist() +\n  theme(plot.title = element_text(size = 12, face = \"bold\")) # Needs this or the font is too large for the plot",
    "crumbs": [
      "Week 02"
    ]
  },
  {
    "objectID": "hands-on/week02.html#extras",
    "href": "hands-on/week02.html#extras",
    "title": "Week 02 - Beyond ggplot2 Fundamentals",
    "section": "2.5 EXTRAS",
    "text": "2.5 EXTRAS\nTODO",
    "crumbs": [
      "Week 02"
    ]
  },
  {
    "objectID": "hands-on/week01.html",
    "href": "hands-on/week01.html",
    "title": "Week 01 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "",
    "text": "The following content is created by following the tutorial on this chapter.\n\npacman::p_load(tidyverse)\n\nexam_data &lt;- read_csv(\"../data/Exam_data.csv\")\n\n\n\n\nR Graphicsggplot2\n\n\n\nhist(exam_data$MATHS, xlab=\"Math Score\", main=\"Distribution of Math Scores\")\n\n\n\n\n\n\n\n\n\n\n\n# ggplot(data=df) will just display an empty canvas.\n# setting aes(x=MATHS) just sets the x-axis to the range of values in the MATHS column\n# using geom_histogram \nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10,\n                 boundary=100,\n                 color=\"black\",\n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Math Scores\")",
    "crumbs": [
      "Week 01"
    ]
  },
  {
    "objectID": "hands-on/week01.html#introduction",
    "href": "hands-on/week01.html#introduction",
    "title": "Week 01 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "",
    "text": "The following content is created by following the tutorial on this chapter.\n\npacman::p_load(tidyverse)\n\nexam_data &lt;- read_csv(\"../data/Exam_data.csv\")\n\n\n\n\nR Graphicsggplot2\n\n\n\nhist(exam_data$MATHS, xlab=\"Math Score\", main=\"Distribution of Math Scores\")\n\n\n\n\n\n\n\n\n\n\n\n# ggplot(data=df) will just display an empty canvas.\n# setting aes(x=MATHS) just sets the x-axis to the range of values in the MATHS column\n# using geom_histogram \nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10,\n                 boundary=100,\n                 color=\"black\",\n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Math Scores\")",
    "crumbs": [
      "Week 01"
    ]
  },
  {
    "objectID": "hands-on/week01.html#geometric-objects-in-ggplot2-geom",
    "href": "hands-on/week01.html#geometric-objects-in-ggplot2-geom",
    "title": "Week 01 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.2 Geometric Objects in ggplot2: geom",
    "text": "1.2 Geometric Objects in ggplot2: geom\n\n1.2.1 Bar chart with geom_bar()\n\nggplot(data=exam_data,\n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n1.2.2 Dot plot with geom_dotplot()\nNot be confused with scatterplots, a dot plot is essentially a histogram but in the style of stacked dots.\n\nggplot(data=exam_data, \n       aes(x=MATHS)) +\n  geom_dotplot(dotsize=0.5)\n\n\n\n\n\n\n\n\nBecause the y-axis scale is misleading, we will have to turn off y-axis with the scale_y_continuous()\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_dotplot(binwidth=2.5,\n               dotsize=0.5) +\n  scale_y_continuous(NULL, breaks=NULL)\n\n\n\n\n\n\n\n\nQuestion: When is a dot plot preferred over something like a histogram? Is counting the dots even feasible?\n\n\n1.2.3 Histograms with geom_histogram()\n\n# default number of bins is 30\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\nIn the geom(), we can use the arguments to modify the geometric object.\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_histogram(bins=20,\n                 color=\"black\",\n                 fill=\"light blue\")\n\n\n\n\n\n\n\n\nSimilar to hue in seaborn, we can colour the histogram by sub-groups using the fill argument in aesthetic(). We can also play around with the other arguments like alpha and color.\n\nfillalphacolor\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS,\n           fill=GENDER)) +\n  geom_histogram(bins=20,\n                 color=\"grey30\")\n\n\n\n\n\n\n\n\n\n\n\n# Can't use it on continuous variables either even though there's the warning.\n# It's very difficult to see.\nggplot(data=exam_data,\n       aes(x=MATHS,\n           alpha=CLASS)) +\n  geom_histogram(bins=20,\n                 color=\"grey30\")\n\n\n\n\n\n\n\n\n\n\nThe color argument in the geom_histogram() needs to be removed as it will override the previous aes()\n\nggplot(data=exam_data,\n       aes(x=MATHS,\n           color=GENDER)) +\n  geom_histogram(bins=20,\n                 alpha=0.3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.2.4 Kernel Density Estimate with geom_density()\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_density()\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS,\n           color=GENDER)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\n1.2.5 Boxplot with geom_boxplot()\n\nggplot(data=exam_data,\n       aes(y=MATHS,\n           x=GENDER)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n# notches are used to see if medians of the distributions differ\nggplot(data=exam_data,\n       aes(y=MATHS,\n           x=GENDER)) +\n  geom_boxplot(notches=TRUE) # TRUE must be all caps\n\n\n\n\n\n\n\n\n\n\n1.2.6 Violin plot with geom_violin()\nThis is for comparing multiple data distributions side by side. With density curves, as the lines may overlap with one another, it is more challenging to compare the different distributions.\n\nggplot(data=exam_data, \n       aes(y=MATHS, \n           x= GENDER)) +\n  geom_violin()\n\n\n\n\n\n\n\n\n\n\n1.2.7 Scatterplot with geom_point()\n\nggplot(data=exam_data,\n       aes(x=MATHS,\n           y=ENGLISH)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n1.2.8 Combining geom objects\n\nggplot(data=exam_data,\n       aes(y=MATHS,\n           x=GENDER)) +\n  geom_boxplot() +\n  geom_point(position=\"jitter\",\n             size=0.5)",
    "crumbs": [
      "Week 01"
    ]
  },
  {
    "objectID": "hands-on/week01.html#statistics-functions-in-ggplot2-stat",
    "href": "hands-on/week01.html#statistics-functions-in-ggplot2-stat",
    "title": "Week 01 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.3 Statistics functions in ggplot2: stat",
    "text": "1.3 Statistics functions in ggplot2: stat\n\n1.3.1 Using the stat_summary() method\nThe box plot above doesn‚Äôt indicate the position of the means. By working with the stat_summary() function, we can indicate the mean values on the plot.\n\nggplot(data=exam_data,\n       aes(y=MATHS,\n           x=GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom=\"point\",\n                fun=\"mean\",\n                colour=\"red\",\n                size=4)\n\n\n\n\n\n\n\n\n\n\n1.3.2 Using geom() to update stat\nOverriding the default stat, we can add the mean values as well.\n\nggplot(data=exam_data,\n       aes(y=MATHS,\n           x=GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",\n             fun=\"mean\",\n             colour=\"red\",\n             size=4)\n\n\n\n\n\n\n\n\n\n\n1.3.3 Using geom_smooth() to add best fit curve\n\nloesslm\n\n\n\nggplot(data=exam_data, \n       aes(x=MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(linewidth=0.5)\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm,\n              linewidth=0.5)",
    "crumbs": [
      "Week 01"
    ]
  },
  {
    "objectID": "hands-on/week01.html#facets",
    "href": "hands-on/week01.html#facets",
    "title": "Week 01 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.4 Facets",
    "text": "1.4 Facets\nAlso known as trellis plot. In mpl it‚Äôs subplots.\n\n1.4.1 Wrapping 1d sequence of panels into 2d with facet_wrap()\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\n\n\n\n\n1.4.2 Creating matrix of panels with facet_grid()\n\n# This should be similar to subplots\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)",
    "crumbs": [
      "Week 01"
    ]
  },
  {
    "objectID": "hands-on/week01.html#coordinates",
    "href": "hands-on/week01.html#coordinates",
    "title": "Week 01 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.5 Coordinates",
    "text": "1.5 Coordinates\n\n1.5.1 Flipping the coordinates with coord_flip()\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n1.5.2 Changing the y- and x-axis range with coord_cartesian()\n\nggplot(data=exam_data, \n       aes(x=MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))",
    "crumbs": [
      "Week 01"
    ]
  },
  {
    "objectID": "hands-on/week01.html#themes",
    "href": "hands-on/week01.html#themes",
    "title": "Week 01 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.6 Themes",
    "text": "1.6 Themes\n\nList of built-in themes\n\n\n1.6.1 Examples of different themes\n\ntheme_gray()theme_classic()theme_minimal()\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()",
    "crumbs": [
      "Week 01"
    ]
  },
  {
    "objectID": "hands-on/week01.html#additional-plots",
    "href": "hands-on/week01.html#additional-plots",
    "title": "Week 01 - A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.7 Additional Plots",
    "text": "1.7 Additional Plots\nThis space is for more exploration regarding this week‚Äôs extra topics. It may be done later when I have time to revise.\n\n1.7.1 Age-sex Pyramid\nData Retrieved From Singstat\n\n\nShow the code\n# Referenced from https://www.geeksforgeeks.org/how-to-create-a-population-pyramid-in-r/\npop_data &lt;- read_csv(\"../data/sg_residents_jun2024.csv\")\n\n# This is to ensure that the age levels are sorted correctly\nage_levels &lt;- pop_data %&gt;%\n  distinct(age) %&gt;%\n  pull(age) %&gt;%\n  str_replace(\" Years\", \"\")\n  \npop_data &lt;- pop_data %&gt;%\n  mutate(age = factor(str_replace(age, \" Years\", \"\"), levels = age_levels))\n\n# Plotting the age-sex pyramid\npop_data %&gt;%mutate( \n    population = ifelse(gender==\"M\", population*(-1e-3), \n                        population*1e-3))%&gt;% \n    ggplot(aes(x = age, \n               y = population, \n               fill = gender)) +  \n    geom_bar(stat = \"identity\") + \n    coord_flip() + \n    scale_y_continuous(limits = c(-200,200),  \n                       breaks = seq(-200, 200, by = 50))+\n   labs(title = \"Singapore Residents\", x = \"Age Range\",  \n        y = \"Population (in thousands)\") +\n  theme_light() +\n  theme(axis.ticks.y=element_blank())\n\n\n\n\n\n\n\n\n\n\n\n1.7.2 Pareto Chart\nData Retrieved From Singstat\n\n\nShow the code\npacman::p_load(scales)\n\nexp_data &lt;- read_csv(\"../data/avg_monthly_expenditure2023.csv\")\n\npareto_data &lt;- exp_data %&gt;%\n  mutate (\n    category_wrapped = str_wrap(category, width = 8)\n  ) %&gt;% \n  arrange(desc(avg_spend)) %&gt;%  # Sort by avg_spend in descending order\n  mutate(\n    category_wrapped = factor(category_wrapped, levels = category_wrapped),  # Fix category order\n    cum_percent = cumsum(avg_spend) / sum(avg_spend) * 100)  # Calculate cumulative percentage\n\n\n# Create the Pareto chart\nggplot(pareto_data, aes(x = category_wrapped)) +\n  geom_bar(aes(y = avg_spend), stat = \"identity\", fill = \"steelblue\") +\n  geom_line(aes(y = cum_percent * max(avg_spend) / 100, \n                group = 1), color = \"red\", \n            size = 1) +\n  geom_point(aes(y = cum_percent * max(avg_spend) / 100), \n             color = \"red\", size = 2) +\n  scale_y_continuous(\n    name = \"Average Monthly HouseHold Expenditure (SGD)\", \n    sec.axis = sec_axis(~ . * 100 / max(pareto_data$avg_spend),\n                        breaks = seq(0, 100, by = 20),\n                        labels = percent_format(scale = 1))) +\n  labs(\n    title = \"Average Monthly Household Expenditure by Goods and Services Type (2023)\",\n    x = \"Type of Goods and Services\",\n    y = \"Average Monthly HouseHold Expenditure (SGD)\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(size = 6)) \n\n\n\n\n\n\n\n\n\nThis Pareto chart shows the average monthly household expenditure in Singapore for 2023, offering insights into spending priorities. Key areas like ‚ÄúHousing and Utilities,‚Äù ‚ÄúFood and Food Serving Services,‚Äù and ‚ÄúTransport‚Äù form the bulk of household expenses. However, it‚Äôs worth noting that the data is self-reported, as outlined in the Household Expenditure Survey 2022/23 (SingStat). Additionally, this analysis isn‚Äôt normalized by household size or segmented by income levels, which could mask inequalities across different demographics.\nFor a deeper dive, the full report and related publications are available on SingStat‚Äôs website (here). This serves as a starting point for exploring how households allocate resources, but there‚Äôs room to uncover more patterns with richer, disaggregated data.",
    "crumbs": [
      "Week 01"
    ]
  },
  {
    "objectID": "hands-on/week05.html",
    "href": "hands-on/week05.html",
    "title": "Week 05 - Visual Multivariate Analysis",
    "section": "",
    "text": "The following section was modified according to https://r4va.netlify.app/chap14.\n\n\n\n\nLoading packages & data import\npacman::p_load(seriation, dendextend, heatmaply, tidyverse, \n               pheatmap, gplots, RColorBrewer)\n\nwh &lt;- read_csv(\"../data/WHData-2018.csv\")\n\n\n\n\nShow the code\nrow.names(wh) &lt;- wh$Country\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nrow.names(wh1) &lt;- wh$Country\nwh_matrix &lt;- data.matrix(wh1)\nhead(wh_matrix)\n\n\n                       Happiness score GDP per capita Social support\nAlbania                          4.586          0.916          0.817\nBosnia and Herzegovina           5.129          0.915          1.078\nBulgaria                         4.933          1.054          1.515\nCroatia                          5.321          1.115          1.161\nCzech Republic                   6.711          1.233          1.489\nEstonia                          5.739          1.200          1.532\n                       Healthy life expectancy Freedom to make life choices\nAlbania                                  0.790                        0.419\nBosnia and Herzegovina                   0.758                        0.280\nBulgaria                                 0.712                        0.359\nCroatia                                  0.737                        0.380\nCzech Republic                           0.854                        0.543\nEstonia                                  0.737                        0.553\n                       Generosity Perceptions of corruption\nAlbania                     0.149                     0.032\nBosnia and Herzegovina      0.216                     0.000\nBulgaria                    0.064                     0.009\nCroatia                     0.120                     0.039\nCzech Republic              0.064                     0.034\nEstonia                     0.086                     0.174\n\n\n\n\n\nThe examples below show different ways of creating a static heatmap. The key things to note:\n\nScaling the data column-wise to ensure that the colour scales are the same.\nDendrogram - whether to show, and if we want to differentiate the groups based on different levels of the cluster.\nLegend (colour map key)\n\n\nheatmap()heatmap.2()pheatmap()ggheatmap()\n\n\n\n\nShow the code\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\nheatmap(wh_matrix,\n        Rowv = NULL,  # NA to suppress the dendrogram\n        Colv = NULL,\n        symm = FALSE,  # Matrix is not symmetric\n        scale = \"column\",  # Standardize by columns\n        cexCol = 0.8,  # Reduce column label font size\n        col = coul\n        )\n\n\n\n\n\n\n\n\n\n\n\nIt‚Äôs so difficult to modify the position & the size of the key üò≠\n\n\nShow the code\n# Ref: https://stackoverflow.com/questions/55585166/difficulty-positioning-heatmap-2-components\n\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\nheatmap.2(wh_matrix,\n        Rowv = TRUE,  # NA to suppress the dendrogram\n        Colv = TRUE,\n        symm = FALSE,  # Matrix is not symmetric\n        density.info=\"none\",  # turns off density plot inside color legend\n        scale = \"column\",  # Standardize by columns\n        key = TRUE,  # Include color key\n        trace = \"none\",  # The trace lines are the blue lines\n        cexCol = 0.8,  # Reduce column label font size\n        col = coul,\n        keysize=1, \n        lmat = rbind( c(0, 3, 0), c(2, 1, 0), c(0, 4, 0)), # Col-dendro, row-dendro, key\n        lhei = c(0.43, 2.6, 0.6), # Height \n        lwid = c(0.6, 4, 0.6), # Alter dimensions of display array cell widths\n        )\n\n\n\n\n\n\n\n\n\n\n\nThe order here is different because it is grouped by the cluster.\n\n\nShow the code\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\npheatmap(wh_matrix,\n         scale = \"column\",\n         color = coul,\n         cutree_rows = 4,\n         fontsize = 6)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\nggheatmap(wh_matrix,\n         scale = \"column\",\n         color = coul)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncolumn scalingnormalizing (min max)percentize\n\n\n\n\nShow the code\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\nheatmaply(wh_matrix,\n          colors = coul,\n          scale=\"column\",\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n\n\n\nShow the code\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\nheatmaply(normalize(wh_matrix),\n          colors = coul,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n\n\n\nShow the code\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\nheatmaply(percentize(wh_matrix),\n          colors = coul,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn dend_expend(), the optim value measures how well the dendrogram preserves the original distance matrix, usually using cophenetic correlation (default). Higher values (closer to 1) indicate better alignment.\nTo find the best dendrogram, choose the combination of distance and clustering methods with the highest optim value. Use find_dend() to automatically select and plot the best one.\n\n\n\nShow the code\nwh_d &lt;- dist(normalize(wh_matrix), \n             method=\"euclidean\")\nden_perf &lt;- dend_expend(wh_d)$performance\nden_perf &lt;- data.frame(den_perf)\nsorted_df_desc &lt;- den_perf %&gt;%\n  arrange(desc(optim))\nprint(sorted_df_desc)\n\n\n  dist_methods hclust_methods     optim\n1      unknown        average 0.7181243\n2      unknown       centroid 0.6871334\n3      unknown         ward.D 0.6641312\n4      unknown       mcquitty 0.6575001\n5      unknown        ward.D2 0.6455811\n6      unknown         median 0.6210611\n7      unknown       complete 0.5668585\n8      unknown         single 0.4676511\n\n\nBased on the table, the ‚Äúaverage‚Äù method has the highest optimum value. We will use find_k() to determine the optimal number of clusters.\n\n\nShow the code\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\n\n\n\n\nThe final plot will look like this.\n\n\nShow the code\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\nheatmaply(normalize(wh_matrix),\n          colors = coul,\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n\n\n\n\nNoneOptimal leaf orderingGruvaeus and WainerMean\n\n\n\n\nShow the code\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\nheatmaply(normalize(wh_matrix),\n          colors = coul,\n          dist_method = \"euclidean\",\n          seriate = \"none\")\n\n\n\n\n\n\n\n\n\n\nShow the code\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\nheatmaply(normalize(wh_matrix),\n          colors = coul,\n          dist_method = \"euclidean\",\n          seriate = \"OLO\")\n\n\n\n\n\n\n\n\n\n\nShow the code\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\nheatmaply(normalize(wh_matrix),\n          colors = coul,\n          dist_method = \"euclidean\",\n          seriate = \"GW\")\n\n\n\n\n\n\n\n\n\n\nShow the code\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\nheatmaply(normalize(wh_matrix),\n          colors = coul,\n          dist_method = \"euclidean\",\n          seriate = \"mean\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\nheatmaply(normalize(wh_matrix),\n          Colv=NA,\n          seriate = \"none\",\n          colors = coul,\n          k_row = 3,\n          margins = c(NA,200,60,NA),\n          fontsize = 7,\n          fontsize_row = 5,\n          fontsize_col = 6,\n          main=\"Normalized World Happiness Score and Variables by Country, 2018\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )\n\n\n\n\n\n\n\n\n\n\n\nhttps://www.datanovia.com/en/lessons/heatmap-in-r-static-and-interactive-visualization/#google_vignette\nhttps://cran.r-project.org/web/packages/heatmaply/vignettes/heatmaply.html",
    "crumbs": [
      "Week 05"
    ]
  },
  {
    "objectID": "hands-on/week05.html#data-preparation",
    "href": "hands-on/week05.html#data-preparation",
    "title": "Week 05 - Visual Multivariate Analysis",
    "section": "",
    "text": "Loading packages & data import\npacman::p_load(seriation, dendextend, heatmaply, tidyverse, \n               pheatmap, gplots, RColorBrewer)\n\nwh &lt;- read_csv(\"../data/WHData-2018.csv\")\n\n\n\n\nShow the code\nrow.names(wh) &lt;- wh$Country\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nrow.names(wh1) &lt;- wh$Country\nwh_matrix &lt;- data.matrix(wh1)\nhead(wh_matrix)\n\n\n                       Happiness score GDP per capita Social support\nAlbania                          4.586          0.916          0.817\nBosnia and Herzegovina           5.129          0.915          1.078\nBulgaria                         4.933          1.054          1.515\nCroatia                          5.321          1.115          1.161\nCzech Republic                   6.711          1.233          1.489\nEstonia                          5.739          1.200          1.532\n                       Healthy life expectancy Freedom to make life choices\nAlbania                                  0.790                        0.419\nBosnia and Herzegovina                   0.758                        0.280\nBulgaria                                 0.712                        0.359\nCroatia                                  0.737                        0.380\nCzech Republic                           0.854                        0.543\nEstonia                                  0.737                        0.553\n                       Generosity Perceptions of corruption\nAlbania                     0.149                     0.032\nBosnia and Herzegovina      0.216                     0.000\nBulgaria                    0.064                     0.009\nCroatia                     0.120                     0.039\nCzech Republic              0.064                     0.034\nEstonia                     0.086                     0.174",
    "crumbs": [
      "Week 05"
    ]
  },
  {
    "objectID": "hands-on/week05.html#static-heatmaps",
    "href": "hands-on/week05.html#static-heatmaps",
    "title": "Week 05 - Visual Multivariate Analysis",
    "section": "",
    "text": "The examples below show different ways of creating a static heatmap. The key things to note:\n\nScaling the data column-wise to ensure that the colour scales are the same.\nDendrogram - whether to show, and if we want to differentiate the groups based on different levels of the cluster.\nLegend (colour map key)\n\n\nheatmap()heatmap.2()pheatmap()ggheatmap()\n\n\n\n\nShow the code\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\nheatmap(wh_matrix,\n        Rowv = NULL,  # NA to suppress the dendrogram\n        Colv = NULL,\n        symm = FALSE,  # Matrix is not symmetric\n        scale = \"column\",  # Standardize by columns\n        cexCol = 0.8,  # Reduce column label font size\n        col = coul\n        )\n\n\n\n\n\n\n\n\n\n\n\nIt‚Äôs so difficult to modify the position & the size of the key üò≠\n\n\nShow the code\n# Ref: https://stackoverflow.com/questions/55585166/difficulty-positioning-heatmap-2-components\n\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\nheatmap.2(wh_matrix,\n        Rowv = TRUE,  # NA to suppress the dendrogram\n        Colv = TRUE,\n        symm = FALSE,  # Matrix is not symmetric\n        density.info=\"none\",  # turns off density plot inside color legend\n        scale = \"column\",  # Standardize by columns\n        key = TRUE,  # Include color key\n        trace = \"none\",  # The trace lines are the blue lines\n        cexCol = 0.8,  # Reduce column label font size\n        col = coul,\n        keysize=1, \n        lmat = rbind( c(0, 3, 0), c(2, 1, 0), c(0, 4, 0)), # Col-dendro, row-dendro, key\n        lhei = c(0.43, 2.6, 0.6), # Height \n        lwid = c(0.6, 4, 0.6), # Alter dimensions of display array cell widths\n        )\n\n\n\n\n\n\n\n\n\n\n\nThe order here is different because it is grouped by the cluster.\n\n\nShow the code\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\npheatmap(wh_matrix,\n         scale = \"column\",\n         color = coul,\n         cutree_rows = 4,\n         fontsize = 6)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\nggheatmap(wh_matrix,\n         scale = \"column\",\n         color = coul)",
    "crumbs": [
      "Week 05"
    ]
  },
  {
    "objectID": "hands-on/week05.html#interactive-heatmap",
    "href": "hands-on/week05.html#interactive-heatmap",
    "title": "Week 05 - Visual Multivariate Analysis",
    "section": "",
    "text": "column scalingnormalizing (min max)percentize\n\n\n\n\nShow the code\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\nheatmaply(wh_matrix,\n          colors = coul,\n          scale=\"column\",\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n\n\n\nShow the code\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\nheatmaply(normalize(wh_matrix),\n          colors = coul,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n\n\n\nShow the code\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\nheatmaply(percentize(wh_matrix),\n          colors = coul,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn dend_expend(), the optim value measures how well the dendrogram preserves the original distance matrix, usually using cophenetic correlation (default). Higher values (closer to 1) indicate better alignment.\nTo find the best dendrogram, choose the combination of distance and clustering methods with the highest optim value. Use find_dend() to automatically select and plot the best one.\n\n\n\nShow the code\nwh_d &lt;- dist(normalize(wh_matrix), \n             method=\"euclidean\")\nden_perf &lt;- dend_expend(wh_d)$performance\nden_perf &lt;- data.frame(den_perf)\nsorted_df_desc &lt;- den_perf %&gt;%\n  arrange(desc(optim))\nprint(sorted_df_desc)\n\n\n  dist_methods hclust_methods     optim\n1      unknown        average 0.7181243\n2      unknown       centroid 0.6871334\n3      unknown         ward.D 0.6641312\n4      unknown       mcquitty 0.6575001\n5      unknown        ward.D2 0.6455811\n6      unknown         median 0.6210611\n7      unknown       complete 0.5668585\n8      unknown         single 0.4676511\n\n\nBased on the table, the ‚Äúaverage‚Äù method has the highest optimum value. We will use find_k() to determine the optimal number of clusters.\n\n\nShow the code\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\n\n\n\n\nThe final plot will look like this.\n\n\nShow the code\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\nheatmaply(normalize(wh_matrix),\n          colors = coul,\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n\n\n\n\nNoneOptimal leaf orderingGruvaeus and WainerMean\n\n\n\n\nShow the code\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\nheatmaply(normalize(wh_matrix),\n          colors = coul,\n          dist_method = \"euclidean\",\n          seriate = \"none\")\n\n\n\n\n\n\n\n\n\n\nShow the code\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\nheatmaply(normalize(wh_matrix),\n          colors = coul,\n          dist_method = \"euclidean\",\n          seriate = \"OLO\")\n\n\n\n\n\n\n\n\n\n\nShow the code\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\nheatmaply(normalize(wh_matrix),\n          colors = coul,\n          dist_method = \"euclidean\",\n          seriate = \"GW\")\n\n\n\n\n\n\n\n\n\n\nShow the code\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\nheatmaply(normalize(wh_matrix),\n          colors = coul,\n          dist_method = \"euclidean\",\n          seriate = \"mean\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\ncoul &lt;- colorRampPalette(brewer.pal(8, \"PiYG\"))(40)\nheatmaply(normalize(wh_matrix),\n          Colv=NA,\n          seriate = \"none\",\n          colors = coul,\n          k_row = 3,\n          margins = c(NA,200,60,NA),\n          fontsize = 7,\n          fontsize_row = 5,\n          fontsize_col = 6,\n          main=\"Normalized World Happiness Score and Variables by Country, 2018\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )",
    "crumbs": [
      "Week 05"
    ]
  },
  {
    "objectID": "hands-on/week05.html#additional-references",
    "href": "hands-on/week05.html#additional-references",
    "title": "Week 05 - Visual Multivariate Analysis",
    "section": "",
    "text": "https://www.datanovia.com/en/lessons/heatmap-in-r-static-and-interactive-visualization/#google_vignette\nhttps://cran.r-project.org/web/packages/heatmaply/vignettes/heatmaply.html",
    "crumbs": [
      "Week 05"
    ]
  },
  {
    "objectID": "hands-on/week05.html#data-preparation-1",
    "href": "hands-on/week05.html#data-preparation-1",
    "title": "Week 05 - Visual Multivariate Analysis",
    "section": "2.1 Data Preparation",
    "text": "2.1 Data Preparation\n\n\nLoading packages & data import\npacman::p_load(corrplot, ggstatsplot, tidyverse)\n\nwine &lt;- read_csv(\"../data/wine_quality.csv\")",
    "crumbs": [
      "Week 05"
    ]
  },
  {
    "objectID": "hands-on/week05.html#correlation-matrix",
    "href": "hands-on/week05.html#correlation-matrix",
    "title": "Week 05 - Visual Multivariate Analysis",
    "section": "2.2 Correlation Matrix",
    "text": "2.2 Correlation Matrix\n\n2.2.1 Single Correlation Matrix\n\npairs()ggcormat()\n\n\n\n\nShow the code\ncmap &lt;- colorRampPalette(c(\"red\", \"white\", \"blue\"))(100)\npanel.cor &lt;- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\n  usr &lt;- par(\"usr\")\n  on.exit(par(usr))\n  par(usr = c(0, 1, 0, 1))\n  \n  r &lt;- cor(x, y, use=\"complete.obs\")  # Compute correlation\n  txt &lt;- format(c(abs(r), 0.123456789), digits=digits)[1]\n  txt &lt;- paste(prefix, txt, sep=\"\")\n  if (missing(cex.cor)) cex.cor &lt;- 0.8 / strwidth(txt)\n  \n  # Convert correlation (-1 to 1) into an index for the colormap\n  col_index &lt;- round((r + 1) * 49 + 1)  # Scale to 1-100\n  col &lt;- cmap[col_index]\n  \n  # Fill background color\n  rect(0, 0, 1, 1, col = col, border = NA)\n  \n  # Add text with high contrast (black/white depending on background)\n  text_col &lt;- ifelse(abs(r) &gt; 0.5, \"white\", \"black\")  \n  text(0.5, 0.5, txt, cex = cex.cor * (1 + abs(r)) / 2, col = text_col, font = 2)\n}\npairs(wine[,1:11], upper.panel = panel.cor)\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10,\n                         lab_size = 3),\n  colors = c(\"red\", \"white\", \"blue\"),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are not significant at p &lt; 0.05\",\n  ggplot.component = list(\n    theme(text=element_text(size=8),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8)))\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.2.2 Multiple correlation matrix\nFaceting can be done by using grouped_ggcorrmat()\n\n\nShow the code\ngrouped_ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  grouping.var = type,  # what is it faceted by\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  legend.title = element_text(size = 3),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         pch.cex = 2,\n                         tl.cex = 2,\n                         lab_size = 2),\n  colors = c(\"red\", \"white\", \"blue\"),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)",
    "crumbs": [
      "Week 05"
    ]
  },
  {
    "objectID": "hands-on/week05.html#additional-references-1",
    "href": "hands-on/week05.html#additional-references-1",
    "title": "Week 05 - Visual Multivariate Analysis",
    "section": "2.3 Additional References",
    "text": "2.3 Additional References\n\nhttps://www.rdocumentation.org/packages/ggstatsplot/versions/0.13.0/topics/ggcorrmat",
    "crumbs": [
      "Week 05"
    ]
  },
  {
    "objectID": "hands-on/week05.html#data-preparation-2",
    "href": "hands-on/week05.html#data-preparation-2",
    "title": "Week 05 - Visual Multivariate Analysis",
    "section": "3.1 Data Preparation",
    "text": "3.1 Data Preparation\n\n\nLoading packages & data import\npacman::p_load(GGally, parallelPlot, tidyverse, hrbrthemes)\n\nwh &lt;- read_csv(\"../data/WHData-2018.csv\")",
    "crumbs": [
      "Week 05"
    ]
  },
  {
    "objectID": "hands-on/week05.html#static-parallel-coordinates-plot",
    "href": "hands-on/week05.html#static-parallel-coordinates-plot",
    "title": "Week 05 - Visual Multivariate Analysis",
    "section": "3.2 Static Parallel Coordinates Plot",
    "text": "3.2 Static Parallel Coordinates Plot\n\n3.2.1 Getting Started\nThis is a basic parallel coordinates plot, using ggparcoord()\n\n\nShow the code\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\n\n\n\n\n\nThe standard plot doesn‚Äôt reveal any meaning (looks like a bunch of lines). Instead of adding a boxplot like in the tutorial, lets look at adding colours and changing the theme of the plot first.\n\n\nShow the code\nggparcoord(wh,\n    columns = c(7:12), \n    groupColumn = 2,\n    showPoints = TRUE, \n    title = \"Parallel Coordinates Plot of World Happines Variables\",\n    alphaLines = 0.3\n    ) + \n  theme_ipsum()+\n  theme(\n    plot.title = element_text(size=10)\n  )\n\n\n\n\n\n\n\n\n\n\n\n3.2.2 Scaling the data\nSimilar to the heatmap in Section 1, we might want to scale the data to have a better visualization. Unfortunately, the lines are still overlapping a lot. Perhaps faceting might be a better option.\n\nNo scalingNormalize (Min Max)StandardizeStandardize + Center\n\n\n\n\nShow the code\nggparcoord(wh,\n    columns = c(7:12), \n    groupColumn = 2,\n    scale = \"globalminmax\",\n    showPoints = TRUE, \n    title = \"No scaling\",\n    alphaLines = 0.3\n    ) + \n  theme_ipsum()+\n  theme(\n    plot.title = element_text(size=10)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggparcoord(wh,\n    columns = c(7:12), \n    groupColumn = 2,\n    scale = \"uniminmax\",\n    showPoints = TRUE, \n    title = \"Standardize to Min = 0, Max = 1\",\n    alphaLines = 0.3\n    ) + \n  theme_ipsum()+\n  theme(\n    plot.title = element_text(size=10)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggparcoord(wh,\n    columns = c(7:12), \n    groupColumn = 2,\n    scale = \"std\",\n    showPoints = TRUE, \n    title = \"Normalize univariately (substract mean & divide by sd)\",\n    alphaLines = 0.3\n    ) + \n  theme_ipsum()+\n  theme(\n    plot.title = element_text(size=10)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggparcoord(wh,\n    columns = c(7:12), \n    groupColumn = 2,\n    scale = \"center\",\n    showPoints = TRUE, \n    title = \"Standardize + Center\",\n    alphaLines = 0.3\n    ) + \n  theme_ipsum()+\n  theme(\n    plot.title = element_text(size=10)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.2.3 Let‚Äôs add a boxplot\n\n\nShow the code\nggparcoord(wh,\n    columns = c(7:12), \n    groupColumn = 2,\n    scale = \"uniminmax\",\n    boxplot = TRUE,\n    title = \"Parallel Coordinates Plot of World Happines Variables\",\n    alphaLines = 0.3\n    ) + \n  theme_ipsum()+\n  theme(\n    plot.title = element_text(size=10)\n  )\n\n\n\n\n\n\n\n\n\n\n\n3.2.4 Parallel Coordinates with Facet\n\n\nShow the code\nggparcoord(wh,\n    columns = c(7:12), \n    groupColumn = 2,\n    scale = \"uniminmax\",\n    boxplot = TRUE,\n    title = \"Multiple Parallel Coordinates Plot of World Happines Variables\",\n    alphaLines = 0.3\n    ) + \n  theme_ipsum()+\n  theme(\n    plot.title = element_text(size=10),\n    axis.text.x = element_text(angle = 90)\n  ) +\n facet_wrap(~ Region)",
    "crumbs": [
      "Week 05"
    ]
  },
  {
    "objectID": "hands-on/week05.html#interative-parallel-coordinates-plot",
    "href": "hands-on/week05.html#interative-parallel-coordinates-plot",
    "title": "Week 05 - Visual Multivariate Analysis",
    "section": "3.3 Interative Parallel Coordinates Plot",
    "text": "3.3 Interative Parallel Coordinates Plot\n\n3.3.1 Basic plot\nThe following plot is coloured based on the happiness score.\n\n\nShow the code\nwh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250,\n             rotateTitle = TRUE,\n            refColumnDim = \"Happiness score\", \n            continuousCS = \"YlOrRd\")\n\n\n\n\n\n\n\n\n3.3.2 With histogram\n\n\nShow the code\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             width = 320,\n             height = 250,\n             rotateTitle = TRUE,\n            refColumnDim = \"Happiness score\", \n            continuousCS = \"YlOrRd\",\n            histoVisibility = histoVisibility)",
    "crumbs": [
      "Week 05"
    ]
  },
  {
    "objectID": "hands-on/week05.html#additional-references-2",
    "href": "hands-on/week05.html#additional-references-2",
    "title": "Week 05 - Visual Multivariate Analysis",
    "section": "3.4 Additional References",
    "text": "3.4 Additional References\n\nhttps://r-graph-gallery.com/parallel-plot-ggally.html\nhttps://cran.r-project.org/web/packages/parallelPlot/vignettes/introduction-to-parallelplot.html",
    "crumbs": [
      "Week 05"
    ]
  },
  {
    "objectID": "hands-on/week05.html#data-preparation-3",
    "href": "hands-on/week05.html#data-preparation-3",
    "title": "Week 05 - Visual Multivariate Analysis",
    "section": "4.1 Data Preparation",
    "text": "4.1 Data Preparation\n\n\nLoading packages & data import\npacman::p_load(plotly, ggtern, tidyverse)\n\npop_data &lt;- read_csv(\"../data/respopagsex2000to2018_tidy.csv\") \n\n\n\n\nShow the code\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year)) %&gt;%  # Convert Year to character type\n  spread(AG, Population) %&gt;%  # Reshape data: AG categories become separate columns\n  mutate(YOUNG = rowSums(.[4:8])) %&gt;%  # Sum columns 4 to 8 for the \"YOUNG\" age group\n  mutate(ACTIVE = rowSums(.[9:16])) %&gt;%  # Sum columns 9 to 16 for the \"ACTIVE\" age group\n  mutate(OLD = rowSums(.[17:21])) %&gt;%  # Sum columns 17 to 21 for the \"OLD\" age group\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%  # Sum columns 22 to 24 for the \"TOTAL\" population\n  filter(Year == 2018) %&gt;%  # Keep only rows where Year is 2018\n  filter(TOTAL &gt; 0)  # Remove rows where TOTAL population is 0 or missing\n\nhead(agpop_mutated)\n\n\n# A tibble: 6 √ó 25\n  PA         SZ        Year  `AGE0-4` `AGE05-9` `AGE10-14` `AGE15-19` `AGE20-24`\n  &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 Ang Mo Kio Ang Mo K‚Ä¶ 2018       180       270        320        300        260\n2 Ang Mo Kio Cheng San 2018      1060      1080       1080       1260       1400\n3 Ang Mo Kio Chong Bo‚Ä¶ 2018       900       900       1030       1220       1380\n4 Ang Mo Kio Kebun Ba‚Ä¶ 2018       720       850       1010       1120       1230\n5 Ang Mo Kio Sembawan‚Ä¶ 2018       220       310        380        500        550\n6 Ang Mo Kio Shangri-‚Ä¶ 2018       550       630        670        780        950\n# ‚Ñπ 17 more variables: `AGE25-29` &lt;dbl&gt;, `AGE30-34` &lt;dbl&gt;, `AGE35-39` &lt;dbl&gt;,\n#   `AGE40-44` &lt;dbl&gt;, `AGE45-49` &lt;dbl&gt;, `AGE50-54` &lt;dbl&gt;, `AGE55-59` &lt;dbl&gt;,\n#   `AGE60-64` &lt;dbl&gt;, `AGE65-69` &lt;dbl&gt;, `AGE70-74` &lt;dbl&gt;, `AGE75-79` &lt;dbl&gt;,\n#   `AGE80-84` &lt;dbl&gt;, AGE85over &lt;dbl&gt;, YOUNG &lt;dbl&gt;, ACTIVE &lt;dbl&gt;, OLD &lt;dbl&gt;,\n#   TOTAL &lt;dbl&gt;",
    "crumbs": [
      "Week 05"
    ]
  },
  {
    "objectID": "hands-on/week05.html#static-ternary-diagram",
    "href": "hands-on/week05.html#static-ternary-diagram",
    "title": "Week 05 - Visual Multivariate Analysis",
    "section": "4.2 Static Ternary Diagram",
    "text": "4.2 Static Ternary Diagram\n\n\nShow the code\nggtern(data = agpop_mutated,\n       aes(x = YOUNG,\n           y = ACTIVE, \n           z = OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2018\") +\n  theme_rgbw()",
    "crumbs": [
      "Week 05"
    ]
  },
  {
    "objectID": "hands-on/week05.html#interactive-ternary-diagram",
    "href": "hands-on/week05.html#interactive-ternary-diagram",
    "title": "Week 05 - Visual Multivariate Analysis",
    "section": "4.3 Interactive Ternary Diagram",
    "text": "4.3 Interactive Ternary Diagram\n\n\nShow the code\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG,\n  b = ~ACTIVE,\n  c = ~OLD, \n  color = ~PA,\n  type = \"scatterternary\",\n  hovertemplate = paste(\n    \"Young: %{a:.3f}%&lt;br&gt;\",\n    \"Active: %{b:.3f}%&lt;br&gt;\",\n    \"Old: %{c:.3f}%&lt;br&gt;\",\n    \"PA: %{text}&lt;extra&gt;&lt;/extra&gt;\"\n  ),\n  text = ~PA\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )",
    "crumbs": [
      "Week 05"
    ]
  },
  {
    "objectID": "hands-on/week05.html#data-preparation-4",
    "href": "hands-on/week05.html#data-preparation-4",
    "title": "Week 05 - Visual Multivariate Analysis",
    "section": "5.1 Data Preparation",
    "text": "5.1 Data Preparation\n\n\nLoading packages & data import\npacman::p_load(treemap, treemapify, tidyverse)",
    "crumbs": [
      "Week 05"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Learning journey and deliverables of ISSS608"
  },
  {
    "objectID": "take-home/exercise02.html",
    "href": "take-home/exercise02.html",
    "title": "Exercise 02 - Be Tradewise or Otherwise",
    "section": "",
    "text": "Since Mr.¬†Donald Trump took office as the President of the United States on January 20, 2025, global trade has come under intense scrutiny. His administration‚Äôs tariff policies, first implemented in 2019, particularly on goods such as steel and appliances, had significant ripple effects on international trade patterns. After assuming office in 2025, Trump introduced a second round of tariffs, further impacting global markets.\nThese policies are expected to affect merchandise trade more significantly than services trade, as tariffs primarily target physical goods rather than intangible services. Understanding how Singapore‚Äôs trade has evolved since 2015 requires both data visualization and time-series analysis. By leveraging analytical techniques in R, this project aims to uncover trade trends, identify key shifts, and assess the broader impact of Trump‚Äôs trade policies on Singapore‚Äôs major trade partners and sectors.\n\n\n\nSingapore reports its trade data in two key categories:\n\nServices trade: Transactions involving transport, finance, business services, and digital trade.\nMerchandise trade: The exchange of physical goods such as machinery, electronics, and raw materials.\n\n\n\nThis section will evaluate and improve three visualizations from the services trade dataset. The decision to focus on services trade for visualization critique is based on the following reasons:\n\nThe services and merchandise trade datasets share similar visualization structures, meaning insights gained from one can be applied to the other.\nThe services trade dataset is annual, making it less suitable for time-series modeling but still valuable for visual storytelling.\nA services trade focus ensures a cohesive critique and makeover.\n\nEach visualization will be critiqued for its strengths and weaknesses and redesigned using ggplot2 and other R packages to enhance clarity and interpretability.\n\n\n\nThe merchandise trade dataset, which provides monthly trade data, is more appropriate for time-series analysis and modeling. Since Trump‚Äôs tariffs primarily target physical goods, analyzing merchandise trade allows us to better understand their impact on Singapore‚Äôs trade patterns over time. This analysis will focus on:\n\nSingapore‚Äôs top 10 trading partners, with a particular emphasis on China, South Korea, and Australia, as these countries were directly affected by Trump‚Äôs tariffs.\nThe top five merchandise trade categories, along with appliances and steel materials, which were explicitly targeted by U.S. tariffs.",
    "crumbs": [
      "Exercise 02"
    ]
  },
  {
    "objectID": "take-home/exercise02.html#background",
    "href": "take-home/exercise02.html#background",
    "title": "Exercise 02 - Be Tradewise or Otherwise",
    "section": "",
    "text": "Since Mr.¬†Donald Trump took office as the President of the United States on January 20, 2025, global trade has come under intense scrutiny. His administration‚Äôs tariff policies, first implemented in 2019, particularly on goods such as steel and appliances, had significant ripple effects on international trade patterns. After assuming office in 2025, Trump introduced a second round of tariffs, further impacting global markets.\nThese policies are expected to affect merchandise trade more significantly than services trade, as tariffs primarily target physical goods rather than intangible services. Understanding how Singapore‚Äôs trade has evolved since 2015 requires both data visualization and time-series analysis. By leveraging analytical techniques in R, this project aims to uncover trade trends, identify key shifts, and assess the broader impact of Trump‚Äôs trade policies on Singapore‚Äôs major trade partners and sectors.",
    "crumbs": [
      "Exercise 02"
    ]
  },
  {
    "objectID": "take-home/exercise02.html#objectives",
    "href": "take-home/exercise02.html#objectives",
    "title": "Exercise 02 - Be Tradewise or Otherwise",
    "section": "",
    "text": "Singapore reports its trade data in two key categories:\n\nServices trade: Transactions involving transport, finance, business services, and digital trade.\nMerchandise trade: The exchange of physical goods such as machinery, electronics, and raw materials.\n\n\n\nThis section will evaluate and improve three visualizations from the services trade dataset. The decision to focus on services trade for visualization critique is based on the following reasons:\n\nThe services and merchandise trade datasets share similar visualization structures, meaning insights gained from one can be applied to the other.\nThe services trade dataset is annual, making it less suitable for time-series modeling but still valuable for visual storytelling.\nA services trade focus ensures a cohesive critique and makeover.\n\nEach visualization will be critiqued for its strengths and weaknesses and redesigned using ggplot2 and other R packages to enhance clarity and interpretability.\n\n\n\nThe merchandise trade dataset, which provides monthly trade data, is more appropriate for time-series analysis and modeling. Since Trump‚Äôs tariffs primarily target physical goods, analyzing merchandise trade allows us to better understand their impact on Singapore‚Äôs trade patterns over time. This analysis will focus on:\n\nSingapore‚Äôs top 10 trading partners, with a particular emphasis on China, South Korea, and Australia, as these countries were directly affected by Trump‚Äôs tariffs.\nThe top five merchandise trade categories, along with appliances and steel materials, which were explicitly targeted by U.S. tariffs.",
    "crumbs": [
      "Exercise 02"
    ]
  },
  {
    "objectID": "take-home/exercise02.html#relevant-libraries",
    "href": "take-home/exercise02.html#relevant-libraries",
    "title": "Exercise 02 - Be Tradewise or Otherwise",
    "section": "2.1 Relevant Libraries",
    "text": "2.1 Relevant Libraries\n\n\nLoading the relevant packages\npacman::p_load(\n  colorspace,   # Advanced color palettes\n  fpp3,         # Time series analysis\n  fracdiff,     # Fractionally differenced ARIMA models\n  geofacet,     # Geofaceted visualizations\n  GGally,       # Extensions to ggplot2, including pairwise plots\n  ggalt,        # Alternative geoms (e.g., xspline for smooth edges)\n  ggh4x,        # Enhancements for ggplot2 (e.g., stat_difference for filled areas)\n  ggiraph,      # Interactive ggplot2 visualizations\n  ggstream,     # Stream plots\n  glue,         # String interpolation and manipulation\n  knitr,        # Dynamic report generation with R Markdown\n  lubridate,    # Date and time handling\n  patchwork,    # Combining multiple ggplot2 plots\n  plotly,       # Interactive plots\n  readxl,       # Reading Excel files\n  tidyverse,    # Data manipulation and visualization\n  urca,         # Unit root and cointegration tests\n  zoo           # Rolling mean and time series operations\n)\n\n\n\n\n\n\n\n\n\nPackage\nDescription\n\n\n\n\ncolorspace\nProvides advanced color palettes and manipulation tools for visualizations.\n\n\nfpp3\nA collection of tools for time series analysis and forecasting.\n\n\nfracdiff\nImplements fractionally differenced ARIMA models for time series.\n\n\ngeofacet\nCreates geofaceted visualizations for spatial data.\n\n\nGGally\nEnhances ggplot2 with extensions like pairwise plots (GGpairs).\n\n\nggalt\nProvides alternative geoms, including xspline for smoother line edges.\n\n\nggh4x\nExtends ggplot2 with additional features like stat_difference for filled areas.\n\n\nggiraph\nEnables interactive ggplot2 visualizations with tooltips and hover effects.\n\n\nggstream\nGenerates stream plots to visualize time-based category proportions.\n\n\nglue\nProvides an easy way to interpolate and manipulate strings.\n\n\nknitr\nFacilitates dynamic report generation, especially with R Markdown.\n\n\nlubridate\nSimplifies working with dates and times in R.\n\n\npatchwork\nMakes it easy to combine multiple ggplot2 plots into a single layout.\n\n\nplotly\nConverts ggplot2 plots into interactive visualizations.\n\n\nreadxl\nReads Excel files into R efficiently.\n\n\ntidyverse\nA collection of packages for data manipulation, visualization, and analysis.\n\n\nurca\nPerforms unit root and cointegration tests for time series analysis.\n\n\nzoo\nProvides functions for rolling means and time series operations.",
    "crumbs": [
      "Exercise 02"
    ]
  },
  {
    "objectID": "take-home/exercise02.html#data-source",
    "href": "take-home/exercise02.html#data-source",
    "title": "Exercise 02 - Be Tradewise or Otherwise",
    "section": "2.2 Data Source",
    "text": "2.2 Data Source\nThe data was retrieved from SingStat on 1st March 2025. - Merchandise Trade - Trade in Services",
    "crumbs": [
      "Exercise 02"
    ]
  },
  {
    "objectID": "take-home/exercise02.html#selection-of-the-plots",
    "href": "take-home/exercise02.html#selection-of-the-plots",
    "title": "Exercise 02 - Be Tradewise or Otherwise",
    "section": "3.1 Selection of The Plots",
    "text": "3.1 Selection of The Plots\nAs previously mentioned, I have chosen the plots based on the dataset and will provide recommendations for improving the three plots from the trade service dataset. In this makeover, I aim to preserve the original message or story the designer intended to convey, while enhancing clarity by altering the way the data is presented.",
    "crumbs": [
      "Exercise 02"
    ]
  },
  {
    "objectID": "take-home/exercise02.html#first-makeover",
    "href": "take-home/exercise02.html#first-makeover",
    "title": "Exercise 02 - Be Tradewise or Otherwise",
    "section": "3.2. First Makeover",
    "text": "3.2. First Makeover\n\nThe Original\n\n\n\nFig 1a. The first figure we will be making over is a bar chart\n\n\nThe pros of the plot are that the vertical bars make it easy to see that both exports and imports have grown over time (as opposed to horizontal bars). Additionally, the totals are highlighted for each year, making the exact numbers accessible. Finally, they included additional information at the bottom is helpful to briefly mention about the trend, which may be helpful.\nHowever, each year has a different color, but the same distinction could be achieved with just two colors (one for exports, one for imports). The current scheme is visually appealing but distracting. Morever, since exports and imports alternate, it‚Äôs difficult to directly compare them across years. A faceted barplot may have been better. Finally, the trade balance is not immediately clear - we have to mentally subtract imports from exports to see the trade surplus.\nTherefore, my suggestion would be to create a line chart inspired from William Playfair‚Äôs trade-balance time-series chart.\n\n\n\nFig 1b. Suggested Visualization - To annotate the graph to show the trend clearly, and to make the graph interactive so we can obtain the values.\n\n\n\n\nThe Makeover\n\n\nLoading the data\nsvc_trade &lt;- read_csv('data/sg_svc_trade_by_category.csv')\nsvc_trade_long &lt;- svc_trade %&gt;%\n  pivot_longer(\n    cols = -c(`Category Name`, `Major Category`, `Trade Type`),  # Exclude identifier columns\n    names_to = \"Year\",                                           # New column for year\n    values_to = \"SGD (Million)\"                                 # New column for values\n  ) %&gt;%\n  mutate(Year = year(as.Date(paste0(Year, \"-01-01\"))))  # Convert Year to Date\n\nsvc_trade_annual &lt;- svc_trade_long %&gt;%\n  group_by(`Trade Type`, Year) %&gt;%\n  summarize(Total_Billion = sum(`SGD (Million)`/1000, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  pivot_wider(names_from = `Trade Type`, values_from = Total_Billion)\n\n\n\n\nCalcuate CAGR\ncalculate_cagr &lt;- function(start, end, n) {\n  cagr &lt;- (end / start)^(1 / n) - 1\n  return (round(cagr * 100, 1))\n}\nyi_start = svc_trade_annual$Import[svc_trade_annual$Year == 2020]\nyi_end = svc_trade_annual$Import[svc_trade_annual$Year == 2024]\nye_start = svc_trade_annual$Export[svc_trade_annual$Year == 2020]\nye_end = svc_trade_annual$Export[svc_trade_annual$Year == 2024]\nimport_cagr &lt;- calculate_cagr(yi_start, yi_end, 2024 - 2020)\nexport_cagr &lt;- calculate_cagr(ye_start, ye_end, 2024 - 2020)\n\n\n\n\nPlot the graph with ggigraph\n# Inspired from https://r-graph-gallery.com/web-time-series-and-facetting.html \n\nexport_colour &lt;- \"#73ad00\"\nimport_colour &lt;- \"#3883c9\"\n\ndf &lt;- svc_trade_annual %&gt;%\n  filter(Year &gt; 2009)\n\nwrapped_subtitle &lt;- str_wrap(\n  \"The areas highlight which aspect is in surplus. Both imports and exports have an increasing overall trend. In 2017, the amount of exports overtook the amount of imports.\",\n  width = 80  # Adjust the width as needed\n)\n\np &lt;- ggplot(df, aes(x = Year)) +\n  geom_point_interactive(aes(x = Year, y = Import, \n                             color = \"Imports\", \n                             tooltip = sprintf(\"Year: %s\\n Import: %.1f\\n Export: %.1f \\nTrade Balance: %.1f \\nTotal Trade: %.1f\",   Year, Import, Export, Export - Import, Export + Import),\n                             data_id = Import),\n                         size = 0.01,\n                         hover_nearest = TRUE) +\n  geom_point_interactive(aes(x = Year, y = Export, \n                             color = \"Exports\", \n                             tooltip = sprintf(\"Year: %s\\n Import: %.1f\\n Export: %.1f \\nTrade Balance: %.1f \\nTotal Trade: %.1f\",   Year, Import, Export, Export - Import, Export + Import),\n                             data_id = Import),\n                         size = 0.01,\n                         hover_nearest = TRUE) +\n  geom_line(aes(y = Import, color = \"Imports\"),\n            stat = StatXspline,\n            spline_shape = -0.4\n            ) +\n  geom_line(aes(y = Export, color = \"Exports\"),\n            stat = StatXspline,\n            spline_shape = -0.4\n            ) +\n  # stat_difference() from ggh4x package applies the conditional fill\n  # based on which of Not_Cat and Cat is larger.\n  stat_difference(aes(ymin = Import, ymax = Export), alpha = 0.3) +\n  scale_color_manual(values = c(export_colour, import_colour)) +\n  scale_fill_manual(\n    values = c(\n      colorspace::lighten(export_colour), \n      colorspace::lighten(import_colour), \n      \"grey60\"\n    ),\n  labels = c(\"More Exports\", \"More Imports\", \"Equal\")) +\n  coord_cartesian(xlim = c(2009, 2025), ylim = c(0, 600)) +  # Set axis limits\n  scale_x_continuous(breaks = seq(2010, 2024, 5)) +\n  scale_y_continuous(breaks = seq(0, 600, 100)) +\n  \n  # Annotate CAGR\n  annotate(\n    geom = \"curve\", \n    x = 2020.5, y = ye_start + 80, xend = 2024, yend = ye_end + 30, \n    curvature = -0.3, \n    arrow = arrow(length = unit(2, \"mm\")),\n    color = export_colour,\n  ) +\n  annotate(\n    geom = \"text\", \n    x = 2018.2, y = ye_end + 15, \n    label = paste(strwrap(sprintf(\"Export CAGR increased by %.1f%% from 2020 to 2024\", export_cagr), \n                    width = 20), collapse = \"\\n\"),\n    hjust = \"left\",\n    size = 3,\n    color = export_colour) +\n\n  annotate(\n    geom = \"curve\", \n    x = 2020.5, y = yi_start - 20, xend = 2024, yend = yi_end - 30, \n    curvature = 0.2, \n    arrow = arrow(length = unit(2, \"mm\")),\n    color = import_colour\n  ) +\n  annotate(\n    geom = \"text\", \n    x = 2021.5, y = yi_start - 53, \n    label = paste(strwrap(sprintf(\"Import CAGR increased by %.1f%% from 2020 to 2024\", import_cagr), \n                    width = 20), collapse = \"\\n\"),\n    size = 3,\n    hjust = \"left\",\n    color = import_colour) +\n\n\n  labs(\n    title = \"Overall Exports and Imports of Services (2010-2024)\",\n    subtitle = wrapped_subtitle,\n    caption = \"Source: Singstat.gov.sg | Graphic: Vivian Chew\",\n    y = \"S$ Billion\"\n  ) +\n  \n  theme_minimal(base_family = \"Helvetica Neue\") +\n  theme(\n    # Top-right position\n    # legend.pos = c(0.875, 0.975),\n    legend.position = \"bottom\",\n    # Elements within a guide are placed one next to the other in the same row\n    legend.direction = \"vertical\",\n    # Different guides are stacked vertically\n    legend.box = \"horizontal\",\n    # No legend title\n    legend.title = element_blank(),\n    # Light background color\n    # plot.background = element_rect(fill = \"#e2e1dc\", color = NA),\n    plot.margin = margin(20, 30, 20, 30),\n    # Customize the title. Note the new font family and its larger size.\n    plot.title = element_text(\n      margin = margin(0, 0, 0, 0), \n      size = 14, \n      family = \"Helvetica Neue\", \n      face = \"bold\", \n      vjust = 1, \n      color = \"grey25\"\n    ),\n    plot.caption = element_text(size = 8),\n    # Remove titles for x and y axes.\n    axis.title.x = element_blank(),\n    # Specify color for the tick labels along both axes \n    axis.text = element_text(color = \"grey40\"),\n    # Specify face and color for the text on top of each panel/facet\n    strip.text = element_text(face = \"bold\", color = \"grey20\")\n  )\n# Unfortunately the girafe object doesn't render on the Quarto HTML (but it works if I run on the cell, so it's very strange)\n# girafe(ggobj = p,\n#       width_svg = 8,\n#       height_svg = 6)\np\n\n\n\n\n\n\n\n\n\nUnfortunately, the girafe object doesn‚Äôt render on the Quarto HTML (but it works if I run on the cell, so it‚Äôs very strange). This is because of the spline plot. I did not manage to rectify this issue so the plot above will be a static plot instead. The plot below will be the interactive one. It shows the same thing just that the line is not ‚Äúsmooth‚Äù.\n\n\nPlot the graph with ggigraph - no spline\n# Inspired from https://r-graph-gallery.com/web-time-series-and-facetting.html \n\nexport_colour &lt;- \"#73ad00\"\nimport_colour &lt;- \"#3883c9\"\n\ndf &lt;- svc_trade_annual %&gt;%\n  filter(Year &gt; 2009)\n\nwrapped_subtitle &lt;- str_wrap(\n  \"The areas highlight which aspect is in surplus. Both imports and exports have an increasing overall trend. In 2017, the amount of exports overtook the amount of imports.\",\n  width = 80  # Adjust the width as needed\n)\n\np &lt;- ggplot(df, aes(x = Year)) +\n  geom_point_interactive(aes(x = Year, y = Import, \n                             color = \"Imports\", \n                             tooltip = sprintf(\"Year: %s\\n Import: %.1f\\n Export: %.1f \\nTrade Balance: %.1f \\nTotal Trade: %.1f\",   Year, Import, Export, Export - Import, Export + Import),\n                             data_id = Import),\n                         size = 0.01,\n                         hover_nearest = TRUE) +\n  geom_point_interactive(aes(x = Year, y = Export, \n                             color = \"Exports\", \n                             tooltip = sprintf(\"Year: %s\\n Import: %.1f\\n Export: %.1f \\nTrade Balance: %.1f \\nTotal Trade: %.1f\",   Year, Import, Export, Export - Import, Export + Import),\n                             data_id = Import),\n                         size = 0.01,\n                         hover_nearest = TRUE) +\n  geom_line(aes(y = Import, color = \"Imports\"),\n            spline_shape = -0.4\n            ) +\n  geom_line(aes(y = Export, color = \"Exports\"),\n            spline_shape = -0.4\n            ) +\n  # stat_difference() from ggh4x package applies the conditional fill\n  # based on which of Not_Cat and Cat is larger.\n  stat_difference(aes(ymin = Import, ymax = Export), alpha = 0.3) +\n  scale_color_manual(values = c(export_colour, import_colour)) +\n  scale_fill_manual(\n    values = c(\n      colorspace::lighten(export_colour), \n      colorspace::lighten(import_colour), \n      \"grey60\"\n    ),\n  labels = c(\"More Exports\", \"More Imports\", \"Equal\")) +\n  coord_cartesian(xlim = c(2009, 2025), ylim = c(0, 600)) +  # Set axis limits\n  scale_x_continuous(breaks = seq(2010, 2024, 5)) +\n  scale_y_continuous(breaks = seq(0, 600, 100)) +\n  \n  # Annotate CAGR\n  annotate(\n    geom = \"curve\", \n    x = 2020.5, y = ye_start + 80, xend = 2024, yend = ye_end + 30, \n    curvature = -0.3, \n    arrow = arrow(length = unit(2, \"mm\")),\n    color = export_colour,\n  ) +\n  annotate(\n    geom = \"text\", \n    x = 2018.2, y = ye_end + 15, \n    label = paste(strwrap(sprintf(\"Export CAGR increased by %.1f%% from 2020 to 2024\", export_cagr), \n                    width = 20), collapse = \"\\n\"),\n    hjust = \"left\",\n    size = 3,\n    color = export_colour) +\n\n  annotate(\n    geom = \"curve\", \n    x = 2020.5, y = yi_start - 20, xend = 2024, yend = yi_end - 30, \n    curvature = 0.2, \n    arrow = arrow(length = unit(2, \"mm\")),\n    color = import_colour\n  ) +\n  annotate(\n    geom = \"text\", \n    x = 2021.5, y = yi_start - 53, \n    label = paste(strwrap(sprintf(\"Import CAGR increased by %.1f%% from 2020 to 2024\", import_cagr), \n                    width = 20), collapse = \"\\n\"),\n    size = 3,\n    hjust = \"left\",\n    color = import_colour) +\n\n\n  labs(\n    title = \"Overall Exports and Imports of Services (2010-2024)\",\n    subtitle = wrapped_subtitle,\n    caption = \"Source: Singstat.gov.sg | Graphic: Vivian Chew\",\n    y = \"S$ Billion\"\n  ) +\n  \n  theme_minimal(base_family = \"Helvetica Neue\") +\n  theme(\n    # Top-right position\n    # legend.pos = c(0.875, 0.975),\n    legend.position = \"bottom\",\n    # Elements within a guide are placed one next to the other in the same row\n    legend.direction = \"vertical\",\n    # Different guides are stacked vertically\n    legend.box = \"horizontal\",\n    # No legend title\n    legend.title = element_blank(),\n    # Light background color\n    # plot.background = element_rect(fill = \"#e2e1dc\", color = NA),\n    plot.margin = margin(20, 30, 20, 30),\n    # Customize the title. Note the new font family and its larger size.\n    plot.title = element_text(\n      margin = margin(0, 0, 0, 0), \n      size = 14, \n      family = \"Helvetica Neue\", \n      face = \"bold\", \n      vjust = 1, \n      color = \"grey25\"\n    ),\n    plot.caption = element_text(size = 8),\n    # Remove titles for x and y axes.\n    axis.title.x = element_blank(),\n    # Specify color for the tick labels along both axes \n    axis.text = element_text(color = \"grey40\"),\n    # Specify face and color for the text on top of each panel/facet\n    strip.text = element_text(face = \"bold\", color = \"grey20\")\n  )\n\ngirafe(ggobj = p,\n      width_svg = 8,\n      height_svg = 6)",
    "crumbs": [
      "Exercise 02"
    ]
  },
  {
    "objectID": "take-home/exercise02.html#second-makeover",
    "href": "take-home/exercise02.html#second-makeover",
    "title": "Exercise 02 - Be Tradewise or Otherwise",
    "section": "3.2 Second Makeover",
    "text": "3.2 Second Makeover\n\nThe Original\n The strengths of this plot lie in the bar representation, which effectively highlights the differences in trade balance across countries. It allows for a clear side-by-side comparison of whether a region is more focused on imports or exports. The change between 2019 and 2023 can also be observed, though it requires some mental effort to assess the changes by region. The inclusion of region flags and category colors enhances the visual appeal and makes the plot easy to scan.\nHowever, the ranking is based on total trade (imports + exports), requiring viewers to mentally calculate the summed values. Additionally, the plot only shows the current rankings, without indicating any shifts in ranking from 2019 to 2023.\nIn order to visualize the change (trend), and also the ranking. I propose to use a slope graph.\n ### The Makeover\n\n\nLoading the data\nsvc_pi &lt;- read_excel('data/sg_svc_trade_by_partners.xlsx',\n                               sheet=\"import\")\nsvc_pe &lt;- read_excel('data/sg_svc_trade_by_partners.xlsx',\n                               sheet=\"export\")\nregion_mapping &lt;- read_csv('data/region_mapping.csv')\n\n\n\n\nData preprocessing\nbroad_classification &lt;- c('Asia', 'Europe', 'Africa', 'Oceania', 'ASEAN', 'European Union (EU-27)', \n                          'North America',\n                          'South And Central America And The Caribbean')\nregion_mapping$`Trading Partner` &lt;- region_mapping$`M49 code`\n\nformat_svc_partner_df &lt;- function(df, new_df) {\n  new_df &lt;- df %&gt;%\n    filter(!`Trading Partner` %in% broad_classification) %&gt;%\n    mutate(across(2:ncol(df), as.numeric)) %&gt;%\n    left_join(region_mapping %&gt;%\n              select(c(`Regional Blocs`, `Sub Division`, `Continent`, `Trading Partner`))) %&gt;%\n  mutate(`Regional Blocs` = ifelse(is.na(`Regional Blocs`), `Trading Partner`, `Regional Blocs`)) %&gt;%\n  pivot_longer(\n    cols = -c(`Trading Partner`, `Regional Blocs`, `Sub Division`, Continent),  # Exclude identifier columns\n    names_to = \"Year\",                                           \n    values_to = \"SGD (Million)\"\n  ) %&gt;%\n  mutate(Year = year(as.Date(paste0(Year, \"-01-01\"))))\n    \n  return (new_df)\n}\n\nsvc_pi_long &lt;- format_svc_partner_df(svc_pi)\nsvc_pe_long &lt;- format_svc_partner_df(svc_pe)\n\n\n\n\nChecking top 10 regions by import / export\nsvc_pi_2019_2023 &lt;- svc_pi_long %&gt;%\n  group_by(`Regional Blocs`, Year) %&gt;%\n  summarize(Import = sum(`SGD (Million)`/1000, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  filter(Year %in% c(2019, 2023))\n\nsvc_pi_2023_top_10 &lt;- svc_pi_2019_2023 %&gt;%\n  filter(Year == 2023) %&gt;%\n  arrange(desc(Import)) %&gt;%\n  slice(1:10)\n\nsvc_pe_2019_2023 &lt;- svc_pe_long %&gt;%\n  group_by(`Regional Blocs`, Year) %&gt;%\n  summarize(Export = sum(`SGD (Million)`/1000, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  filter(Year %in% c(2019, 2023))\n\nsvc_pe_2023_top_10 &lt;- svc_pe_2019_2023 %&gt;%\n  filter(Year == 2023) %&gt;%\n  arrange(desc(Export)) %&gt;%\n  slice(1:10)\n\n\n\n\nFinal top 12 regions for total trade\ncomb_svc_p_2019_2023 &lt;- svc_pi_2019_2023 %&gt;% \n  left_join(svc_pe_2019_2023,\n            by = c(\"Regional Blocs\" = \"Regional Blocs\", \"Year\" = \"Year\")) %&gt;%\n  mutate(`Total Trade` = Import + Export)\n\ntop_12_svc_p &lt;- comb_svc_p_2019_2023 %&gt;%\n  filter(Year == 2023) %&gt;%\n  arrange(desc(`Total Trade`)) %&gt;%\n  slice(1:12)\n\n\n\n\nSlopegraph using plotly\nexport_colour &lt;- \"#73ad00\"\nimport_colour &lt;- \"#3883c9\"\ntotal_colour &lt;- \"#f76a80\"\n\n# This helped: https://stackoverflow.com/questions/72669786/in-r-how-to-use-plotlys-highlight-function-to-activate-a-ggplot-2-graphic-la\nsubset_data &lt;- comb_svc_p_2019_2023 %&gt;%\n                   filter(`Regional Blocs` %in% top_12_svc_p$`Regional Blocs`) %&gt;%\n                   mutate(Region = `Regional Blocs`)\nranked_data &lt;- subset_data %&gt;% \n  group_by(Year) %&gt;% \n  mutate(\n    Import_Rank = rank(-Import, ties.method = \"min\"),  # Rank by Import (descending)\n    Export_Rank = rank(-Export, ties.method = \"min\"),  # Rank by Export (descending)\n    Total_Trade_Rank = rank(-`Total Trade`, ties.method = \"min\")  # Rank by Total Trade (descending)\n  ) %&gt;%\n  ungroup()  \n\nd &lt;- highlight_key(ranked_data, ~Region)\n\n# Their colours are pretty dull. \ngroup_colors &lt;- c(\n  \"United States Of America\" = \"#04747c\",\n  \"European Union (EU-27)\" = \"#808080\",\n  \"Mainland China\" = \"#344f6b\",\n  \"Japan\" = \"#d04f65\",\n  \"ASEAN\" = \"#6b99bb\",\n  \"Australia\" = \"#feab40\",\n  \"Hong Kong\" = \"#5c6ac0\",\n  \"United Kingdom\" = \"#679f39\",\n  \"Switzerland\" = \"#7f3e70\",\n  \"India\" = \"#726356\",\n  \"Taiwan\" = \"#cfa61d\",\n  \"Republic Of Korea\" = \"#9b3d4b\"\n)\n\np1 &lt;- ggplot(data = d,\n       aes(y=Import,\n           x=Year,\n           group = Region,\n           color = Region)) +\n  geom_point(size = 1) +\n  geom_line(aes(group = Region, alpha = 1), size = 0.5) +\n  geom_text(aes(label = Import_Rank),\n            hjust = \"left\",\n            size = 2.5,\n            nudge_x = 0.1,   # Adjust horizontal position (for plotly)\n            check_overlap = TRUE) +  # Avoid overlapping labels\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    panel.border = element_blank(),\n    axis.title.y = element_blank(),\n    axis.text.y = element_blank(),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor.y = element_blank(),\n    axis.title.x = element_blank(),\n    panel.grid.major.x = element_blank(),\n    axis.text.x.top = element_text(size=12)\n  ) +\n  coord_cartesian(xlim = c(2018.5, 2023.5), ylim = c(0, 110)) + \n  scale_x_continuous(breaks = seq(2019, 2023, 4)) +\n  scale_y_continuous(breaks = seq(5, 110, 10)) \n\np2 &lt;- ggplot(data = d,\n       aes(y=Export,\n           x=Year,\n           group = Region,\n           color = Region)) +\n  geom_point(size = 1) +\n  geom_line(aes(group = Region, alpha = 1), size = 0.5) +\n  geom_text(aes(label = Export_Rank),\n            hjust = \"left\",\n            size = 2.5,\n            nudge_x = 0.1,   # Adjust horizontal position (for plotly)\n            check_overlap = TRUE) +  # Avoid overlapping labels\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    panel.border = element_blank(),\n    axis.title.y = element_blank(),\n    axis.text.y = element_blank(),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor.y = element_blank(),\n    axis.title.x = element_blank(),\n    panel.grid.major.x = element_blank(),\n    axis.text.x.top = element_text(size=12)\n  ) +\n  coord_cartesian(xlim = c(2018.5, 2023.5), ylim = c(0, 110)) + \n  scale_x_continuous(breaks = seq(2019, 2023, 4)) +\n  scale_y_continuous(breaks = seq(5, 110, 10))\n\np3 &lt;- ggplot(data = d,\n       aes(y=`Total Trade`,\n           x=Year,\n           group = Region,\n           color = Region)) +\n  geom_point(size = 1) +\n  geom_line(aes(group = Region, alpha = 1), size = 0.5) +\n  geom_text(aes(label = paste0(Total_Trade_Rank,\" \", Region),\n                y = `Total Trade`),\n            hjust = \"left\",\n            size = 2.5,\n            nudge_x = 0.1,   # Adjust horizontal position (for plotly)\n            check_overlap = TRUE) +  # Avoid overlapping labels\n  coord_cartesian(xlim = c(2018.5, 2026), ylim = c(0, 160)) +\n  scale_x_continuous(breaks = seq(2019, 2023, 4)) +\n  scale_y_continuous(breaks = seq(5, 160, 15)) +\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    panel.border = element_blank(),\n    axis.title.y = element_blank(),\n    axis.text.y = element_blank(),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor.y = element_blank(),\n    axis.title.x = element_blank(),\n    panel.grid.major.x = element_blank(),\n    axis.text.x.top = element_text(size=12)\n  ) \n\n# Convert to plotly objects\np1_plotly &lt;- ggplotly(p1) \np2_plotly &lt;- ggplotly(p2)\np3_plotly &lt;- ggplotly(p3) \n\nrephrase_hovertext &lt;- function(txt) {\n  txt &lt;- sub(\"^((.*?&lt;br /&gt;){2}.*?)(&lt;br /&gt;.*)*$\", \"\\\\1\", txt)\n  txt &lt;- gsub(\":\\\\s+\", \": \", txt)  # Ensure only one space after colon\n\n  # Extract Year, Mode (Import/Export), Value, and Region\n  txt &lt;- sub(\"Year: (\\\\d+)&lt;br /&gt;([^:]+): ([0-9\\\\.]+)\\\\s*&lt;br /&gt;Region: (.+)\", \n             \"In &lt;b&gt;\\\\1&lt;/b&gt;, the \\\\2 was &lt;b&gt;S$ \\\\3 billion&lt;/b&gt; from &lt;b&gt;\\\\4&lt;/b&gt;\", txt)\n\n  # Round numbers to one decimal place if needed\n  txt &lt;- gsub(\"([0-9]+\\\\.[0-9]{1})[0-9]*\", \"\\\\1\", txt)\n  return (txt)\n}\n\nreplace_p_trace &lt;- function(plotly_object) {\n  for (i in rev(seq_along(plotly_object$x$data))) {\n    # Check if the trace has mode = \"markers\"\n    if (!is.null(plotly_object$x$data[[i]]$mode) && plotly_object$x$data[[i]]$mode == \"markers\") {\n      # Get the marker color\n      c &lt;- plotly_object$x$data[[i]]$marker$color\n      # Add lines to the trace\n      plotly_object$x$data[[i]]$line &lt;- list(\n        width = 1.889764,  # Set line width\n        color = sub(\"\\\\d+(\\\\.\\\\d+)?\\\\)$\", \"0.55)\", c), # Use marker color for the line, keeping the same opacity\n        dash = \"solid\"     # Set line style to solid\n      )\n      # Change mode to \"markers+lines\"\n      plotly_object$x$data[[i]]$mode &lt;- \"markers+lines\"\n      plotly_object$x$data[[i]]$text[[1]] &lt;- rephrase_hovertext(plotly_object$x$data[[i]]$text[[1]])\n      plotly_object$x$data[[i]]$text[[2]] &lt;- rephrase_hovertext(plotly_object$x$data[[i]]$text[[2]])\n    }\n    # Check if the trace has mode = \"lines\"\n    if (!is.null(plotly_object$x$data[[i]]$mode) && plotly_object$x$data[[i]]$mode == \"lines\") {\n      # Remove the entire trace\n      plotly_object$x$data[[i]] &lt;- NULL\n      }\n    for (j in seq_along(plotly_object$x$data[[i]]$hovertext)) {\n        plotly_object$x$data[[i]]$hovertext[[j]] &lt;- rephrase_hovertext(plotly_object$x$data[[i]]$hovertext[[j]])\n    }\n    trace_color &lt;- plotly_object$x$data[[i]]$textfont$color\n    \n    # Set hoverlabel bgcolor to match trace color\n    plotly_object$x$data[[i]]$hoverlabel &lt;- list(\n      bgcolor = trace_color,  # Match trace color\n      font = list(color = \"black\", size = 12)  # Customize font\n    )\n  }\n  return (plotly_object)\n}\n\np1_plotly &lt;- replace_p_trace(p1_plotly)\np2_plotly &lt;- replace_p_trace(p2_plotly)\np3_plotly &lt;- replace_p_trace(p3_plotly)\n  \n# For p1 and p2\nadjust_p_text &lt;- function(plotly_object) {\n  for (i in rev(seq_along(plotly_object$x$data))) {\n    if (!is.null(plotly_object$x$data[[i]]$mode) && plotly_object$x$data[[i]]$mode == \"text\") {\n      plotly_object$x$data[[i]]$x[[1]] &lt;- plotly_object$x$data[[i]]$x[[1]] - 0.4  # Shift left\n      plotly_object$x$data[[i]]$x[[2]] &lt;- plotly_object$x$data[[i]]$x[[2]] + 0.1  # Shift right\n    }\n  }\n  return (plotly_object)\n}\n\np1_plotly &lt;- adjust_p_text(p1_plotly)\np2_plotly &lt;- adjust_p_text(p2_plotly)\n\nfor (i in rev(seq_along(p3_plotly$x$data))) {\n  if (!is.null(p3_plotly$x$data[[i]]$mode) && p3_plotly$x$data[[i]]$mode == \"text\") {\n    if (any(grepl(\"Republic Of Korea\", p3_plotly$x$data[[i]]$text[[1]]))) {\n      p3_plotly$x$data[[i]]$y[[2]] &lt;- p3_plotly$x$data[[i]]$y[[2]] - 3\n    }\n   if (any(grepl(\"Mainland China\", p3_plotly$x$data[[i]]$text[[1]]))) {\n      p3_plotly$x$data[[i]]$y[[2]] &lt;- p3_plotly$x$data[[i]]$y[[2]] + 1\n   }\n    p3_plotly$x$data[[i]]$x[[1]] &lt;- p3_plotly$x$data[[i]]$x[[1]] - 0.5  # Shift left\n    p3_plotly$x$data[[i]]$text[[1]] &lt;- str_extract(p3_plotly$x$data[[i]]$text[[1]], \"\\\\d+\")\n    p3_plotly$x$data[[i]]$textposition &lt;- \"right\"\n  }\n}\n\ntitle &lt;- \"Major Trading Partners for Trade In Services\"\nsubtitle &lt;- \"The slopegraph illustrates the changes in services trade with Singapore‚Äôs top 12 trading partners.\"\nsubtitle2 &lt;- \"Click on the points and region names to highlight specific countries and regions.\"\n\nsubplot(p2_plotly, p1_plotly, p3_plotly, nrows = 1, \n        shareX = TRUE,\n        widths = c(0.3, 0.3, 0.4)) %&gt;%\n  highlight(on = 'plotly_click', off = 'plotly_doubleclick', \n            opacityDim = .25) %&gt;%\nlayout(\n  margin = list(b = 50),\n  title = list(\n      text = sprintf(\"&lt;b&gt;%s&lt;/b&gt;\", title),  # Title\n      font = list(family = \"Helvetica Neue\", size = 18, color = \"black\"),  # Title font\n      x = 0.02,  # Position title (0 = left, 1 = right)\n      y = 1   # Position title (0 = bottom, 1 = top)\n    ),\n  annotations = list( \n    list(x = 0 , y = 1.015, text = subtitle, showarrow = F, \n         xref='paper', yref='paper',\n         font = list(color = \"black\")\n         ), \n      list(x = 0 , y = 0.99, text = subtitle2, showarrow = F, \n         xref='paper', yref='paper',\n         font = list(color = \"black\")\n         ), \n    list(x = 0.02 , y = 0.93, text = \"Exports\", showarrow = F, \n         xref='paper', yref='paper',\n         font = list(color = \"white\"),\n         bgcolor = export_colour,\n         bordercolor = export_colour, \n         borderpad = 8,  \n         borderwidth = 1.5\n         ), \n    list(x = 0.35 , y = 0.93, text = \"Imports\", showarrow = F, \n         xref='paper', yref='paper',\n         font = list(color = \"white\"),\n         bgcolor = import_colour,\n         bordercolor = import_colour, \n         borderpad = 8,  \n         borderwidth = 1.5\n         ), \n    list(x = 0.72 , y = 0.93, text = \"Total Trade\", showarrow = F, \n         xref='paper', yref='paper',\n         font = list(color = \"white\"),\n         bgcolor = total_colour,\n         bordercolor = total_colour,  \n         borderpad = 8, \n         borderwidth = 1.5\n         ), \n    list(x = 1 , y = -0.05, text = \"Data Source: Singstat.gov.sg | Graphic: Vivian Chew\", showarrow = F, \n         xref='paper', yref='paper',\n         font = list(color = \"darkgray\", size = 12)\n         )), \n  font = list(family = \"Helvetica Neue\", size = 14, color = \"black\")\n  ) \n\n\n\n\n\n\nInstead of labelling the values as shown in the draft. I labelled the ranking instead, so we don‚Äôt have to manually count what position the country is ranked. We can also clearly see the change in ranking. If the values are needed, the viewer can just hover over to look at it.\nAlso note that:\n\nASEAN includes Brunei Darussalam, Cambodia, Indonesia, Lao People‚Äôs Democratic Republic, Malaysia, Myanmar, Philippines, Thailand and Vietnam.\nThe European Union (EU-27) comprises Austria, Belgium, Bulgaria, Croatia, Cyprus, Czech Rep, Denmark, Estonia, Finland, France, Germany, Greece, Hungary, Ireland, Italy, Latvia, Lithuania, Luxembourg, Malta, Netherlands, Poland, Portugal, Romania, Slovak Rep, Slovenia, Spain and Sweden.",
    "crumbs": [
      "Exercise 02"
    ]
  },
  {
    "objectID": "take-home/exercise02.html#third-makeover",
    "href": "take-home/exercise02.html#third-makeover",
    "title": "Exercise 02 - Be Tradewise or Otherwise",
    "section": "3.3 Third Makeover",
    "text": "3.3 Third Makeover\n\nThe Original\n The strengths of the chart lie in the use of distinct colors, which effectively differentiate the various groups. Additionally, the clear and concise labels make it easy to identify the proportions. However, a drawback is the excessive number of groups, which causes some sections of the pie to be unclear.\nWhile the designer has done a good job in conveying the proportions, I would suggest extending the visualization to highlight trends over time, given that this is a time-series challenge. A streamplot could be an effective way to display the changes in proportions over time, providing a clearer view of how the data evolves.\n For the actual implementation, a stacked area plot was used instead of a streamplot. This was because the trend shows a general increase, and a streamplot may not be the best choice in this case, as it could introduce unnecessary artifacts in the data representation. The stacked area plot provides a clearer and more straightforward visualization of the trend. The Government services category was also combined with the Other Business Services category as it constitutes the lowest proportion. The merging was done to reduce the number of categories.\n\n\nThe Makeover\n\n\nData preprocessing\nsvc_trade_by_cat &lt;- svc_trade_long %&gt;%\n  mutate(\n    `Major Category` = if_else(\n      `Major Category` == \"Government Goods And Services\",\n      \"Other Business Services\",\n      `Major Category`)) %&gt;%\n  group_by(`Major Category`, `Trade Type`, Year) %&gt;%\n  summarize(`SGD` = sum(`SGD (Million)`/1000, na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  mutate(`Major Category` = as.factor(`Major Category`))\n\ncategory_mapping &lt;- c(\n  \"Transport\" = \"Transport\",\n  \"Other Business Services\" = \"Other Biz\",\n  \"Financial\" = \"Financial\",\n  \"Telecommunications, Computer & Information\" = \"Telecom & IT\",\n  \"Travel\" = \"Travel\",\n  \"Charges For The Use Of Intellectual Property\" = \"Intellectual Prop\",\n  \"Insurance\" = \"Insurance\",\n  \"Maintenance And Repair Services\" = \"Maintenance\",\n  \"Manufacturing Services On Physical Inputs Owned By Others\" = \"Manufacturing\",\n  \"Personal, Cultural And Recreational\" = \"Personal & Cultural\",\n  \"Construction\" = \"Construction\"\n)\n\nsvc_trade_by_cat &lt;- svc_trade_by_cat %&gt;%\n  mutate(`Major Category` = recode(`Major Category`, !!!category_mapping))\n\n# Getting the order for the hierarchy of the plot\norder &lt;- svc_trade_by_cat %&gt;% filter(Year == 2024) %&gt;% \n  group_by(`Major Category`) %&gt;% \n  summarize(Total = sum(`SGD`, na.rm = TRUE)) %&gt;%\n  arrange(desc(`Total`))\norder &lt;- order$`Major Category`\n\n\n\n\nGetting text annotation positions\n# For annotation of the text points. In the end the values are manipulated in the last array, but the base values\n# were defined from this set of code.\nsvc_trade_export_val_2024 &lt;- svc_trade_by_cat %&gt;%\n  filter(Year == 2024 & `Trade Type` == 'Export') %&gt;%\n  mutate(`Major Category` = factor(`Major Category`, levels = order)) %&gt;%\n  arrange(desc(`Major Category`)) %&gt;% \n  mutate(Cumulative_Sum = cumsum(`SGD`)) %&gt;%\n  arrange(`Major Category`)\nsvc_trade_export_val_2024$Roll &lt;- rollmean(svc_trade_export_val_2024$Cumulative_Sum, \n                                           k = 2, fill = svc_trade_export_val_2024$Cumulative_Sum[[1]], \n                                           align = \"right\")\nsvc_trade_export_val_2024$Roll &lt;- svc_trade_export_val_2024$Roll * 1.1\nsvc_trade_export_val_2024$Roll &lt;- c(581.42513, 466.29103, 286.52903, 172.53065, 140.52777, 110.36837, \n                                    90.40066, 70.00528, 50.09414, 30.88403, 10.96793)\n\nsvc_trade_import_val_2024 &lt;- svc_trade_by_cat %&gt;%\n  filter(Year == 2024 & `Trade Type` == 'Import') %&gt;%\n  mutate(`Major Category` = factor(`Major Category`, levels = order)) %&gt;%\n  arrange(desc(`Major Category`)) %&gt;% \n  mutate(Cumulative_Sum = cumsum(`SGD`)) %&gt;%\n  arrange(`Major Category`)\nsvc_trade_import_val_2024$Roll &lt;- rollmean(svc_trade_import_val_2024$Cumulative_Sum, \n                                           k = 2, fill = svc_trade_import_val_2024$Cumulative_Sum[[1]], \n                                           align = \"right\")\nsvc_trade_import_val_2024$Roll &lt;- svc_trade_import_val_2024$Roll * 1.1\nsvc_trade_import_val_2024$Roll &lt;- c(516.099650, 406.992280, 225.728440, 160.798055, 124.086435, \n                                    105.163955,  88.944805,  68.877570,  48.004660,  28.538805, 10.112220)\n\n\n\n\nPlotting the graph with ggstream\n# Inspired from https://r-graph-gallery.com/web-stacked-area-chart-inline-labels.html\n\npal &lt;- c('#5c6ac0', '#bd76ac', '#8c6238', '#35506a', '#6d98bb', '#ff718b', \n  '#9b3d4b', '#04abc1', '#7ecc6b','#349098', '#feab40', '#cfa61d')\n\n# Convert hex colors to RGB values\nrgb_values &lt;- col2rgb(pal)\n\n# Extract the red component and order the colors by red value\nsorted_pal &lt;- pal[order(rgb_values[1, ], decreasing = TRUE)]\n\n# Display the sorted palette\ngradient_pal &lt;- colorRampPalette(sorted_pal)\ngrad_colors &lt;- gradient_pal(23)\n\nslp1 &lt;- svc_trade_by_cat %&gt;% filter(Year &gt; 2014 & `Trade Type` == 'Export') %&gt;%\n  mutate(`Major Category` = factor(`Major Category`, levels=order)) %&gt;% \n  ggplot(aes(x = Year, \n             y = `SGD`, \n             fill = `Major Category`, \n             label = `Major Category`, \n             color = `Major Category`)) +\n  geom_stream(type = \"ridge\", bw=1) +\n  theme_minimal() +\n  scale_fill_manual(values=grad_colors) +\n  scale_color_manual(values=grad_colors) +\n  theme(\n    legend.position = \"none\",\n    panel.border = element_blank(),\n    axis.title.y = element_blank(),\n    axis.text.y = element_blank(),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor.y = element_blank(),\n    axis.title.x = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor.x = element_blank()\n  ) +\n  scale_x_continuous(breaks=c(2015, 2020, 2024),labels = c(\"2015\",\"2020\",\"2024\")) +\n  scale_y_continuous(expand = c(0,0)) +\n  coord_cartesian(xlim = c(2015, 2027), ylim = c(0, 950)) +\n  geom_text(\n    data = svc_trade_export_val_2024,\n    aes(x = 2024, y = `Roll`, label = paste0(`Major Category`, \" S$ \", round(`SGD`, 1), \" B\")),  # Place labels to the left of the plot\n    hjust = 0,  # Right-align text\n    size = 2.5,  # Adjust text size\n    nudge_x = 0.1,\n  ) +\n  annotate(\"text\", x = 2015, y = 700,\n           label = \"Exports\",\n           hjust=0,\n           size=10,\n           lineheight=.9,\n           fontface=\"bold\", family=\"Helvetica Neue\",\n           color=\"black\") +\n  geom_segment(aes(x = 2015, y = 0, xend = 2015, yend = 211 + 180),color=\"black\") +\n  geom_point(aes(x = 2015, y = 211 + 180),color=\"black\") +\n  annotate(\"text\", x = 2015, y = 211 + 200,\n           label = \"S$ 211 B\",\n           hjust=0.5,\n           size=3,\n           lineheight=.8,\n           fontface=\"bold\",family=\"Helvetica Neue\",\n           color=\"black\") +\n  \n  geom_segment(aes(x = 2020, y = 0, xend = 2020, yend = 300 + 180),color=\"black\") +\n  geom_point(aes(x = 2020, y = 300 + 180),color=\"black\") +\n  annotate(\"text\", x = 2020, y = 300 + 200,\n           label = \"S$ 300 B\",\n           hjust=0.5,\n           size=3,\n           lineheight=.8,\n           fontface=\"bold\",family=\"Helvetica Neue\",\n           color=\"black\") +\n\n  geom_segment(aes(x = 2024, y = 0, xend = 2024, yend = 529 + 350),color=\"black\") +\n  geom_point(aes(x = 2024, y = 529 + 350), color=\"black\") +\n  annotate(\"text\", x = 2024, y = 529 + 370,\n           label = \"S$ 529 B\",\n           hjust=1.1,\n           size=3,\n           lineheight=.8,\n           fontface=\"bold\",family=\"Helvetica Neue\",\n           color=\"black\")\n\nslp2 &lt;- svc_trade_by_cat %&gt;% filter(Year &gt; 2014 & `Trade Type` == 'Import') %&gt;%\n  mutate(`Major Category` = factor(`Major Category`, levels=order)) %&gt;% \n  ggplot(aes(x = Year, \n             y = `SGD`, \n             fill = `Major Category`, \n             label = `Major Category`, \n             color = `Major Category`)) +\n  geom_stream(type = \"ridge\", bw=1) +\n  theme_minimal() +\n  scale_fill_manual(values=grad_colors) +\n  scale_color_manual(values=grad_colors) +\n  theme(\n    legend.position = \"none\",\n    panel.border = element_blank(),\n    axis.title.y = element_blank(),\n    axis.text.y = element_blank(),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor.y = element_blank(),\n    axis.title.x = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor.x = element_blank()\n  ) +\n  scale_x_continuous(breaks=c(2015, 2020, 2024),labels = c(\"2015\",\"2020\",\"2024\")) +\n  scale_y_continuous(expand = c(0,0)) +\n  coord_cartesian(xlim = c(2015, 2027), ylim = c(0, 950)) +\n  geom_text(\n    data = svc_trade_import_val_2024,\n    aes(x = 2024, y = `Roll`, label = paste0(`Major Category`, \" S$ \", round(`SGD`, 1), \" B\")),\n    hjust = 0,  # Right-align text\n    size = 2.5,  # Adjust text size\n    nudge_x = 0.1,\n  ) +\n  annotate(\"text\", x = 2015, y = 700,\n           label = \"Imports\",\n           hjust=0,\n           size=10,\n           lineheight=.9,\n           fontface=\"bold\", family=\"Helvetica Neue\",\n           color=\"black\") +\n  geom_segment(aes(x = 2015, y = 0, xend = 2015, yend = 222 + 180),color=\"black\") +\n  geom_point(aes(x = 2015, y = 222 + 180),color=\"black\") +\n  annotate(\"text\", x = 2015, y = 222 + 200,\n           label = \"S$ 222 B\",\n           hjust=0.5,\n           size=3,\n           lineheight=.8,\n           fontface=\"bold\",family=\"Helvetica Neue\",\n           color=\"black\") +\n  \n  geom_segment(aes(x = 2020, y = 0, xend = 2020, yend = 290 + 180),color=\"black\") +\n  geom_point(aes(x = 2020, y = 290 + 180),color=\"black\") +\n  annotate(\"text\", x = 2020, y = 290 + 200,\n           label = \"S$ 290 B\",\n           hjust=0.5,\n           size=3,\n           lineheight=.8,\n           fontface=\"bold\",family=\"Helvetica Neue\",\n           color=\"black\") +\n\n  geom_segment(aes(x = 2024, y = 0, xend = 2024, yend = 469 + 350),color=\"black\") +\n  geom_point(aes(x = 2024, y = 469 + 350), color=\"black\") +\n  annotate(\"text\", x = 2024, y = 469 + 370,\n           label = \"S$ 469 B\",\n           hjust=1.1,\n           size=3,\n           lineheight=.8,\n           fontface=\"bold\",family=\"Helvetica Neue\",\n           color=\"black\")\n\ncombined_plot &lt;- slp1 + slp2\n\n# Add a global title\ncombined_plot &lt;- combined_plot +\n  plot_annotation(\n    title = \"Trade of Services By Services Category (2015 - 2024)\",\n    subtitle = \"The stacked area chart shows the proportion of services trade by category over the years.\",\n    theme = theme(plot.title = element_text(size = 16, face = \"bold\", family=\"Helvetica Neue\")),\n    caption = \"Data Source: Singstat.gov.sg | Graphic: Vivian Chew\"\n  )\n\ncombined_plot",
    "crumbs": [
      "Exercise 02"
    ]
  },
  {
    "objectID": "take-home/exercise02.html#data-processing-exploration",
    "href": "take-home/exercise02.html#data-processing-exploration",
    "title": "Exercise 02 - Be Tradewise or Otherwise",
    "section": "4.1 Data Processing & Exploration",
    "text": "4.1 Data Processing & Exploration\n\n\nData processing\nmerch_import_comm &lt;- read_excel(\"data/sg_merchandise_trade_commodities_monthly.xlsx\",\n                             sheet = \"import\")\nmerch_dexport_comm &lt;- read_excel(\"data/sg_merchandise_trade_commodities_monthly.xlsx\",\n                             sheet = \"dexport\")\nmerch_rexport_comm &lt;- read_excel(\"data/sg_merchandise_trade_commodities_monthly.xlsx\",\n                             sheet = \"rexport\")\nmerch_trade_by_region &lt;- read_csv(\"data/merch_trade_by_region.csv\")\n\ntrade_type &lt;- c(\"Import\", \"Domestic Export\", \"Re Export\")\ndf_list &lt;- list(merch_import_comm, merch_dexport_comm, merch_rexport_comm)\ntransformed_dfs &lt;- list()\n\nfor (i in seq_along(df_list)) {\n  transformed_dfs[[i]] &lt;- df_list[[i]][, 1:302] %&gt;%  # Only until Jan 2000\n    pivot_longer(cols = -Division, names_to = \"Date\", values_to = \"Dollars\") %&gt;%\n    mutate(Date = yearmonth(as.Date(paste0(Date, \" 01\"), format = \"%Y %b %d\"))) %&gt;%\n    mutate(`Trade Type` = trade_type[i])\n}\nmerch_trade_comm &lt;- bind_rows(transformed_dfs)\n\n\n\n\nShowing the top 10 imports\n#\ntop_10_imports &lt;- data.frame(\n  Division = merch_import_comm[, 1],\n  Total = rowSums(merch_import_comm[, 3:13], na.rm = TRUE)\n) %&gt;%\n  arrange(desc(Total)) %&gt;%\n  slice(1:10)\n\nkable(top_10_imports, caption = \"Top 10 Imports by Division\", align = \"c\")\n\n\n\nTop 10 Imports by Division\n\n\n\n\n\n\nDivision\nTotal\n\n\n\n\nElectrical Machinery Apparatus & Appliances Nes & Electrical Parts Thereof\n152635947\n\n\nPetroleum & Products & Related Materials\n99904510\n\n\nOffice Machines & Automatic Data-Processing Machines\n35683761\n\n\nTelecommunications & Sound-Recording & Reproducing Apparatus & Equipment\n21881157\n\n\nMiscellaneous Manufactured Articles Nes\n17537659\n\n\nProfessional Scientific & Controlling Instruments & Apparatus Nes\n13063085\n\n\nOrganic Chemicals\n9906637\n\n\nMedicinal & Pharmaceutical Products\n8253028\n\n\nGas\n7676251\n\n\nEssential Oils & Resinoids & Perfume Materials; Toilet Polishing & Cleansing Preparations\n6707179\n\n\n\n\n\n\n\nShowing the top 10 domestic exports\ntop_10_dexports &lt;- data.frame(\n  Division = merch_dexport_comm[, 1],\n  Total = rowSums(merch_dexport_comm[, 3:13], na.rm = TRUE)\n) %&gt;%\n  arrange(desc(Total)) %&gt;%\n  slice(1:10)\n\nkable(top_10_dexports, caption = \"Top 10 Domestic Exports by Division\", align = \"c\")\n\n\n\nTop 10 Domestic Exports by Division\n\n\n\n\n\n\nDivision\nTotal\n\n\n\n\nPetroleum & Products & Related Materials\n66725676\n\n\nOil Bunkers\n36518099\n\n\nElectrical Machinery Apparatus & Appliances Nes & Electrical Parts Thereof\n26759504\n\n\nProfessional Scientific & Controlling Instruments & Apparatus Nes\n13333000\n\n\nOrganic Chemicals\n12787195\n\n\nMiscellaneous Manufactured Articles Nes\n11721623\n\n\nPlastics In Primary Forms\n9382327\n\n\nOffice Machines & Automatic Data-Processing Machines\n6622158\n\n\nMedicinal & Pharmaceutical Products\n6505025\n\n\nEssential Oils & Resinoids & Perfume Materials; Toilet Polishing & Cleansing Preparations\n3715803\n\n\n\n\n\n\n\nShowing the top 10 re-exports\ntop_10_rexports &lt;- data.frame(\n  Division = merch_rexport_comm[, 1],\n  Total = rowSums(merch_rexport_comm[, 3:13], na.rm = TRUE)\n) %&gt;%\n  arrange(desc(Total)) %&gt;%\n  slice(1:10)\n\nkable(top_10_rexports, caption = \"Top 10 Re-Exports by Division\", align = \"c\")\n\n\n\nTop 10 Re-Exports by Division\n\n\n\n\n\n\nDivision\nTotal\n\n\n\n\nProfessional Scientific & Controlling Instruments & Apparatus Nes\n10128897\n\n\nMiscellaneous Manufactured Articles Nes\n9050097\n\n\nEssential Oils & Resinoids & Perfume Materials; Toilet Polishing & Cleansing Preparations\n8714097\n\n\nMedicinal & Pharmaceutical Products\n5498607\n\n\nPlastics In Primary Forms\n3687515\n\n\nPhotographic Apparatus Equipment & Supplies & Optical Goods Nes; Watches & Clocks\n3594048\n\n\nBeverages\n3302949\n\n\nManufactures Of Metals Nes\n2837285\n\n\nPetroleum & Products & Related Materials\n2525066\n\n\nIron & Steel\n2315779\n\n\n\n\n\n\n\nData processing - by region\nmerch_trade_region_long &lt;- merch_trade_by_region %&gt;%\n  pivot_longer(\n    cols = -c(Region, Continent, `Trade Type`),  # Exclude these columns\n    names_to = \"Date\", \n    values_to = \"Dollars\"\n  ) %&gt;%\n  mutate(Date = yearmonth(as.Date(paste0(Date, \" 01\"), format = \"%Y %b %d\")))\n\n\n\n\nTop merchandise trade by region\ntop_merch_trade_by_country &lt;- merch_trade_region_long %&gt;%\n  filter(year(Date) == 2024) %&gt;%\n  group_by(Region, Continent) %&gt;% \n  summarize(Total_Dollars = sum(Dollars, na.rm = TRUE)) %&gt;%  \n  ungroup() %&gt;%\n  arrange(desc(Total_Dollars))\n\ntop_merch_trade_by_country_20 &lt;- top_merch_trade_by_country %&gt;%\n  slice(1:20)\n\nkable(top_merch_trade_by_country_20, caption = \"Top 20 Total Merchandise Trade by Country in 2024\", align = \"c\")\n\n\n\nTop 20 Total Merchandise Trade by Country in 2024\n\n\nRegion\nContinent\nTotal_Dollars\n\n\n\n\nChina\nAsia\n170182.3\n\n\nMalaysia\nAsia\n138643.5\n\n\nUnited States\nAmerica\n131989.3\n\n\nTaiwan\nAsia\n116787.9\n\n\nHong Kong\nAsia\n78622.2\n\n\nIndonesia\nAsia\n74154.9\n\n\nKorea, Rep Of\nAsia\n66818.1\n\n\nJapan\nAsia\n53402.3\n\n\nThailand\nAsia\n44475.0\n\n\nIndia\nAsia\n31893.9\n\n\nViet Nam\nAsia\n31670.3\n\n\nAustralia\nOceania\n30305.7\n\n\nUnited Arab Emirates\nAsia\n24051.2\n\n\nGermany\nEurope\n22512.8\n\n\nFrance\nEurope\n21563.0\n\n\nUnited Kingdom\nEurope\n19257.4\n\n\nPhilippines\nAsia\n19177.9\n\n\nNetherlands\nEurope\n14068.8\n\n\nSwitzerland\nEurope\n13726.0\n\n\nBrazil\nAmerica\n11867.7\n\n\n\n\n\n\n\nSelected regions\nselected_regions &lt;- c(\"China\", \"United States\", \"Malaysia\", \n                      \"Taiwan\", \"Canada\", \"Australia\", \"Germany\",\n                      \"France\", \"Korea, Rep Of\")\n\n\nChina, the US, Canada, and Australia were selected due to their involvement in trade tensions following Trump‚Äôs tariffs, particularly China, which was the primary target. Canada was affected by steel and aluminum tariffs, while Australia, though largely exempt, remains a key trade partner of the US. Germany and France were included to represent the EU, which faced tariffs on steel and other goods, though the UK, despite higher trade flows, was excluded as it is no longer part of the EU. Malaysia Taiwan and Korea were chosen due to their position among the top few merchandise trade partners of Singapore.",
    "crumbs": [
      "Exercise 02"
    ]
  },
  {
    "objectID": "take-home/exercise02.html#time-series-patterns---by-trade-regions",
    "href": "take-home/exercise02.html#time-series-patterns---by-trade-regions",
    "title": "Exercise 02 - Be Tradewise or Otherwise",
    "section": "4.2 Time Series Patterns - By Trade Regions",
    "text": "4.2 Time Series Patterns - By Trade Regions\n\nUsing ggplotUsing autoplot\n\n\nThis plot is preferred over using autoplot.\n\n\nPlot time series using ggplot\nmerch_trade_region_long %&gt;%\n  filter(year(Date) &gt; 2009) %&gt;%\n  as_tsibble(key = c(Region, `Trade Type`), index = Date) %&gt;%\n  filter(Region %in% selected_regions) %&gt;%\n  ggplot(aes(x = Date, y = Dollars, color = `Trade Type`)) +\n  geom_line() +\n  facet_wrap(~ Region, scales = \"free_y\", ncol = 3) +\n  labs(\n    title = \"Monthly Merchandise Trade Flow of Selected Countries (2010 - 2024)\",\n    x = \"Date\",\n    y = \"Dollars\"\n  )\n\n\n\n\n\n\n\n\n\n\nChina, Malaysia, Taiwan, and Korea show strong import growth (green) post-2020, with a sharp peak in imports from Taiwan and Korea between 2022-2023. This aligns with trends in specific merchandise categories like ‚ÄúElectrical Machinery & Parts‚Äù and ‚ÄúGas,‚Äù which also spike during the same period (The plot is below). Given Taiwan and Korea‚Äôs role in semiconductors and electronics, this surge likely reflects increased demand for electronic components and supply chain adjustments during the post-pandemic recovery.\nRe-Exports (blue) have grown for Germany, China, and US, reflecting Singapore‚Äôs role as a trade hub.\nDomestic exports (red) remain relatively stable across most countries, though China and the US show gradual increases.\nThe US-China trade war trend isn‚Äôt immediately obvious in the chart, as there‚Äôs no clear dip or disruption around 2018-2019.\n\n\n\nIt‚Äôs difficult to see because there‚Äôs too many points on the legend.\n\n\nUsing autoplot\nmerch_trade_region_long %&gt;%\n  filter(year(Date) &gt; 2009) %&gt;%\n  as_tsibble(key = c(Region, `Trade Type`), index = Date) %&gt;%\n  filter(Region %in% selected_regions) %&gt;%\n  autoplot(Dollars) + facet_wrap(~ Region, scales = \"free_y\" , ncol = 3) +\n  ggtitle(\"Monthly Merchandise Trade Flow Selected Countries (2010 - 2024)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChecking by import category division\nmerch_trade_comm %&gt;%\n  filter(Division %in% top_10_imports$Division) %&gt;%\n  filter(year(Date) &gt; 2009) %&gt;%\n  as_tsibble(key = c(Division, `Trade Type`), index = Date) %&gt;%\n  ggplot(aes(x = Date, y = Dollars, color = `Trade Type`)) +\n  geom_line() +\n  facet_wrap(~ Division, scales = \"free_y\", ncol = 5) +\n  labs(\n    title = \"Monthly Merchandise Trade Flow of Selected Divisions (2010 - 2024)\",\n    x = \"Date\",\n    y = \"Dollars\"\n  )",
    "crumbs": [
      "Exercise 02"
    ]
  },
  {
    "objectID": "take-home/exercise02.html#seasonal-plots",
    "href": "take-home/exercise02.html#seasonal-plots",
    "title": "Exercise 02 - Be Tradewise or Otherwise",
    "section": "4.2 Seasonal Plots",
    "text": "4.2 Seasonal Plots\nThe plots above don‚Äôt seem to show any clear seasonal patterns, but for the sake of the analysis, let‚Äôs investigate further.\n\nImportsDomestic ExportsRe-Exports\n\n\n\n\nseasonality plots\nmerch_trade_region_long |&gt; \n  filter(`Trade Type` == \"Import\" & year(Date) &gt; 2014) |&gt;\n  as_tsibble(key = Region, index = Date) |&gt;\n  filter(Region %in% selected_regions) |&gt; \n  gg_season(Dollars, period=\"year\", labels = \"both\") +\n  theme(legend.position = \"none\") +\n  ggtitle(\"Seasonal Plot: Monthly Merchandise Imports of Selected Countries (2015 - 2024)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nseasonality plots\nmerch_trade_region_long |&gt; \n  filter(`Trade Type` == \"Domestic Export\" & year(Date) &gt; 2014) |&gt;\n  as_tsibble(key = Region, index = Date) |&gt;\n  filter(Region %in% selected_regions) |&gt; \n  gg_season(Dollars, period=\"year\", labels = \"both\") +\n  theme(legend.position = \"none\") +\n  ggtitle(\"Seasonal Plot: Monthly Merchandise Domestic Exports of Selected Countries (2015 - 2024)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nseasonality plots\nmerch_trade_region_long |&gt; \n  filter(`Trade Type` == \"Re-Export\" & year(Date) &gt; 2014) |&gt;\n  as_tsibble(key = Region, index = Date) |&gt;\n  filter(Region %in% selected_regions) |&gt; \n  gg_season(Dollars, period=\"year\", labels = \"both\") +\n  theme(legend.position = \"none\") +\n  ggtitle(\"Seasonal Plot: Monthly Merchandise Re-Exports of Selected Countries (2015 - 2024)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportsDomestic ExportsRe-Exports\n\n\n\n\nseasonality subseries\nmerch_trade_region_long |&gt; \n  filter(`Trade Type` == \"Import\" & year(Date) &gt; 2014) |&gt;\n  as_tsibble(key = Region, index = Date) |&gt;\n  filter(Region %in% selected_regions) |&gt; \n  gg_subseries(Dollars) +\n  ggtitle(\"Subseries: Monthly Merchandise Imports of Selected Countries (2015 - 2024)\")\n\n\n\n\n\n\n\n\n\nFebruary appears to be the month with the lowest imports, with China showing the most noticeable dip, possibly due to the Chinese New Year, followed by the United States. However, overall, the mean import values seem relatively stable, indicating no significant differences in the average across the months. Regarding the trend, imports generally show an upward trajectory, though there was a noticeable dip in 2020 across most regions, likely due to the impact of the pandemic.\n\n\n\n\nseasonality subseries\nmerch_trade_region_long |&gt; \n  filter(`Trade Type` == \"Domestic Export\" & year(Date) &gt; 2014) |&gt;\n  as_tsibble(key = Region, index = Date) |&gt;\n  filter(Region %in% selected_regions) |&gt; \n  gg_subseries(Dollars) +\n  ggtitle(\"Subseries: Monthly Merchandise Domestic Exports of Selected Countries (2015 - 2024)\")\n\n\n\n\n\n\n\n\n\nFor domestic exports, the trends are less clear, though there are occasional spikes throughout the period.\n\n\n\n\nseasonality subseries\nmerch_trade_region_long |&gt; \n  filter(`Trade Type` == \"Re-Export\" & year(Date) &gt; 2014) |&gt;\n  as_tsibble(key = Region, index = Date) |&gt;\n  filter(Region %in% selected_regions) |&gt; \n  gg_subseries(Dollars) +\n  ggtitle(\"Subseries: Monthly Merchandise Re-Exports of Selected Countries (2015 - 2024)\")\n\n\n\n\n\n\n\n\n\nOverall, re-exports remain stable, with a noticeable upward trend in the US for Singapore‚Äôs re-exports. In Australia, March and December appear to have the highest re-export levels.",
    "crumbs": [
      "Exercise 02"
    ]
  },
  {
    "objectID": "take-home/exercise02.html#scatterplots",
    "href": "take-home/exercise02.html#scatterplots",
    "title": "Exercise 02 - Be Tradewise or Otherwise",
    "section": "4.3 Scatterplots",
    "text": "4.3 Scatterplots\n\nImportsDomestic ExportsRe-Exports\n\n\n\n\nscatter pairplots\nmerch_trade_region_long %&gt;%\n  filter(`Trade Type` == \"Import\" & Region %in% selected_regions & year(Date) &gt; 2009) %&gt;%\n  select(-Continent, -`Trade Type`) %&gt;%\n  pivot_wider(values_from = Dollars, names_from = Region) %&gt;%\n  GGally::ggpairs(2:9)\n\n\n\n\n\n\n\n\n\n\n\n\n\nscatter pairplots\nmerch_trade_region_long %&gt;%\n  filter(`Trade Type` == \"Domestic Export\" & Region %in% selected_regions & year(Date) &gt; 2009) %&gt;%\n  select(-Continent, -`Trade Type`) %&gt;%\n  pivot_wider(values_from = Dollars, names_from = Region) %&gt;%\n  GGally::ggpairs(2:9)\n\n\n\n\n\n\n\n\n\n\n\n\n\nscatter pairplots\nmerch_trade_region_long %&gt;%\n  filter(`Trade Type` == \"Re-Export\" & Region %in% selected_regions & year(Date) &gt; 2009) %&gt;%\n  select(-Continent, -`Trade Type`) %&gt;%\n  pivot_wider(values_from = Dollars, names_from = Region) %&gt;%\n  GGally::ggpairs(2:9)",
    "crumbs": [
      "Exercise 02"
    ]
  },
  {
    "objectID": "take-home/exercise02.html#lag-plots",
    "href": "take-home/exercise02.html#lag-plots",
    "title": "Exercise 02 - Be Tradewise or Otherwise",
    "section": "4.4 Lag plots",
    "text": "4.4 Lag plots\n\n\nlagplots\nmerch_trade_region_long %&gt;%\n  filter(`Trade Type` == \"Import\" & Region == \"China\" & year(Date) &gt; 2009) %&gt;%\n  as_tsibble(key = Region, index = Date) %&gt;%\n  gg_lag(Dollars, geom = \"point\") +\n  labs(x = \"lag(Dollars, k)\")",
    "crumbs": [
      "Exercise 02"
    ]
  },
  {
    "objectID": "take-home/exercise02.html#stl-decomposition",
    "href": "take-home/exercise02.html#stl-decomposition",
    "title": "Exercise 02 - Be Tradewise or Otherwise",
    "section": "4.5 STL Decomposition",
    "text": "4.5 STL Decomposition\n\n\ncombine exports\nmerch_trade_exports_comb &lt;- merch_trade_region_long %&gt;%\n  filter((`Trade Type` == \"Domestic Export\" | `Trade Type` == \"Re Export\") & year(Date) &gt; 2009) %&gt;%\n  group_by(Region, Date) %&gt;%\n  summarize(Dollars = sum(Dollars)) %&gt;%\n  ungroup() %&gt;%\n  as_tsibble(key = Region, index = Date)\n\n\n\nChinaUSTaiwanGermanyAustraliaMalaysia\n\n\n\n\nSTL plots\nmerch_trade_exports_comb %&gt;%\n  filter(Region == \"China\") %&gt;%\n  as_tsibble(key = Region, index = Date) %&gt;%\n  model(\n    STL(Dollars ~ trend(window = 11) +\n                   season(window = \"periodic\"),\n    robust = TRUE)) |&gt;\n  components() |&gt;\n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\nSTL plots\nmerch_trade_exports_comb %&gt;%\n  filter(Region == \"United States\") %&gt;%\n  as_tsibble(key = Region, index = Date) %&gt;%\n  model(\n    STL(Dollars ~ trend(window = 11) +\n                   season(window = \"periodic\"),\n    robust = TRUE)) |&gt;\n  components() |&gt;\n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\nSTL plots\nmerch_trade_exports_comb %&gt;%\n  filter(Region == \"Taiwan\") %&gt;%\n  as_tsibble(key = Region, index = Date) %&gt;%\n  model(\n    STL(Dollars ~ trend(window = 11) +\n                   season(window = \"periodic\"),\n    robust = TRUE)) |&gt;\n  components() |&gt;\n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\nSTL plots\nmerch_trade_exports_comb %&gt;%\n  filter(Region == \"Germany\") %&gt;%\n  as_tsibble(key = Region, index = Date) %&gt;%\n  model(\n    STL(Dollars ~ trend(window = 11) +\n                   season(window = \"periodic\"),\n    robust = TRUE)) |&gt;\n  components() |&gt;\n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\nSTL plots\nmerch_trade_exports_comb %&gt;%\n  filter(Region == \"Australia\") %&gt;%\n  as_tsibble(key = Region, index = Date) %&gt;%\n  model(\n    STL(Dollars ~ trend(window = 11) +\n                   season(window = \"periodic\"),\n    robust = TRUE)) |&gt;\n  components() |&gt;\n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\nSTL plots\nmerch_trade_exports_comb %&gt;%\n  filter(Region == \"Malaysia\") %&gt;%\n  as_tsibble(key = Region, index = Date) %&gt;%\n  model(\n    STL(Dollars ~ trend(window = 11) +\n                   season(window = \"periodic\"),\n    robust = TRUE)) |&gt;\n  components() |&gt;\n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\n\nI‚Äôve combined both domestic exports and re-exports to assess how external trade restrictions, like the Trump tariffs, might affect Singapore‚Äôs trade. Since these restrictions are expected to have a larger impact on exports, looking at both gives a clearer understanding of their potential effect on overall trade dynamics.\nFrom the STL plots, we can see that:\n\nExports to the US and China from Singapore show an increasing trend.\nExports to Germany exhibit a decreasing trend.\nExports to the rest of the countries remain relatively stable. There seem to be an up and down trend due to the global economic conditions, but it has mostly gone back up.\nSeasonality-wise, most dips are observed in February (as corroborated by the seasonality plots), with the exception of Australia, where the dip spans from December to February.",
    "crumbs": [
      "Exercise 02"
    ]
  },
  {
    "objectID": "take-home/exercise02.html#conclusion",
    "href": "take-home/exercise02.html#conclusion",
    "title": "Exercise 02 - Be Tradewise or Otherwise",
    "section": "4.6 Conclusion",
    "text": "4.6 Conclusion\nWhile there is some seasonality, especially with February showing consistent dips, the overall import and export trend appears positive, with growth in key markets like the US and China. This suggests that, despite some seasonal variations, Singapore‚Äôs export situation remains favorable. The observed patterns, including the dips and stable trends, provide valuable insight into how external factors, such as trade restrictions, may influence Singapore‚Äôs trade flow. However, the first round of tariffs does not seem to have had a noticeable impact on trade flows. In conclusion, Singapore‚Äôs merchandise trade situation appears to be overall positive, with steady growth and stability.",
    "crumbs": [
      "Exercise 02"
    ]
  },
  {
    "objectID": "in-class/exercise05.html",
    "href": "in-class/exercise05.html",
    "title": "Week 05‚Äôs In Class Exercise - Visual Analytics For Building Better Explanatory Models",
    "section": "",
    "text": "pacman::p_load(tidyverse, \n               readxl, \n               SmartEDA, \n               easystats,\n               performance,\n               ggstatsplot,\n               gtsummary # summarize model results to create table\n               )\n# R base stats is clumsy and untidy LOL\n\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \"data\")",
    "crumbs": [
      "Exercise 05"
    ]
  },
  {
    "objectID": "in-class/exercise05.html#getting-started",
    "href": "in-class/exercise05.html#getting-started",
    "title": "Week 05‚Äôs In Class Exercise - Visual Analytics For Building Better Explanatory Models",
    "section": "",
    "text": "pacman::p_load(tidyverse, \n               readxl, \n               SmartEDA, \n               easystats,\n               performance,\n               ggstatsplot,\n               gtsummary # summarize model results to create table\n               )\n# R base stats is clumsy and untidy LOL\n\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \"data\")",
    "crumbs": [
      "Exercise 05"
    ]
  },
  {
    "objectID": "in-class/exercise05.html#using-smarteda-to-explore-the-data",
    "href": "in-class/exercise05.html#using-smarteda-to-explore-the-data",
    "title": "Week 05‚Äôs In Class Exercise - Visual Analytics For Building Better Explanatory Models",
    "section": "Using SmartEDA to Explore the Data",
    "text": "Using SmartEDA to Explore the Data\n\n# Overview of the data - Type = 1\nsummary1 &lt;- car_resale %&gt;%\n  ExpData(type = 1)\n\n\n# Structure of the data - Type = 2\nsummary2 &lt;- car_resale %&gt;%\n  ExpData(type = 2)\n\n\ncols &lt;- c(\"Mfg_Month\", \"HP_Bin\", \"CC_bin\", \"Doors\", \"Gears\",\n          \"Cylinders\", \"Fuel_Type\", \"Color\", \"Met_Color\",\n          \"Automatic\", \"Mfr_Guarantee\", \"BOVAG_Guarantee\",\n          \"ABS\", \"Airbag_1\", \"Airbag_2\", \"Airco\", \"Automatic_airco\",\n          \"Boardcomputer\", \"CD_Player\", \"Central_Lock\",\n          \"Powered_Windows\", \"Power_Steering\", \"Radio\", \"Mistlamps\",\n          \"Sport_Model\", \"Backseat_Divider\", \"Metallic_Rim\",\n          \"Radio_cassette\", \"Tow_Bar\")\ncar_resale &lt;- car_resale %&gt;% \n  mutate(Id = as.character(Id)) %&gt;%\n  mutate_each_(funs(factor(.)), cols)\n\n\nLooking at the numerical variables\n\ncar_resale %&gt;%\n  ExpNumViz(target=NULL,\n            nlim=10,\n            Page=c(2,2))\n\n$`0`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncar_resale %&gt;%\n  ExpNumViz(target = \"Price\",\n            nlim = 10,\n            Page = c(2,2)  # Figure layout per page\n            )\n\n$`0`\n\n\n\n\n\n\n\n\n\n\n\nLooking at the categorical variables\n\ncar_resale %&gt;%\n  ExpCatViz(target = NULL,\n            clim = 10,\n            col = \"skyblue\",\n            margin = 2,\n            Page = c(4,4), \n            sample = 16\n            )\n\n$`0`",
    "crumbs": [
      "Exercise 05"
    ]
  },
  {
    "objectID": "in-class/exercise05.html#using-performance-for-model-statistics",
    "href": "in-class/exercise05.html#using-performance-for-model-statistics",
    "title": "Week 05‚Äôs In Class Exercise - Visual Analytics For Building Better Explanatory Models",
    "section": "Using performance For Model Statistics",
    "text": "Using performance For Model Statistics\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period,\n            data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\n\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + Weight + Guarantee_Period,\n            data = car_resale)\ncheck_normality(model1)\n\nWarning: Non-normality of residuals detected (p &lt; .001).\n\n\n\nsummary(model1)\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10249.4   -768.6    -15.4    738.5   6356.5 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      -2.186e+03  9.722e+02  -2.248   0.0247 *  \nAge_08_04        -1.195e+02  2.760e+00 -43.292   &lt;2e-16 ***\nKM               -2.406e-02  1.201e-03 -20.042   &lt;2e-16 ***\nWeight            1.972e+01  8.379e-01  23.533   &lt;2e-16 ***\nGuarantee_Period  2.682e+01  1.261e+01   2.126   0.0336 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1413 on 1431 degrees of freedom\nMultiple R-squared:  0.8486,    Adjusted R-squared:  0.8482 \nF-statistic:  2005 on 4 and 1431 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "Exercise 05"
    ]
  },
  {
    "objectID": "in-class/exercise05.html#using-gtsummary-for-model-statistics-in-tabular-form",
    "href": "in-class/exercise05.html#using-gtsummary-for-model-statistics-in-tabular-form",
    "title": "Week 05‚Äôs In Class Exercise - Visual Analytics For Building Better Explanatory Models",
    "section": "Using gtsummary For Model Statistics in Tabular Form",
    "text": "Using gtsummary For Model Statistics in Tabular Form\n\n# gtsummary - organise the regression summary into a data table\ntbl_regression(model, intercept = TRUE)\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI1\np-value\n\n\n\n\n(Intercept)\n-2,636,783\n-3,150,331, -2,123,236\n&lt;0.001\n\n\nAge_08_04\n-14\n-35, 7.1\n0.2\n\n\nMfg_Year\n1,315\n1,059, 1,571\n&lt;0.001\n\n\nKM\n-0.02\n-0.03, -0.02\n&lt;0.001\n\n\nWeight\n19\n17, 21\n&lt;0.001\n\n\nGuarantee_Period\n28\n3.8, 52\n0.023\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n# Include additional statistical measures\ntbl_regression(model1,\n               intercept = TRUE) %&gt;%\n  add_glance_source_note(\n    label = list(sigma = \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared,\n                AIC, statistic,\n                p.value, sigma)\n  )\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n-2,186\n-4,093, -278\n0.025\n    Age_08_04\n-119\n-125, -114\n&lt;0.001\n    KM\n-0.02\n-0.03, -0.02\n&lt;0.001\n    Weight\n20\n18, 21\n&lt;0.001\n    Guarantee_Period\n27\n2.1, 52\n0.034\n  \n  \n    \n      R¬≤ = 0.849; Adjusted R¬≤ = 0.848; AIC = 24,915; Statistic = 2,005; p-value = &lt;0.001; œÉ = 1,413\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\np_model1 &lt;- parameters(model1)\np_model1\n\nParameter        | Coefficient |       SE |              95% CI | t(1431) |      p\n----------------------------------------------------------------------------------\n(Intercept)      |    -2185.52 |   972.19 | [-4092.59, -278.45] |   -2.25 | 0.025 \nAge 08 04        |     -119.49 |     2.76 | [ -124.91, -114.08] |  -43.29 | &lt; .001\nKM               |       -0.02 | 1.20e-03 | [   -0.03,   -0.02] |  -20.04 | &lt; .001\nWeight           |       19.72 |     0.84 | [   18.08,   21.36] |   23.53 | &lt; .001\nGuarantee Period |       26.82 |    12.61 | [    2.08,   51.56] |    2.13 | 0.034 \n\n\n\nplot(parameters(model1))\n\n\n\n\n\n\n\n\n\nggcoefstats(model1)",
    "crumbs": [
      "Exercise 05"
    ]
  },
  {
    "objectID": "in-class/exercise07.html",
    "href": "in-class/exercise07.html",
    "title": "Week 07 - Visualising and Analysing Time-oriented Data",
    "section": "",
    "text": "Loading packages\npacman::p_load(tidyverse,\n               tsibble,\n               feasts,\n               fable,\n               seasonal,\n               knitr)\n\n\n\n\nLoad and process data\nts_data &lt;- read_csv('data/visitor_arrivals_by_air.csv')\n# Convert to date field\nts_data$`Month-Year` &lt;- dmy(ts_data$`Month-Year`)\n# Convert from tibble to TS data type\nts_data_ts &lt;- ts(ts_data)\n\n\n\n\nConvert datatype\n# Convert to tbl_ts for compatibility with tidyverts\nts_tsibble &lt;- ts_data %&gt;%\n  mutate(Month = yearmonth(`Month-Year`)) %&gt;%\n  as_tsibble(index = `Month`)\n\n\n\n\nTransform the data\n# This is pd.melt\nts_longer &lt;- ts_data %&gt;%\n  pivot_longer(cols = c(2:34),\n               names_to = \"Country\",  # Columns\n               values_to = \"Arrivals\")",
    "crumbs": [
      "Exercise 07"
    ]
  },
  {
    "objectID": "in-class/exercise07.html#seasonality",
    "href": "in-class/exercise07.html#seasonality",
    "title": "Week 07 - Visualising and Analysing Time-oriented Data",
    "section": "3.1 Seasonality",
    "text": "3.1 Seasonality\n\n\nExtend the tsibble\n# Convert to tbl_ts for compatibility with tidyverts\ntsibble_longer &lt;- ts_tsibble %&gt;%\n  pivot_longer(cols = c(2:34),\n               names_to = \"Country\",  # Columns\n               values_to = \"Arrivals\")\n\n\n\ntsibble_longer %&gt;%\n  filter(Country == \"Vietnam\" | Country == \"Italy\") %&gt;%\n  gg_subseries(Arrivals) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCan see that the Italians only come in the month of August.",
    "crumbs": [
      "Exercise 07"
    ]
  },
  {
    "objectID": "in-class/exercise07.html#acf-and-pacf-decomposition",
    "href": "in-class/exercise07.html#acf-and-pacf-decomposition",
    "title": "Week 07 - Visualising and Analysing Time-oriented Data",
    "section": "3.2 ACF and PACF Decomposition",
    "text": "3.2 ACF and PACF Decomposition\n\nacf_vals &lt;- tsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\" |\n         `Country` == \"Italy\" |\n         `Country` == \"United Kingdom\" |\n         `Country` == \"China\") %&gt;%\n  ACF(Arrivals)\n\nacf_vals %&gt;% autoplot()\n\n\n\n\n\n\n\n\n\nThe blue line is the 95% confidence interval. Anything within the blue line -&gt; correlation is not statistically significant.\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\" |\n         `Country` == \"Italy\" |\n         `Country` == \"United Kingdom\" |\n         `Country` == \"China\") %&gt;%\n  PACF(Arrivals) %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\nACF plots show the correlation between data points at different lags, while PACF plots show the partial correlation between data points at different lags.",
    "crumbs": [
      "Exercise 07"
    ]
  },
  {
    "objectID": "in-class/exercise07.html#stl-decomposition",
    "href": "in-class/exercise07.html#stl-decomposition",
    "title": "Week 07 - Visualising and Analysing Time-oriented Data",
    "section": "3.3 STL Decomposition",
    "text": "3.3 STL Decomposition\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  model(stl = STL(Arrivals)) %&gt;%\n  components() %&gt;%\n  autoplot()",
    "crumbs": [
      "Exercise 07"
    ]
  },
  {
    "objectID": "in-class/exercise04.html",
    "href": "in-class/exercise04.html",
    "title": "Week 04‚Äôs In Class Exercise",
    "section": "",
    "text": "Loading packages & data import\npacman::p_load(haven, smartEDA, tidyverse, tidymodels, ggridges)\n\nexam_data &lt;- read_csv(\"../data/Exam_data.csv\")",
    "crumbs": [
      "Exercise 04"
    ]
  },
  {
    "objectID": "in-class/exercise04.html#comparing-boxplot-ridgeline-plots",
    "href": "in-class/exercise04.html#comparing-boxplot-ridgeline-plots",
    "title": "Week 04‚Äôs In Class Exercise",
    "section": "Comparing Boxplot & Ridgeline Plots",
    "text": "Comparing Boxplot & Ridgeline Plots\n\nBoxplotRidgeline\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = ENGLISH,\n           y = CLASS)) +\n  geom_boxplot() +\n    scale_x_continuous(\n    name = \"English scores\",\n    limits = c(0, 100),\n    expand = c(0, 0)\n    ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = ENGLISH, \n           y = CLASS,\n           height = after_stat(count))) +\n  geom_ridgeline(stat = \"density\",\n                 alpha = 0.8) + \n  scale_x_continuous(\n    name = \"English scores\",\n    limits = c(0, 100),\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = \"CLASS\",\n                   expand = expansion(add = c(0.2, 2.6))) +\n  theme_minimal()",
    "crumbs": [
      "Exercise 04"
    ]
  },
  {
    "objectID": "take-home/exercise01.html",
    "href": "take-home/exercise01.html",
    "title": "Exercise 01 - Heart Attack In Japan",
    "section": "",
    "text": "Disclaimer: The content has been parsed through various LLMs for refinement.",
    "crumbs": [
      "Exercise 01"
    ]
  },
  {
    "objectID": "take-home/exercise01.html#background",
    "href": "take-home/exercise01.html#background",
    "title": "Exercise 01 - Heart Attack In Japan",
    "section": "1.1 Background",
    "text": "1.1 Background\nCardiovascular diseases (CVDs) remain a major health concern in Japan, ranking as the second and fourth leading causes of death, according to recent statistics [1]. While overall CVD mortality has declined, challenges continue to exist in certain demographics and regions. In particular, the incidence of ischemic heart disease is projected to rise among urban male employees and middle-aged men [2]. Although projections suggest a potential decline in CVD-related deaths across most Japanese prefectures between 2020 and 2040 [3], this trend is not uniform. The evolving landscape of risk factors necessitates ongoing vigilance and targeted interventions.",
    "crumbs": [
      "Exercise 01"
    ]
  },
  {
    "objectID": "take-home/exercise01.html#objectives",
    "href": "take-home/exercise01.html#objectives",
    "title": "Exercise 01 - Heart Attack In Japan",
    "section": "1.2 Objectives",
    "text": "1.2 Objectives\nWe will first examine risk factors beyond individual control before focusing on modifiable factors. The outcome variable (O) will be Heart Attack Occurrence. The goal is to provide recommendations for reducing heart attack risk by emphasizing controllable factors while recognizing the influence of non-modifiable ones.\nFactors Beyond Individual Control (U)\n\nDemographics & Medical History\nKey analyses:\n\nExamining age and sex distribution among heart attack patients.\nInvestigating how medical history contributes to individual risk.\nAssessing the impact of all the uncontrollable factors on heart attack risk.\n\n\nModifiable Risk Factors (M)\n\nLifestyle & Behavioral Factors, Physical & Medical Indicators\nKey analyses:\n\nExamining the relationship between lifestyle behaviors and physical/medical indicators.\nComparing univariate and multivariate models to understand how these factors interact.",
    "crumbs": [
      "Exercise 01"
    ]
  },
  {
    "objectID": "take-home/exercise01.html#references",
    "href": "take-home/exercise01.html#references",
    "title": "Exercise 01 - Heart Attack In Japan",
    "section": "1.3 References",
    "text": "1.3 References\n\nMinistry of Health, Labour and Welfare, Japan. (2022). The 2021 vital statistics [in Japanese]. Link\nLink to PMC article\nNational Cerebral and Cardiovascular Center",
    "crumbs": [
      "Exercise 01"
    ]
  },
  {
    "objectID": "take-home/exercise01.html#relevant-libraries",
    "href": "take-home/exercise01.html#relevant-libraries",
    "title": "Exercise 01 - Heart Attack In Japan",
    "section": "2.1 Relevant Libraries",
    "text": "2.1 Relevant Libraries\n\n\nLoading the relevant packages\npacman::p_load(broom,  \n               ComplexUpset,\n               corrplot,\n               easystats,\n               ggdist,\n               ggstatsplot,\n               gtsummary,\n               patchwork, \n               SmartEDA,\n               tidyverse\n)\n\n\n\n\n\n\n\n\n\nPackage\nDescription\n\n\n\n\nbroom\nConverts statistical model outputs into tidy data frames for easy manipulation.\n\n\nComplexUpset\nCreates complex UpSet plots for visualizing intersections of sets.\n\n\ncorrplot\nVisualizes correlation matrices with customizable plots.\n\n\neasystats\nA suite of tools for statistical modeling and interpretation.\n\n\nggdist\nCreates visualizations for distributions and uncertainty in ggplot2.\n\n\nggstatsplot\nProduces enhanced statistical plots with significance tests.\n\n\ngtsummary\nCreates elegant summary tables for regression models and descriptive statistics.\n\n\npatchwork\nCombines multiple ggplot2 plots into single layouts easily.\n\n\nSmartEDA\nPerforms automated exploratory data analysis (EDA) with summaries and visuals.\n\n\ntidyverse\nA collection of packages for data manipulation, visualization, and analysis.",
    "crumbs": [
      "Exercise 01"
    ]
  },
  {
    "objectID": "take-home/exercise01.html#data-source",
    "href": "take-home/exercise01.html#data-source",
    "title": "Exercise 01 - Heart Attack In Japan",
    "section": "2.2 Data Source",
    "text": "2.2 Data Source\n\n2.2.1 About the Data Source\nThe dataset was originally retrieved from this Kaggle repository. However, as of February 16, 2025, the page is no longer accessible, and we are unable to retrieve the dataset.\nAccording to the author, the dataset included:\n\nDemographic data (e.g., age, sex, region)\nMedical history\nLifestyle & behavioral factors\nPhysical & medical indicators\nElectrocardiographic (ECG) data\n\nFurther details will be discussed in the data wrangling section. We have also extracted Japan population data from here.\n\n\n2.2.2 Considerations and Limitations\nSeveral uncertainties and limitations must be acknowledged regarding this dataset:\n\nStudy Design & Temporal Issues\n\nThis is unlikely to be a cohort study and, at best, might be a retrospective cohort study. We assume it is a case-control study, but key uncertainties remain.\nIt is unclear whether certain health indicators (e.g., BMI, physical activity levels) were recorded before or after the heart attack. This means:\n\nReverse causation is possible (e.g., Did individuals have high BMI before their heart attack, or did they gain weight due to post-event health deterioration?).\nBehavioral changes post-heart attack could influence results (e.g., Did those with high physical activity levels increase their exercise habits after experiencing a heart attack?).\n\n\nUnclear Baseline & Regional Ambiguity\n\nThe dataset does not clarify whether the recorded region (urban/rural) reflects where individuals lived most of their lives.\nMigration post-heart attack could affect interpretations (e.g., Did individuals move to an urban area for better healthcare, or relocate to a rural area for a lower-stress lifestyle?).\n\nMissing Information\n\nNo details are provided on heart attack severity (e.g., intensity, number of occurrences).\n\nPotential Sampling Bias\n\nSurvivorship bias: Individuals who died from a heart attack may not be included, affecting representativeness.\n\nPopulation Uncertainty\n\nThe dataset does not specify whether participants are Japanese nationals or residents of Japan, which could have implications for generalizability.\n\n\nThese limitations should be considered when interpreting any associations, as correlation does not imply causation, and some findings may be bidirectional.",
    "crumbs": [
      "Exercise 01"
    ]
  },
  {
    "objectID": "take-home/exercise01.html#should-we-remove-the-unknown-columns",
    "href": "take-home/exercise01.html#should-we-remove-the-unknown-columns",
    "title": "Exercise 01 - Heart Attack In Japan",
    "section": "3.1 Should we remove the unknown columns?",
    "text": "3.1 Should we remove the unknown columns?\nThere were 15 columns named Extra_Columns_ that were provided in the dataset. The initial suspicion was that it could be the ECG data as the authors claimed that ECG data was provided.\n\n\nVisualizing the 15 unknown columns\noriginal_colors &lt;- c(\"#ddb1b1\", \"#d0839a\", \"#8cb8c5\", \"#e7a43b\", \"#e72222\")\ncustom_palette &lt;- colorRampPalette(c(\"#d0839a\", \"#ddb1b1\", \"#8cb8c5\"))(100)\nrepeating_palette &lt;- rep(original_colors, length.out = 100)\n\ndf_last_15 &lt;- df %&gt;% \n  select(tail(names(df), 15)) %&gt;%\n  rename_with(~ gsub(\"Extra_Column_\", \"Col_\", .x)) \n\ndf_check &lt;- df_last_15 %&gt;% \n  slice_sample(n = 100) %&gt;%\n  t() %&gt;%\n  as.data.frame() %&gt;%\n  mutate(row = row_number()) %&gt;%\n  pivot_longer(cols = -row, names_to = \"sample\", values_to = \"value\")\n\nsample_lineplot &lt;- ggplot(df_check, aes(x = row, y = value, color = sample)) +\n  geom_line() +\n  scale_color_manual(values = repeating_palette) +\n  labs(x = \"Row\", y = \"Value\", \n       title = \"LinePlot of Extra Columns\",\n       subtitle = \"Subsample of n = 100\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\nlast15_corrplot &lt;- ggstatsplot::ggcorrmat(\n  data = df_last_15, \n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  colors = custom_palette,\n  title    = \"Correlogram for \",\n  subtitle = \"Four pairs are no significant at p &lt; 0.05\"\n) + theme_minimal() +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        axis.text.x = element_text(angle = 45, hjust = 1))\n\ncombined_plot &lt;- sample_lineplot + last15_corrplot\ncombined_plot\n\n\n\n\n\n\n\n\n\nUpon closer examination of the data, several concerning observations were made:\n\nVisualization Issues: Sub-samples of the data, when plotted, do not resemble typical ECG wave-forms (Left). Another suspicion was that it could be derived features, such as single heartbeat feature (PQRST) extracted from the ECG signal and features [1].\nLack of Correlation: Contrary to expectations for ECG-derived features, there is no correlation observed among the features (Right). Typically, some level of correlation would be expected in signal data.\nStatistical Analysis: A Kruskal-Wallis test using the 15 features to examine heart attack occurrence revealed no significant differences.\n\nGiven these findings and in the interest of explanatory modelling, it has been decided to exclude these unknown features from further analysis. This decision is based on initial checks suggesting limited utility of these features, although a comprehensive multivariate analysis was not conducted. The focus will shift to more reliable and interpretable variables for the study of heart attack risk factors.\n\n\nKruskal test\ndf_last_16 &lt;- df %&gt;% \n  select(tail(names(df), 16)) %&gt;%\n  rename_with(~ gsub(\"Extra_Column_\", \"Col_\", .x)) \n\nkwtest_stats_table &lt;- df_last_16 %&gt;%\n  select(Col_1:Col_15, Heart_Attack_Occurrence) %&gt;%\n  tbl_summary(\n    by = Heart_Attack_Occurrence,\n    statistic = list(all_continuous() ~ \"{mean} ({sd})\"),\n    missing = \"no\"\n  ) %&gt;%\n  add_p(\n    test = list(all_continuous() ~ \"kruskal.test\")\n  ) %&gt;%\n  add_overall() %&gt;%\n  modify_header(label = \"**Variable**\") %&gt;%\n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**By Outcome**\")\n\n\n\n\nRemoving the 15 columns\nnew_df &lt;- df[, 1:(ncol(df) - 15)]",
    "crumbs": [
      "Exercise 01"
    ]
  },
  {
    "objectID": "take-home/exercise01.html#summary-of-initial-data-checks",
    "href": "take-home/exercise01.html#summary-of-initial-data-checks",
    "title": "Exercise 01 - Heart Attack In Japan",
    "section": "3.2 Summary of Initial Data Checks",
    "text": "3.2 Summary of Initial Data Checks\n\n\nEDA\nna_counts &lt;- colSums(is.na(df)) # Check for missing values\nnum_report &lt;- ExpNumViz(new_df, \n          Page = c(2,4))\ncat_report &lt;- ExpCatViz(new_df,\n                        Page = c(2,5))\n\n\n\n\nEDA with target variable\nnum_w_target_report &lt;- ExpNumViz(new_df, target=\"Heart_Attack_Occurrence\",\n                                 scatter=TRUE,\n                                 fname=NULL,\n                                 Page=c(3, 1))\nnum_w_target_report2 &lt;- ExpNumViz(new_df, target=\"Heart_Attack_Occurrence\",\n                                 fname=NULL,\n                                 Page=c(1, 2))\ncat_w_target_report &lt;-ExpCatViz(new_df,\n                                target = \"Heart_Attack_Occurrence\",\n                                Page = c(1, 2))\n\n\nThe code blocks above are the initial EDA tests ran. The insights are as follows:\n\nDistribution of Variables: Most numerical variables exhibit normal distribution patterns. Age stands out as an exception, showing a uniform distribution across the sample.\nHeart Attack Incidence: A relatively small proportion (10%) of participants reported experiencing a heart attack.\nDemographic Characteristics: Gender representation is nearly balanced in the sample. Majority of the respondents (70%) were from the Urban region.\nRelationship Between Variables and Heart Attack Occurrence:\n\nCorrelation Analysis: Scatter plots reveal no apparent correlations between pairs of numerical variables.\nDistribution Comparison: Boxplot analysis shows substantial overlap in the distributions of numerical variables between those who experienced heart attacks and those who did not, indicating no clear distinctions based on these variables alone.",
    "crumbs": [
      "Exercise 01"
    ]
  },
  {
    "objectID": "take-home/exercise01.html#binning-numerical-variables",
    "href": "take-home/exercise01.html#binning-numerical-variables",
    "title": "Exercise 01 - Heart Attack In Japan",
    "section": "3.3 Binning Numerical Variables",
    "text": "3.3 Binning Numerical Variables\nThe intent of binning numerical variables is to obtain more interpretable odds ratios when modeling.\nThe bins are as follows:\n\nAge: The age variable is divided into 12 categories, spanning from 18 to 80 years old, with 5-year intervals (e.g., 18-24, 25-29, 30-34, etc.).\nBMI (Body Mass Index): BMI is categorized into four groups based on standard classifications [2]:\n\n\nUnderweight: Less than 18.5\nNormal: 18.5 to less than 25\nPre-Obese: 25 to 30\nObese: 30 or greater\n\n\nCholesterol: Cholesterol levels are grouped into three categories [4]:\n\nLow: Less than 120 mg/dL\nNormal: 120 to less than 219 mg/dL\nHigh: 219 mg/dL or greater\n\nStress: Stress levels are divided into five categories based on a 0-10 scale:\n\nVery Low: 0 to 2\nLow: 2 to 4\nModerate: 4 to 6\nHigh: 6 to 8\nVery High: 8 to 10\n\nHeart Rate: Heart rate is categorized into eight groups, with 10 beats per minute intervals, ranging from less than 40 to 110 beats per minute.\nBlood Pressure: Blood pressure grades are categorized according to [3].\n\n\n\nBinning variables and transforming to factors\nage_breaks &lt;- c(18, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80)\nage_labels &lt;- c(\"18-24\", \"25-29\", \"30-34\", \"35-39\", \"40-44\", \"45-49\", \n                \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\", \"75-79\")\nbmi_breaks &lt;- c(-Inf, 18.5, 25, 30, Inf) \nbmi_labels &lt;- c(\"Underweight (&lt;18.5)\", \"Normal (18.5 to &lt;25)\", \"Pre-Obese (25 to 30)\", \"Obese (‚â•30)\")\n\ncholesterol_breaks &lt;- c(0, 120, 219, Inf)\ncholesterol_labels &lt;- c(\"Low (&lt;120)\", \"Normal (120 to &lt;219)\", \"High (‚â•219)\")\n\nstress_breaks &lt;- c(-Inf, 2, 4, 6, 8, Inf)\nstress_labels &lt;- c(\"Very Low (0-2)\", \"Low (2-4)\", \"Moderate (4-6)\", \"High (6-8)\", \"Very High (8-10)\")\n\nheart_rate_breaks &lt;- c(30, 40, 50, 60, 70, 80, 90, 100, 110)\nheart_rate_labels &lt;- c(\"&lt;40\", \"40-&lt;50\", \"50-&lt;60\", \"60-&lt;70\", \"70-&lt;80\", \"80-&lt;90\", \"90-&lt;100\", \"100-&lt;110\")\n\nbp_labels &lt;- c(\"Normal\", \"High-Normal\", \"Elevated\", \"Hypertension Grade I\", \n               \"Hypertension Grade II\", \"Hypertension (Isolated) Systolic\", \"Hypertension Grade III\")\n\nnew_df2 &lt;- new_df %&gt;%\n  mutate(\n    Age_Group = cut(Age, breaks = age_breaks, labels = age_labels, right = FALSE),\n    across(c(Smoking_History, Diabetes_History, Hypertension_History,\n             Family_History, Heart_Attack_Occurrence), .fns = ~+(.x == \"Yes\")),  # Change from Yes No to 1, 0\n    # Convert other category to factors\n    Physical_Activity = factor(Physical_Activity, levels = c(\"Low\", \"Moderate\", \"High\")),\n    Diet_Quality = factor(Diet_Quality, levels = c(\"Poor\", \"Average\", \"Good\")),\n    Alcohol_Consumption = factor(Alcohol_Consumption, levels = c(\"None\", \"Low\", \"Moderate\", \"High\")),\n    # Numerical variables to binned groups\n    Age_Group = factor(Age_Group),\n    BMI_Group = cut(BMI, breaks = bmi_breaks, labels = bmi_labels, right = FALSE), \n    BMI_Group = factor(BMI_Group, levels = bmi_labels),\n    Blood_Pressure = case_when(\n      Systolic_BP &gt;= 180 | Diastolic_BP &gt;= 110 ~ \"Hypertension Grade III\",\n      Systolic_BP &gt;= 140 & Diastolic_BP &lt; 90 ~ \"Hypertension (Isolated) Systolic\",\n      (Systolic_BP &gt;= 160 & Systolic_BP &lt;= 179) | (Diastolic_BP &gt;= 100 & Diastolic_BP &lt;= 109) ~ \"Hypertension Grade II\",\n      (Systolic_BP &gt;= 140 & Systolic_BP &lt;= 159) | (Diastolic_BP &gt;= 90 & Diastolic_BP &lt;= 99) ~ \"Hypertension Grade I\",\n      (Systolic_BP &gt;= 130 & Systolic_BP &lt;= 139) | (Diastolic_BP &gt;= 80 & Diastolic_BP &lt;= 89) ~ \"Elevated\",\n      Systolic_BP &gt;= 120 & Systolic_BP &lt;= 129 & Diastolic_BP &lt; 80 ~ \"High-Normal\",\n      Systolic_BP &lt; 120 & Diastolic_BP &lt; 80 ~ \"Normal\",\n      TRUE ~ NA_character_  # Default for any values that don't match the above conditions\n    ),\n    Blood_Pressure = factor(Blood_Pressure, levels = bp_labels),\n    Cholesterol = cut(Cholesterol_Level, breaks = cholesterol_breaks, labels = cholesterol_labels, right = FALSE),\n    Cholesterol = factor(Cholesterol, levels = cholesterol_labels),\n    Stress = cut(Stress_Levels, breaks = stress_breaks, labels = stress_labels, right = FALSE),\n    Stress = factor(Stress, levels = stress_labels),\n    Heart_Rate_Group = cut(Heart_Rate, breaks = heart_rate_breaks, labels = heart_rate_labels, right = FALSE),\n    Heart_Rate_Group = factor(Heart_Rate_Group, levels = heart_rate_labels)\n  )",
    "crumbs": [
      "Exercise 01"
    ]
  },
  {
    "objectID": "take-home/exercise01.html#final-description-of-the-features",
    "href": "take-home/exercise01.html#final-description-of-the-features",
    "title": "Exercise 01 - Heart Attack In Japan",
    "section": "3.4 Final Description of the Features",
    "text": "3.4 Final Description of the Features\n\n\n\n\n\n\n\n\n\nGroup*\nSubgroup\nName\nDescription\n\n\n\n\nU\nDemographics\nAge\nRange from 18 - 79\n\n\nU\nDemographics\nAge Group\nBinned age in intervals of 5, with the exception of 18-24\n\n\nU\nDemographics\nGender\nMale, Female\n\n\nU\nDemographics\nRegion\nUrban, Rural\n\n\nU\nMedical History\nSmoking History\nYes, No\n\n\nU\nMedical History\nDiabetes History\nYes, No\n\n\nU\nMedical History\nHypertension History\nYes, No\n\n\nU\nMedical History\nFamily History\nYes, No\n\n\nM\nLifestyle & Behavioral Factors\nPhysical Activity\nModerate, Low, High\n\n\nM\nLifestyle & Behavioral Factors\nDiet Quality\nPoor, Good, Average\n\n\nM\nLifestyle & Behavioral Factors\nAlcohol Consumption\nNone, Low, Moderate, High\n\n\nM\nPhysical and Medical Indicators\nBMI\nRange from 5.5 - 46.1\n\n\nM\nPhysical and Medical Indicators\nBMI Group\nBinned BMI according to [2]\n\n\nM\nPhysical and Medical Indicators\nHeart Rate\nRange from 30 - 110\n\n\nM\nPhysical and Medical Indicators\nHeart Rate Group\nBinned by intervals of 10\n\n\nM\nPhysical and Medical Indicators\nCholesterol Level\nRange from 80 - 337\n\n\nM\nPhysical and Medical Indicators\nCholesterol\nBinned as Low, Normal, and High according to [4]\n\n\nM\nPhysical and Medical Indicators\nSystolic BP\nRange from 56 - 179\n\n\nM\nPhysical and Medical Indicators\nDiastolic BP\nRange from 39 - 118\n\n\nM\nPhysical and Medical Indicators\nBlood Pressure\nBinned according to [3] using systolic and diastolic BP\n\n\nM\nPhysical and Medical Indicators\nStress Levels\nRange from 0 - 10\n\n\nM\nPhysical and Medical Indicators\nStress\nBinned by intervals of 2 points\n\n\nO\n\nHeart Attack Occurrence\nYes, No\n\n\n\n*U: Uncontrolled Factors, M: Modifiable Factors, O: Outcome",
    "crumbs": [
      "Exercise 01"
    ]
  },
  {
    "objectID": "take-home/exercise01.html#references-1",
    "href": "take-home/exercise01.html#references-1",
    "title": "Exercise 01 - Heart Attack In Japan",
    "section": "3.5 References",
    "text": "3.5 References\n\nA machine learning approach for classifying healthy and infarcted patients using heart rate variabilities derived vector magnitude\nJSH 2019 Office Guidelines\nKey Points of the 2019 Japanese Society of Hypertension Guidelines for the Management of Hypertension\nTotal Cholesterol Range",
    "crumbs": [
      "Exercise 01"
    ]
  },
  {
    "objectID": "take-home/exercise01.html#how-do-age-and-gender-shape-heart-attack-risk",
    "href": "take-home/exercise01.html#how-do-age-and-gender-shape-heart-attack-risk",
    "title": "Exercise 01 - Heart Attack In Japan",
    "section": "4.1 How Do Age and Gender Shape Heart Attack Risk?",
    "text": "4.1 How Do Age and Gender Shape Heart Attack Risk?\n\n\nConverting japan population data\njapan_pop &lt;- read_csv('data/japan_pop_2023.csv')\n\n# Find the row where Age == \"15 - 19\"\nage_15_19 &lt;- japan_pop %&gt;% filter(Age == \"15-19\")\n\n# Calculate the adjusted counts for ages 18 and 19\nadjusted_M &lt;- (age_15_19$M / 5) * 2\nadjusted_F &lt;- (age_15_19$F / 5) * 2\n\njapan_pop &lt;- japan_pop %&gt;%\n  # Find the row where Age == \"20 - 24\" and add the adjusted counts\n  mutate(\n    M = ifelse(Age == \"20-24\", M + adjusted_M, M),\n    F = ifelse(Age == \"20-24\", F + adjusted_F, F)\n  ) %&gt;%\n  # Change the Age value for \"20-24\" to \"18-24\"\n  mutate(\n    Age = ifelse(Age == \"20-24\", \"18-24\", Age)) %&gt;% \n  filter(Age %in% age_labels)\n\njapan_pop &lt;- japan_pop %&gt;%\n  pivot_longer(cols = c(M, F), names_to = \"Gender\", values_to = \"Count\") %&gt;%\n  mutate(Proportion = Count / sum(Count)) %&gt;%\n  mutate(Age = factor(Age, levels=age_labels),\n         Gender = factor(Gender)) %&gt;%\n  mutate(\n      percent = round(100*(Count / sum(Count, na.rm=T)),1),  # calculate % of total for age-gender groups\n      percent = case_when(                                     # convert % to negative if male\n        Gender == \"F\" ~ percent,\n        Gender == \"M\" ~ -percent,\n        TRUE          ~ NA_real_),\n      Gender = factor(Gender, levels=c(\"F\", \"M\"))\n    ) %&gt;%\n  arrange(Age, Gender)\n\n\n\n\nData conversion for plotting the pyramid plot\nconvert_to_pyramid_data &lt;- function(df) {\n\n  df %&gt;% \n    count(Age_Group, Gender, name = \"counts\") %&gt;%  # counts by age-gender groups\n    ungroup() %&gt;% \n    mutate(\n      percent = round(100*(counts / sum(counts, na.rm=T)),1),  # calculate % of total for age-gender groups\n      percent = case_when(                                     # convert % to negative if male\n        Gender == \"Female\" ~ percent,\n        Gender == \"Male\" ~ -percent,\n        TRUE          ~ NA_real_)\n    )\n}\n\npop_data &lt;- convert_to_pyramid_data(new_df2)\nha_data &lt;- convert_to_pyramid_data(new_df2 %&gt;% filter(Heart_Attack_Occurrence == 1))\npyramid_data &lt;- bind_rows(\"cases\" = ha_data, \"population\" = pop_data, .id = \"data_source\")\n\n\n\n\nPlotting the two age-sex pyramid\nmax_per &lt;- max(pyramid_data$percent, na.rm=T)\nmin_per &lt;- min(pyramid_data$percent, na.rm=T)\n\n# The japan population data\np1 &lt;- ggplot() + \n  geom_col(\n    data = japan_pop,\n    mapping = aes(\n      x = Age,\n      y = percent,\n      fill = Gender),\n    colour = \"black\",                             \n    width = 1)  +\n  coord_flip()+\n  scale_x_discrete(limits = age_labels) +\n  scale_fill_manual(\n    values = c(\"F\" = \"#d0839a\",\n               \"M\" = \"#8cb8c5\"),\n    labels = c(\"F\" = \"Female\",\n               \"M\"= \"Male\"),\n  ) +\n    scale_y_continuous(\n    limits = c(min_per, max_per),                                         \n    breaks = seq(floor(min_per), ceiling(max_per), by = 2),                \n    labels = paste0(                                                      \n              abs(seq(floor(min_per), ceiling(max_per), by = 2)), \"%\")) +\n  labs(\n    subtitle = \"Age and gender distribution of Japan population\",\n    x = \"Percentage of Total (%)\"\n  ) +   theme(legend.position = \"none\",\n        axis.title.y = element_blank(),\n        # optional aesthetic themes                    \n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.background = element_blank(),\n    axis.line = element_line(colour = \"black\"),\n    plot.title = element_text(hjust = 0), \n    plot.caption = element_text(hjust=0, size=11, face = \"italic\"))\n  \np2 &lt;- ggplot() + \n  geom_col(\n    data = pop_data,\n    mapping = aes(\n      x = Age_Group,\n      y = percent,\n      fill = Gender),\n    colour = \"black\",                             \n    width = 1)  +\n  coord_flip()+\n  scale_x_discrete(limits = age_labels) +\n  scale_fill_manual(\n    values = c(\"Female\" = \"#d0839a\",\n               \"Male\" = \"#8cb8c5\"),\n    labels = c(\"Female\" = \"Female\",\n               \"Male\"= \"Male\"),\n  ) +\n    scale_y_continuous(\n    limits = c(min_per, max_per),                                         \n    breaks = seq(floor(min_per), ceiling(max_per), by = 2),                \n    labels = paste0(                                                      \n              abs(seq(floor(min_per), ceiling(max_per), by = 2)), \"%\")) +\n  labs(\n    subtitle = \"Age and gender distribution of sample\",\n    x = \"Percentage of Total (%)\") + \n  theme(legend.position = \"none\",\n        axis.title.y = element_blank(),\n        # optional aesthetic themes                    \n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.background = element_blank(),\n    axis.line = element_line(colour = \"black\"),\n    plot.title = element_text(hjust = 0), \n    plot.caption = element_text(hjust=0, size=11, face = \"italic\"))\n\n\n\n\nWeighting the percentage based on the japan population\nweights &lt;- japan_pop$percent/pop_data$percent \npop_data$weighted_pct &lt;- pop_data$percent * weights\nha_data$weighted_pct &lt;- ha_data$percent * weights\n\npyramid_data &lt;- bind_rows(\"cases\" = ha_data, \"population\" = pop_data, .id = \"data_source\")\n\n\n\n\nPlotting the entire age-sex pyramid\n# From here https://epirhandbook.com/en/new_pages/age_pyramid.html \n\np3 &lt;- ggplot()+  \n  geom_col(\n    data = pyramid_data %&gt;% filter(data_source == \"population\"),\n    mapping = aes(\n      x = Age_Group,\n      y = weighted_pct,\n      fill = Gender),\n    colour = \"black\",                               # black color around bars\n    alpha = 0.2,                                    # more transparent\n    width = 1)+                                     # full width\n  \n  geom_col(\n    data = pyramid_data %&gt;% filter(data_source == \"cases\"), \n    mapping = aes(\n      x = Age_Group,                               # age categories as original X axis\n      y = weighted_pct,                                # % as original Y-axis\n      fill = Gender),                             # fill of bars by gender\n    colour = \"black\",                               # black color around bars\n    alpha = 1,                                      # not transparent \n    width = 0.3)+                                   # half width\n\n  coord_flip()+\n  scale_x_discrete(limits = age_labels) +\n  scale_y_continuous(\n    limits = c(min_per, max_per),                                         \n    breaks = seq(floor(min_per), ceiling(max_per), by = 2),              \n    labels = paste0(                                                     \n              abs(seq(floor(min_per), ceiling(max_per), by = 2)), \"%\"))+                                                  \n\n  # designate colors and legend labels manually\n  scale_fill_manual(\n    values = c(\"Female\" = \"#d0839a\",\n               \"Male\" = \"#8cb8c5\"),\n    labels = c(\"Female\" = \"Female\",\n               \"Male\"= \"Male\"), \n  ) +\n  \n  # plot labels, titles, caption    \n  labs(\n    title = \"Age and gender distribution of respondents with heart attack,\\nas compared to baseline population\",\n    subtitle = \"The age and gender distribution has been weighted based on the Japan population\",\n    x = \"Age Category\",\n    y = \"Weighted Percentage of Total (%)\",\n    fill = NULL,\n    caption = stringr::str_glue(\"Cases shown on top of adjusted sample demographic baseline\\nData from Kaggle, n = {nrow(df)}\")) +\n  \n  # optional aesthetic themes\n  theme(\n    legend.position = \"bottom\",                             # move legend to bottom\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.background = element_blank(),\n    axis.line = element_line(colour = \"black\"),\n    plot.title = element_text(hjust = 0), \n    plot.caption = element_text(hjust=0, size=11, face = \"italic\"))\n\n(p1+p2)/p3 + plot_layout(heights = c(3, 7))\n\n\n\n\n\n\n\n\n\nThis visualization presents a comparative analysis of age and gender distributions across three different populations:\n\nJapan‚Äôs General Population (Top-left)\n\nShows the natural age and gender distribution in Japan.\nMales and females are represented by different colors.\n\nStudy Sample Distribution (Top-right)\n\nRepresents the age and gender composition of the dataset used for analysis.\nHelps assess how well the sample represents the actual Japanese population.\n\nHeart Attack Cases (Bottom Panel, Weighted by Japan‚Äôs Population)\n\nIllustrates the age and gender distribution of individuals who reported heart attack occurrences.\nBars in the background represent the adjusted (based on population distributed) baseline sample distribution\nThe darker bars show the proportion of heart attack cases, allowing for direct comparison - if the bars are outside the baseline, means this group has larger representation in the heart attack cases.\n\n\nThe key observations are:\n\nHigher Heart Attack Incidence in Older Age Groups: The proportion of heart attack cases increases with age, especially in individuals aged 50 and above.\nGender Differences:\n\nMales have a higher representation in heart attack cases compared to females in most age groups.\nThis pattern aligns with existing medical research suggesting that men are at a higher risk of cardiovascular diseases at younger ages.\n\nLower Incidence in Younger Groups:\n\nThe 18-29 age group has the lowest proportion of heart attack cases, aligning with the expected lower risk for younger individuals.\n\nSample Representativeness:\n\nThe sample (top-right) appears to be well-distributed compared to the general Japanese population (top-left), suggesting that findings may be broadly applicable.",
    "crumbs": [
      "Exercise 01"
    ]
  },
  {
    "objectID": "take-home/exercise01.html#does-your-medical-history-decide-your-heart-attack-risk",
    "href": "take-home/exercise01.html#does-your-medical-history-decide-your-heart-attack-risk",
    "title": "Exercise 01 - Heart Attack In Japan",
    "section": "4.2 Does Your Medical History Decide Your Heart Attack Risk?",
    "text": "4.2 Does Your Medical History Decide Your Heart Attack Risk?\n\n\nCreating the combination plot\nmean_proportion &lt;- mean(new_df2$Heart_Attack_Occurrence, na.rm = TRUE)\nmean_BMI &lt;- mean(new_df2$BMI, na.rm = TRUE)\nnew_df2$Heart_Attack_Occurrence2 &lt;- factor(new_df2$Heart_Attack_Occurrence, levels = c(\"0\", \"1\"))\n\np &lt;- ComplexUpset::upset(new_df2, \n    c(\"Smoking_History\", \"Diabetes_History\", \"Hypertension_History\", \"Family_History\"), \n    name='Medical History',\n    base_annotations=list(\n        'Intersection size'=intersection_size()\n    ),\n    annotations = list(\n        'Heart Attack Occurrence'=list(\n            aes = aes(x = intersection, fill = Heart_Attack_Occurrence2),\n            geom = list(\n                geom_bar(stat = 'count', position = 'fill', na.rm = TRUE),\n                geom_hline(yintercept = mean_proportion, linetype = \"dashed\", color = \"black\"),\n                annotate(\"text\", x = Inf, y = mean_proportion, \n         label = sprintf(\"%.2f\", mean_proportion*100),  # Annotate with a % at the end. \n         hjust = 1.4, vjust = -0.5, color = \"black\", size = 3),\n                scale_fill_manual(\n                    name = \"Heart Attack\",\n                    values = c(\"0\" = alpha(\"#e7a43b\", 0.8), \"1\" = \"#e72222\"),  \n                    labels = c(\"1\" = \"Yes\", \"0\" = \"No\")\n                ),\n          geom_text(\n                    aes(\n                        label=!!aes_percentage(relative_to='intersection'),\n                        group=Heart_Attack_Occurrence2\n                    ),\n                    stat='count',\n                    position=position_fill(vjust = .5)\n                ),\n                scale_y_continuous(labels=scales::percent_format())\n            ))\n    ),\n    width_ratio = 0.1,\n    wrap=TRUE\n) + ggtitle(\"Impact of Medical History on Heart Attack Occurrence: An Upset and Proportional Analysis\")\n\np\n\n\n\n\n\n\n\n\n\nThis visualization consists of two key components:\n\nStacked Bar Plot (Top Panel) ‚Äì Heart Attack Occurrence by Medical History Intersection:\n\nEach bar represents a specific combination of medical history factors (Smoking, Family History, Hypertension, Diabetes). The red portion (percentage labeled) represents individuals who experienced a heart attack, while the orange portion represents those who did not.\nThe proportion of heart attack occurrences ranges from 9% to 14%, indicating that certain medical history combinations are associated with a higher likelihood of heart attacks.\nThe highest risk categories (12‚Äì14% heart attack rate) involve individuals with multiple conditions, such as hypertension, diabetes, and smoking history.\n\n\n\n\nUpset Plot (Bottom Panel) ‚Äì Medical History Combinations and Frequencies:\n\nThe bar heights indicate the number of individuals in each medical history category.\nThe largest group (8,791 individuals) has no recorded medical history of these conditions.\nOther major groups include individuals with family history, hypertension, and smoking history in different combinations.\nThe dots below the bars indicate the specific medical conditions present in each group, with multiple black dots showing co-occurring risk factors.\nGroups with three or more risk factors have fewer individuals but show higher heart attack rates, reinforcing the cumulative effect of these conditions.\n\n\nIndividuals with multiple risk factors (e.g., smoking + hypertension + diabetes) are at higher risk of heart attacks compared to the average. Preventive measures should focus on individuals with multiple risk factors, as they represent the highest-risk categories.",
    "crumbs": [
      "Exercise 01"
    ]
  },
  {
    "objectID": "take-home/exercise01.html#how-do-uncontrollable-factors-interact-in-determining-your-heart-attack-risk",
    "href": "take-home/exercise01.html#how-do-uncontrollable-factors-interact-in-determining-your-heart-attack-risk",
    "title": "Exercise 01 - Heart Attack In Japan",
    "section": "4.3 How Do Uncontrollable Factors Interact in Determining Your Heart Attack Risk?",
    "text": "4.3 How Do Uncontrollable Factors Interact in Determining Your Heart Attack Risk?\n\n\nUnivariate regression\nuniv_tab &lt;- tbl_uvregression(\n    new_df2,\n    method = glm,                           ## define regression want to run (generalised linear model)\n    y = Heart_Attack_Occurrence,   \n    include = c(\n  \"Age_Group\", \"Gender\", \"Region\", \n  \"Smoking_History\", \"Diabetes_History\",\n  \"Hypertension_History\", \"Family_History\"),\n    method.args = list(family = binomial),  ## define what type of glm want to run (logistic)\n    exponentiate = TRUE                     ## exponentiate to produce odds ratios (rather than log odds)\n  )\n\n\n\n\nMultivariate regression\nexplanatory_vars &lt;- c(\n  \"Age_Group\", \"Gender\", \"Region\", \"Smoking_History\", \"Diabetes_History\",\n  \"Hypertension_History\", \"Family_History\")\n\nmv_reg &lt;- explanatory_vars %&gt;%  ## begin with vector of explanatory column names\n  str_c(collapse = \"+\") %&gt;%     ## combine all names of the variables of interest separated by a plus\n  str_c(\"Heart_Attack_Occurrence ~ \", .) %&gt;%    ## combine the names of variables of interest with outcome in formula style\n  glm(family = \"binomial\",      ## define type of glm as logistic,\n      data = new_df2)          ## define your dataset\n\nfinal_mv_reg &lt;- mv_reg %&gt;%\n  step(direction = \"forward\", trace = FALSE)\n\nmv_tab &lt;- tbl_regression(final_mv_reg, exponentiate = TRUE)\n\n\n\n\nMerge regression results\ntbl_merge(\n  tbls = list(univ_tab, mv_tab),                          # combine\n  tab_spanner = c(\"**Univariate**\", \"**Multivariate**\")) # set header names\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nUnivariate\n\n\nMultivariate\n\n\n\nN\nOR1\n95% CI1\np-value\nOR1\n95% CI1\np-value\n\n\n\n\nAge_Group\n30,000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†18-24\n\n\n‚Äî\n‚Äî\n\n\n‚Äî\n‚Äî\n\n\n\n\n¬†¬†¬†¬†25-29\n\n\n0.98\n0.81, 1.17\n0.8\n0.98\n0.81, 1.17\n0.8\n\n\n¬†¬†¬†¬†30-34\n\n\n1.14\n0.96, 1.35\n0.14\n1.14\n0.96, 1.36\n0.14\n\n\n¬†¬†¬†¬†35-39\n\n\n1.22\n1.03, 1.45\n0.023\n1.22\n1.03, 1.45\n0.023\n\n\n¬†¬†¬†¬†40-44\n\n\n1.16\n0.97, 1.38\n0.10\n1.16\n0.97, 1.38\n0.10\n\n\n¬†¬†¬†¬†45-49\n\n\n0.96\n0.80, 1.15\n0.6\n0.96\n0.79, 1.15\n0.6\n\n\n¬†¬†¬†¬†50-54\n\n\n1.17\n0.98, 1.40\n0.081\n1.17\n0.98, 1.39\n0.084\n\n\n¬†¬†¬†¬†55-59\n\n\n1.16\n0.97, 1.38\n0.11\n1.16\n0.97, 1.38\n0.11\n\n\n¬†¬†¬†¬†60-64\n\n\n1.14\n0.95, 1.36\n0.15\n1.14\n0.95, 1.36\n0.15\n\n\n¬†¬†¬†¬†65-69\n\n\n0.97\n0.81, 1.16\n0.7\n0.97\n0.81, 1.16\n0.7\n\n\n¬†¬†¬†¬†70-74\n\n\n1.07\n0.89, 1.28\n0.5\n1.07\n0.90, 1.28\n0.5\n\n\n¬†¬†¬†¬†75-79\n\n\n1.18\n0.99, 1.40\n0.067\n1.18\n0.99, 1.41\n0.064\n\n\nGender\n30,000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†Female\n\n\n‚Äî\n‚Äî\n\n\n‚Äî\n‚Äî\n\n\n\n\n¬†¬†¬†¬†Male\n\n\n1.07\n0.99, 1.16\n0.073\n1.07\n0.99, 1.16\n0.070\n\n\nRegion\n30,000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†Rural\n\n\n‚Äî\n‚Äî\n\n\n‚Äî\n‚Äî\n\n\n\n\n¬†¬†¬†¬†Urban\n\n\n1.00\n0.92, 1.09\n&gt;0.9\n1.00\n0.92, 1.09\n&gt;0.9\n\n\nSmoking_History\n30,000\n1.05\n0.97, 1.14\n0.2\n1.05\n0.97, 1.14\n0.2\n\n\nDiabetes_History\n30,000\n1.06\n0.97, 1.17\n0.2\n1.07\n0.97, 1.17\n0.2\n\n\nHypertension_History\n30,000\n1.03\n0.94, 1.12\n0.5\n1.03\n0.94, 1.12\n0.5\n\n\nFamily_History\n30,000\n0.99\n0.91, 1.08\n0.8\n0.99\n0.91, 1.07\n0.8\n\n\n\n1 OR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\nThe table presents the odds ratios and confidence intervals for various factors associated with heart attack occurrence, comparing results from univariate and multivariate logistic regression models. The odds ratios remain largely unchanged between the two models, indicating that there is minimal confounding among the included variables. This suggests that each factor‚Äîsuch as age group, smoking history, hypertension, diabetes, and family history‚Äîcontributes independently to heart attack risk rather than being strongly influenced by other factors in the model. Notably, only the 35-39 age group shows a significantly higher risk, while the other factors do not exhibit statistically significant associations. Further analyses, such as interaction tests, may be needed to explore potential combined effects between variables.\n\n\nRegression coefficients\nfinal_mv_reg %&gt;% \n  model_parameters(exponentiate = TRUE) %&gt;% \n  plot() +\n  labs(title = \"Odds Ratio of Heart Attack Occurrence (Multivariate Model)\") +\n  scale_color_manual(values=c(\"#e72222\", \"#8cb8c5\"))\n\n\n\n\n\n\n\n\n\nThis plot presents the odds ratio of heart attack occurrence, derived from a logistic regression model. In logistic regression, the coefficients represent the log-odds of an event occurring (in this case, a heart attack), and when exponentiated, they translate into odds ratios (ORs). An odds ratio above 1 indicates an increased risk, while an odds ratio below 1 suggests a reduced risk.\nEach point represents the estimated odds ratio for a given variable, with the horizontal bars denoting the confidence intervals. If a confidence interval crosses the vertical dashed line at 1.00 (the null value), it suggests that the effect is not statistically significant.\n\nThe age group 35-39 is the only category with a significantly higher risk of heart attack, as indicated by its confidence interval not crossing 1.\nOther age groups show varying odds ratios, but their confidence intervals include 1, suggesting no strong evidence of increased risk.\nSimilarly, gender, urban/rural region, and medical history factors such as smoking, diabetes, hypertension, and family history exhibit varying effects, but none are statistically significant.\n\nDespite variations in odds ratios across age groups and medical history factors, the only statistically significant predictor of increased heart attack risk in this model is being in the 35-39 age group. Other factors may still contribute to risk, but this model does not find strong enough evidence to confirm their impact.\n\n\nModel Diagnostic\ncheck_model(final_mv_reg)\n\n\n\n\n\n\n\n\n\n\nPosterior Predictive Check: Observed and model-predicted data align well, indicating good overall fit.\nBinned Residuals: Several residuals fall outside error bounds, particularly between 10%‚Äì11% predicted probabilities, suggesting model miscalibration.\nInfluential Observations: All the points are within the contour lines.\nCollinearity: All predictors have VIF values below 5, ruling out multicollinearity concerns.\nUniformity of Residuals: Residuals follow the expected distribution, suggesting no significant pattern in errors.\n\nThe model fits the data well but shows issues with calibration. For probability calibration, Platt scaling or isotonic regression could be considered. Model could be refined by adding interaction or polynomial terms.",
    "crumbs": [
      "Exercise 01"
    ]
  },
  {
    "objectID": "take-home/exercise01.html#does-your-behavioural-and-lifestyle-factors-influence-your-medical-indicators",
    "href": "take-home/exercise01.html#does-your-behavioural-and-lifestyle-factors-influence-your-medical-indicators",
    "title": "Exercise 01 - Heart Attack In Japan",
    "section": "4.4 Does Your Behavioural and Lifestyle Factors Influence Your Medical Indicators?",
    "text": "4.4 Does Your Behavioural and Lifestyle Factors Influence Your Medical Indicators?\n\n\nPhysical Activity VS Numerical Values\np1 &lt;- ggbetweenstats(new_df2,\n                    x = Physical_Activity,\n                    y = BMI,\n                    pairwise.comparisons = TRUE, \n                    title = \"Physical Activity VS BMI\")\np2 &lt;- ggbetweenstats(new_df2,\n                    x = Physical_Activity,\n                    y = Stress_Levels,\n                    pairwise.comparisons = TRUE, \n                    title = \"Physical Activity VS Stress Levels\")\np3 &lt;- ggbetweenstats(new_df2,\n                    x = Physical_Activity,\n                    y = Heart_Rate,\n                    pairwise.comparisons = TRUE, \n                    title = \"Physical Activity VS Heart Rate\")\np4 &lt;- ggbetweenstats(new_df2,\n                    x = Physical_Activity,\n                    y = Cholesterol_Level,\n                    pairwise.comparisons = TRUE, \n                    title = \"Physical Activity VS Cholesterol\")\np5 &lt;- ggbetweenstats(new_df2,\n                    x = Physical_Activity,\n                    y = Systolic_BP,\n                    pairwise.comparisons = TRUE, \n                    title = \"Physical Activity VS Systolic BP\")\np6 &lt;- ggbetweenstats(new_df2,\n                    x = Physical_Activity,\n                    y = Diastolic_BP,\n                    pairwise.comparisons = TRUE, \n                    title = \"Physical Activity VS Diastolic BP\")\n\n\n\n\nPhysical Activity VS Numerical Factors\n(p1 + p2)/(p3 + p4)/(p5 + p6)\n\n\n\n\n\n\n\n\n\n\nBMI: No significant difference across activity levels (p = 0.61), with mean BMIs around 25.\nStress Levels: No significant effect of physical activity (p = 0.29), stress averages ~5.\nHeart Rate: Minimal difference between groups (p = 0.36), with means around 70 bpm.\nCholesterol Levels: No significant variation by activity level (p = 0.64), averages ~200 mg/dL.\nSystolic Blood Pressure (BP): No effect of activity on systolic BP (p = 0.91), means ~119 mmHg.\nDiastolic Blood Pressure (BP): Slightly lower diastolic BP with higher activity (p = 0.03), but differences are small (79.96 to 79.21 mmHg).\n\nPhysical activity has minimal impact on these health metrics, with only a minor difference in diastolic BP. Other metrics show no significant differences.\n\n\nDiet Quality VS Numerical Values\npd1 &lt;- ggbetweenstats(new_df2,\n                    x = Diet_Quality,\n                    y = BMI,\n                    pairwise.comparisons = TRUE, \n                    title = \"Diet Quality VS BMI\")\npd2 &lt;- ggbetweenstats(new_df2,\n                    x = Diet_Quality,\n                    y = Stress_Levels,\n                    pairwise.comparisons = TRUE, \n                    title = \"Diet Quality VS Stress Levels\")\npd3 &lt;- ggbetweenstats(new_df2,\n                    x = Diet_Quality,\n                    y = Heart_Rate,\n                    pairwise.comparisons = TRUE, \n                    title = \"Diet Quality VS Heart Rate\")\npd4 &lt;- ggbetweenstats(new_df2,\n                    x = Diet_Quality,\n                    y = Cholesterol_Level,\n                    pairwise.comparisons = TRUE, \n                    title = \"Diet Quality VS Cholesterol\")\npd5 &lt;- ggbetweenstats(new_df2,\n                    x = Diet_Quality,\n                    y = Systolic_BP,\n                    pairwise.comparisons = TRUE, \n                    title = \"Diet Quality VS Systolic BP\")\npd6 &lt;- ggbetweenstats(new_df2,\n                    x = Diet_Quality,\n                    y = Diastolic_BP,\n                    pairwise.comparisons = TRUE, \n                    title = \"Diet Quality VS Diastolic BP\")\n\n\n\n\nDiet Quality VS Numerical Factors\n(pd1 + pd2)/(pd3 + pd4)/(pd5 + pd6)\n\n\n\n\n\n\n\n\n\n\nBMI: No significant difference across diet quality levels (p = 0.54), with mean BMIs around 25.\nStress Levels: Minor differences, not significant (p = 0.50), with averages ~5.\nHeart Rate: No significant variation (p = 0.98), means ~70 bpm.\nCholesterol Levels: No significant difference (p = 0.67), averages ~200 mg/dL.\nSystolic Blood Pressure (BP): Slight variation but not significant (p = 0.16), means ~120 mmHg.\nDiastolic Blood Pressure (BP): No significant difference (p = 0.93), means ~80 mmHg.\n\nDiet quality has no significant impact on BMI, stress, heart rate, cholesterol, or blood pressure. All health metrics remain stable regardless of diet quality.\n\n\nAlcohol Consumption VS Numerical Values\npa1 &lt;- ggbetweenstats(new_df2,\n                    x = Alcohol_Consumption,\n                    y = BMI,\n                    pairwise.comparisons = TRUE, \n                    title = \"Alcohol Consumpion VS BMI\")\npa2 &lt;- ggbetweenstats(new_df2,\n                    x = Alcohol_Consumption,\n                    y = Stress_Levels,\n                    pairwise.comparisons = TRUE, \n                    title = \"Alcohol Consumpion VS Stress Levels\")\npa3 &lt;- ggbetweenstats(new_df2,\n                    x = Alcohol_Consumption,\n                    y = Heart_Rate,\n                    pairwise.comparisons = TRUE, \n                    title = \"Alcohol Consumpion VS Heart Rate\")\npa4 &lt;- ggbetweenstats(new_df2,\n                    x = Alcohol_Consumption,\n                    y = Cholesterol_Level,\n                    pairwise.comparisons = TRUE, \n                    title = \"Alcohol Consumpion VS Cholesterol\")\npa5 &lt;- ggbetweenstats(new_df2,\n                    x = Alcohol_Consumption,\n                    y = Systolic_BP,\n                    pairwise.comparisons = TRUE, \n                    title = \"Alcohol Consumpion VS Systolic BP\")\npa6 &lt;- ggbetweenstats(new_df2,\n                    x = Alcohol_Consumption,\n                    y = Diastolic_BP,\n                    pairwise.comparisons = TRUE, \n                    title = \"Alcohol Consumpion VS Diastolic BP\")\n\n\n\n\nAlcohol Consumption VS Numerical Factors\n(pa1 + pa2)/(pa3 + pa4)/(pa5 + pa6)\n\n\n\n\n\n\n\n\n\n\nBMI: No significant difference across alcohol consumption levels (p = 0.78), with mean BMIs around 25.\nStress Levels: Slight variation but not significant (p = 0.07), with stress averages around 5.\nHeart Rate: Minor differences but not significant (p = 0.09), with means around 70 bpm.\nCholesterol Levels: No significant variation (p = 0.70), average levels ~200 mg/dL.\nSystolic Blood Pressure (BP): No significant differences (p = 0.68), means ~120 mmHg.\nDiastolic Blood Pressure (BP): No significant differences (p = 0.59), means around 80 mmHg.\n\nAlcohol consumption shows no significant effect on BMI, stress, heart rate, cholesterol, or blood pressure. All metrics remain stable across consumption levels.",
    "crumbs": [
      "Exercise 01"
    ]
  },
  {
    "objectID": "take-home/exercise01.html#how-do-uncontrollable-factors-interact-in-determining-your-heart-attack-risk-1",
    "href": "take-home/exercise01.html#how-do-uncontrollable-factors-interact-in-determining-your-heart-attack-risk-1",
    "title": "Exercise 01 - Heart Attack In Japan",
    "section": "4.5 How Do Uncontrollable Factors Interact in Determining Your Heart Attack Risk?",
    "text": "4.5 How Do Uncontrollable Factors Interact in Determining Your Heart Attack Risk?\n\n\nUnivariate regression - Modifiable factors\nuniv_tab &lt;- tbl_uvregression(\n    new_df2,\n    method = glm,                           ## define regression want to run (generalised linear model)\n    y = Heart_Attack_Occurrence,   \n    include = c(\n  \"Physical_Activity\", \"Diet_Quality\",\n  \"Alcohol_Consumption\", \"BMI_Group\",\n  \"Heart_Rate_Group\", \"Blood_Pressure\",\n  \"Cholesterol\", \"Stress\"),\n    method.args = list(family = binomial),  ## define what type of glm want to run (logistic)\n    exponentiate = TRUE                     ## exponentiate to produce odds ratios (rather than log odds)\n  )\n\n\n\n\nMultivariate regression - Modifiable factors\nexplanatory_vars &lt;- c(\n  \"Physical_Activity\", \"Diet_Quality\",\n  \"Alcohol_Consumption\", \"BMI_Group\",\n  \"Heart_Rate_Group\", \"Blood_Pressure\",\n  \"Cholesterol\", \"Stress\")\n\nmv_reg &lt;- explanatory_vars %&gt;%  ## begin with vector of explanatory column names\n  str_c(collapse = \"+\") %&gt;%     ## combine all names of the variables of interest separated by a plus\n  str_c(\"Heart_Attack_Occurrence ~ \", .) %&gt;%    ## combine the names of variables of interest with outcome in formula style\n  glm(family = \"binomial\",      ## define type of glm as logistic,\n      data = new_df2)          ## define your dataset\n\nfinal_mv_reg &lt;- mv_reg %&gt;%\n  step(direction = \"forward\", trace = FALSE)\n\nmv_tab &lt;- tbl_regression(final_mv_reg, exponentiate = TRUE)\n\n\n\n\nMerge regression results - Modifiable factors\ntbl_merge(\n  tbls = list(univ_tab, mv_tab),                          # combine\n  tab_spanner = c(\"**Univariate**\", \"**Multivariate**\")) # set header names\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nUnivariate\n\n\nMultivariate\n\n\n\nN\nOR1\n95% CI1\np-value\nOR1\n95% CI1\np-value\n\n\n\n\nPhysical_Activity\n30,000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†Low\n\n\n‚Äî\n‚Äî\n\n\n‚Äî\n‚Äî\n\n\n\n\n¬†¬†¬†¬†Moderate\n\n\n1.09\n0.99, 1.20\n0.066\n1.08\n0.99, 1.19\n0.10\n\n\n¬†¬†¬†¬†High\n\n\n1.05\n0.95, 1.16\n0.3\n1.06\n0.96, 1.18\n0.2\n\n\nDiet_Quality\n30,000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†Poor\n\n\n‚Äî\n‚Äî\n\n\n‚Äî\n‚Äî\n\n\n\n\n¬†¬†¬†¬†Average\n\n\n1.04\n0.93, 1.15\n0.5\n1.04\n0.94, 1.16\n0.5\n\n\n¬†¬†¬†¬†Good\n\n\n1.06\n0.96, 1.18\n0.2\n1.07\n0.96, 1.19\n0.2\n\n\nAlcohol_Consumption\n30,000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†None\n\n\n‚Äî\n‚Äî\n\n\n‚Äî\n‚Äî\n\n\n\n\n¬†¬†¬†¬†Low\n\n\n0.98\n0.85, 1.12\n0.7\n0.97\n0.84, 1.11\n0.6\n\n\n¬†¬†¬†¬†Moderate\n\n\n0.91\n0.80, 1.04\n0.2\n0.91\n0.79, 1.04\n0.2\n\n\n¬†¬†¬†¬†High\n\n\n0.97\n0.84, 1.12\n0.6\n0.95\n0.82, 1.11\n0.5\n\n\nBMI_Group\n30,000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†Underweight (&lt;18.5)\n\n\n‚Äî\n‚Äî\n\n\n‚Äî\n‚Äî\n\n\n\n\n¬†¬†¬†¬†Normal (18.5 to &lt;25)\n\n\n1.17\n1.02, 1.35\n0.028\n1.18\n1.03, 1.37\n0.023\n\n\n¬†¬†¬†¬†Pre-Obese (25 to 30)\n\n\n1.12\n0.97, 1.30\n0.12\n1.14\n0.98, 1.32\n0.084\n\n\n¬†¬†¬†¬†Obese (‚â•30)\n\n\n0.99\n0.84, 1.16\n0.9\n0.99\n0.84, 1.17\n&gt;0.9\n\n\nHeart_Rate_Group\n30,000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†&lt;40\n\n\n‚Äî\n‚Äî\n\n\n‚Äî\n‚Äî\n\n\n\n\n¬†¬†¬†¬†40-&lt;50\n\n\n0.84\n0.35, 2.51\n0.7\n0.78\n0.32, 2.33\n0.6\n\n\n¬†¬†¬†¬†50-&lt;60\n\n\n0.98\n0.42, 2.84\n&gt;0.9\n0.94\n0.41, 2.73\n0.9\n\n\n¬†¬†¬†¬†60-&lt;70\n\n\n0.92\n0.40, 2.65\n0.9\n0.87\n0.38, 2.52\n0.8\n\n\n¬†¬†¬†¬†70-&lt;80\n\n\n1.00\n0.44, 2.90\n&gt;0.9\n0.94\n0.41, 2.74\n&gt;0.9\n\n\n¬†¬†¬†¬†80-&lt;90\n\n\n0.98\n0.42, 2.84\n&gt;0.9\n0.95\n0.41, 2.75\n&gt;0.9\n\n\n¬†¬†¬†¬†90-&lt;100\n\n\n1.06\n0.45, 3.15\n&gt;0.9\n1.02\n0.43, 3.04\n&gt;0.9\n\n\n¬†¬†¬†¬†100-&lt;110\n\n\n1.39\n0.39, 5.17\n0.6\n1.39\n0.39, 5.18\n0.6\n\n\nBlood_Pressure\n28,828\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†Normal\n\n\n‚Äî\n‚Äî\n\n\n‚Äî\n‚Äî\n\n\n\n\n¬†¬†¬†¬†High-Normal\n\n\n0.97\n0.84, 1.11\n0.6\n0.97\n0.84, 1.11\n0.6\n\n\n¬†¬†¬†¬†Elevated\n\n\n0.98\n0.89, 1.09\n0.8\n0.98\n0.89, 1.09\n0.8\n\n\n¬†¬†¬†¬†Hypertension Grade I\n\n\n1.02\n0.90, 1.16\n0.8\n1.02\n0.90, 1.16\n0.8\n\n\n¬†¬†¬†¬†Hypertension Grade II\n\n\n1.04\n0.79, 1.35\n0.8\n1.04\n0.79, 1.35\n0.8\n\n\n¬†¬†¬†¬†Hypertension (Isolated) Systolic\n\n\n0.97\n0.83, 1.13\n0.7\n0.97\n0.83, 1.13\n0.7\n\n\n¬†¬†¬†¬†Hypertension Grade III\n\n\n0.88\n0.26, 2.19\n0.8\n0.89\n0.27, 2.22\n0.8\n\n\nCholesterol\n30,000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†Low (&lt;120)\n\n\n‚Äî\n‚Äî\n\n\n‚Äî\n‚Äî\n\n\n\n\n¬†¬†¬†¬†Normal (120 to &lt;219)\n\n\n0.91\n0.52, 1.74\n0.8\n1.02\n0.56, 2.10\n&gt;0.9\n\n\n¬†¬†¬†¬†High (‚â•219)\n\n\n0.93\n0.53, 1.79\n0.8\n1.05\n0.58, 2.17\n0.9\n\n\nStress\n30,000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†¬†¬†¬†Very Low (0-2)\n\n\n‚Äî\n‚Äî\n\n\n‚Äî\n‚Äî\n\n\n\n\n¬†¬†¬†¬†Low (2-4)\n\n\n0.87\n0.74, 1.02\n0.090\n0.89\n0.75, 1.05\n0.2\n\n\n¬†¬†¬†¬†Moderate (4-6)\n\n\n0.87\n0.75, 1.02\n0.081\n0.88\n0.76, 1.04\n0.12\n\n\n¬†¬†¬†¬†High (6-8)\n\n\n0.81\n0.69, 0.95\n0.011\n0.82\n0.70, 0.98\n0.023\n\n\n¬†¬†¬†¬†Very High (8-10)\n\n\n0.85\n0.69, 1.04\n0.12\n0.87\n0.71, 1.07\n0.2\n\n\n\n1 OR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\nRegression coefficients\nfinal_mv_reg %&gt;% \n  model_parameters(exponentiate = TRUE) %&gt;% \n  plot() +\n  labs(title = \"Odds Ratio of Heart Attack Occurrence (Multivariate Model)\") +\n  scale_color_manual(values=c(\"#e72222\", \"#8cb8c5\"))\n\n\n\n\n\n\n\n\n\nThe multivariate model reveals two unexpected results. First, the Normal BMI group (18.5 to &lt;25) is associated with a higher risk of heart attack, which may indicate an issue with the reference group‚Äîpossibly using ‚Äúunderweight‚Äù instead of ‚Äúoverweight‚Äù as the baseline. Additionally, reverse causality could be at play, where chronic illnesses lower BMI but increase heart attack risk.\nSecond, high stress appears to lower heart attack risk, which is counter-intuitive. This may stem from survivourship bias, where individuals with heart conditions experience lifestyle adjustments that reduce stress levels. Additionally, measurement error from self-reported stress levels or unadjusted confounders, such as protective behaviors (e.g., exercise in high-stress careers), could influence this result.\nTo address these issues, we might want to check the model‚Äôs reference groups, adjust for comorbidities, and include interaction terms (e.g., stress √ó age).\n\n\nModel Diagnostic\ncheck_model(final_mv_reg)",
    "crumbs": [
      "Exercise 01"
    ]
  },
  {
    "objectID": "take-home/exercise01.html#conclusion",
    "href": "take-home/exercise01.html#conclusion",
    "title": "Exercise 01 - Heart Attack In Japan",
    "section": "4.6 Conclusion",
    "text": "4.6 Conclusion\nThe analysis aimed to explore heart attack risk across demographics and identified that individuals aged 35‚Äì39 have a higher odds ratio. However, when evaluating lifestyle factors, the results were inconsistent. There were significant discrepancies between physical and medical indicators, and the controllable factors model produced counter-intuitive results, such as high stress showing a protective effect. These issues make it difficult to derive clear recommendations for lifestyle adjustments.\nTo address these concerns, it is essential to refine the model by reviewing reference groups to ensure appropriate baselines, such as using ‚Äúnormal BMI‚Äù and ‚Äúlow stress‚Äù as references. Additionally, including interaction terms (e.g., age √ó physical activity, stress √ó BMI) and adjusting for potential confounders, such as smoking and family history, can improve accuracy. A stratified analysis by age should also be performed, focusing on the 35‚Äì39 cohort to detect age-specific patterns.",
    "crumbs": [
      "Exercise 01"
    ]
  },
  {
    "objectID": "take-home/exercise01.html#references-2",
    "href": "take-home/exercise01.html#references-2",
    "title": "Exercise 01 - Heart Attack In Japan",
    "section": "4.7 References",
    "text": "4.7 References\n\nhttps://epirhandbook.com/en/\nhttps://r4va.netlify.app/\nhttps://krassowski.github.io/complex-upset/articles/Examples_R.html\nhttps://clarewest.github.io/blog/post/2020-03-26-upsetr-beyond-the-venn-diagram/\nhttps://www.color-hex.com/color-palette/49506",
    "crumbs": [
      "Exercise 01"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Analytics Journey",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics And Applications.\nChanges"
  },
  {
    "objectID": "hands-on/week07.html",
    "href": "hands-on/week07.html",
    "title": "Week 05 - Visualising and Analysing Time-oriented Data",
    "section": "",
    "text": "Loading packages\npacman::p_load(scales,\n               viridis,\n               lubridate,\n               ggthemes,\n               gridExtra,\n               readxl,\n               knitr,\n               data.table,\n               tidyverse,\n               CGPfunctions,  #for slopegraph\n               ggHoriPlot\n               )\n\n\n\n\n\n\n\n\n\nLoad attack data\nattacks &lt;- read_csv(\"../data/wk07/eventlog.csv\")\nkable(head(attacks))\n\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nWe can see that there are three columns, the timestamp, source_country and timezone.\n\n\nCreating weekday and hour fields\nmake_hr_weekday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts,\n                        tz = tz[1], \n                        quiet = TRUE) # Transforms dates stored as character vectors in year, month, day, hour, minute, second format to POSIXct objects\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n}\n\nwkday_levels &lt;- c('Saturday', 'Friday', 'Thursday', 'Wednesday', 'Tuesday', 'Monday', 'Sunday')\n\n\n\n\nModifying the attack tibble\nattacks_new &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_weekday(.$timestamp,\n                   .$source_country,\n                   .$tz)) %&gt;%\n  ungroup() %&gt;%\n  mutate(wkday = factor(wkday, levels = wkday_levels),  # To keep the order\n         hour = factor(hour, levels = 0:23)\n)\n\nkable(head(attacks_new))\n\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\nLoading the air dataset\nair &lt;- read_excel(\"../data/wk07/arrivals_by_air.xlsx\")\nkable(head(air))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMonth-Year\nRepublic of South Africa\nCanada\nUSA\nBangladesh\nBrunei\nChina\nHong Kong SAR (China)\nIndia\nIndonesia\nJapan\nSouth Korea\nKuwait\nMalaysia\nMyanmar\nPakistan\nPhilippines\nSaudi Arabia\nSri Lanka\nTaiwan\nThailand\nUnited Arab Emirates\nVietnam\nBelgium & Luxembourg\nCIS\nFinland\nFrance\nGermany\nIreland\nItaly\nNetherlands\nSpain\nSwitzerland\nUnited Kingdom\nAustralia\nNew Zealand\n\n\n\n\n2000-01-01\n3291\n5545\n25906\n2883\n3749\n33895\n13692\n19235\n65151\n59288\n21457\n507\n27472\n1177\n2150\n8404\n1312\n3922\n15766\n12048\n1318\n1527\n1434\n2703\n1634\n4752\n12739\n1292\n3544\n4962\n925\n3731\n28986\n34616\n5034\n\n\n2000-02-01\n2357\n6120\n28262\n2469\n3236\n34344\n19870\n18975\n37105\n58188\n19634\n199\n29084\n1161\n2496\n9128\n623\n3988\n24861\n12745\n899\n2269\n1596\n1182\n1297\n6391\n13093\n1200\n2897\n5054\n747\n3980\n35148\n26030\n3938\n\n\n2000-03-01\n4036\n6255\n30439\n2904\n3342\n27053\n17086\n21049\n44205\n74426\n20719\n386\n30504\n1355\n2429\n11691\n1578\n4259\n18767\n16971\n1474\n2034\n1548\n1088\n1220\n5528\n13645\n1368\n2717\n4950\n935\n3576\n36117\n31119\n4668\n\n\n2000-04-01\n4241\n4521\n25378\n2843\n5117\n30464\n22346\n26160\n45480\n49985\n17489\n221\n34478\n1593\n2711\n14141\n705\n6579\n22735\n20397\n1284\n2420\n1592\n1012\n1208\n5544\n13366\n1345\n2512\n4149\n941\n3850\n33792\n34824\n6890\n\n\n2000-05-01\n2841\n3914\n26163\n2793\n4152\n30775\n16357\n35869\n38350\n48937\n19398\n164\n34795\n1397\n2594\n13305\n679\n4625\n18399\n15769\n1042\n1833\n1167\n660\n743\n4225\n10878\n1067\n2205\n3643\n764\n3025\n23377\n33139\n7006\n\n\n2000-06-01\n2776\n3487\n28179\n3146\n5018\n26720\n18133\n31314\n47982\n53798\n17522\n440\n34660\n1715\n2924\n10555\n2749\n4740\n21042\n17217\n1545\n2480\n1170\n712\n982\n4047\n9054\n1363\n2196\n3544\n855\n2580\n21769\n35731\n7634\n\n\n\n\n\n\n\nCreating MM YY columns\nair$month &lt;- factor(month(air$`Month-Year`),\n                    levels=1:12,\n                    labels=month.abb,\n                    ordered=TRUE)\nair$year &lt;- year(ymd(air$`Month-Year`))\nkable(head(air))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMonth-Year\nRepublic of South Africa\nCanada\nUSA\nBangladesh\nBrunei\nChina\nHong Kong SAR (China)\nIndia\nIndonesia\nJapan\nSouth Korea\nKuwait\nMalaysia\nMyanmar\nPakistan\nPhilippines\nSaudi Arabia\nSri Lanka\nTaiwan\nThailand\nUnited Arab Emirates\nVietnam\nBelgium & Luxembourg\nCIS\nFinland\nFrance\nGermany\nIreland\nItaly\nNetherlands\nSpain\nSwitzerland\nUnited Kingdom\nAustralia\nNew Zealand\nmonth\nyear\n\n\n\n\n2000-01-01\n3291\n5545\n25906\n2883\n3749\n33895\n13692\n19235\n65151\n59288\n21457\n507\n27472\n1177\n2150\n8404\n1312\n3922\n15766\n12048\n1318\n1527\n1434\n2703\n1634\n4752\n12739\n1292\n3544\n4962\n925\n3731\n28986\n34616\n5034\nJan\n2000\n\n\n2000-02-01\n2357\n6120\n28262\n2469\n3236\n34344\n19870\n18975\n37105\n58188\n19634\n199\n29084\n1161\n2496\n9128\n623\n3988\n24861\n12745\n899\n2269\n1596\n1182\n1297\n6391\n13093\n1200\n2897\n5054\n747\n3980\n35148\n26030\n3938\nFeb\n2000\n\n\n2000-03-01\n4036\n6255\n30439\n2904\n3342\n27053\n17086\n21049\n44205\n74426\n20719\n386\n30504\n1355\n2429\n11691\n1578\n4259\n18767\n16971\n1474\n2034\n1548\n1088\n1220\n5528\n13645\n1368\n2717\n4950\n935\n3576\n36117\n31119\n4668\nMar\n2000\n\n\n2000-04-01\n4241\n4521\n25378\n2843\n5117\n30464\n22346\n26160\n45480\n49985\n17489\n221\n34478\n1593\n2711\n14141\n705\n6579\n22735\n20397\n1284\n2420\n1592\n1012\n1208\n5544\n13366\n1345\n2512\n4149\n941\n3850\n33792\n34824\n6890\nApr\n2000\n\n\n2000-05-01\n2841\n3914\n26163\n2793\n4152\n30775\n16357\n35869\n38350\n48937\n19398\n164\n34795\n1397\n2594\n13305\n679\n4625\n18399\n15769\n1042\n1833\n1167\n660\n743\n4225\n10878\n1067\n2205\n3643\n764\n3025\n23377\n33139\n7006\nMay\n2000\n\n\n2000-06-01\n2776\n3487\n28179\n3146\n5018\n26720\n18133\n31314\n47982\n53798\n17522\n440\n34660\n1715\n2924\n10555\n2749\n4740\n21042\n17217\n1545\n2480\n1170\n712\n982\n4047\n9054\n1363\n2196\n3544\n855\n2580\n21769\n35731\n7634\nJun\n2000\n\n\n\n\n\n\n\n\n\n\nLoading the rice dataset\nrice &lt;- read_csv(\"../data/wk07/rice.csv\")\nkable(head(rice))\n\n\n\n\n\nCountry\nYear\nYield\nProduction\n\n\n\n\nChina\n1961\n20787\n56217601\n\n\nChina\n1962\n23700\n65675288\n\n\nChina\n1963\n26833\n76439280\n\n\nChina\n1964\n28289\n85853780\n\n\nChina\n1965\n29667\n90705630\n\n\nChina\n1966\n31445\n98403990\n\n\n\n\n\n\n\n\n\n\nLoading the retail price dataset\naverp &lt;- read_csv(\"../data/wk07/AVERP.csv\") %&gt;%\n  mutate(`Date` = dmy(`Date`))\nkable(head(averp))\n\n\n\n\n\nDate\nConsumer Items\nValues\n\n\n\n\n2014-01-01\nWholemeal Bread (Per 400 Gram)\n2.05\n\n\n2014-02-01\nWholemeal Bread (Per 400 Gram)\n2.05\n\n\n2014-03-01\nWholemeal Bread (Per 400 Gram)\n2.04\n\n\n2014-04-01\nWholemeal Bread (Per 400 Gram)\n2.04\n\n\n2014-05-01\nWholemeal Bread (Per 400 Gram)\n2.05\n\n\n2014-06-01\nWholemeal Bread (Per 400 Gram)\n2.05",
    "crumbs": [
      "Week 07"
    ]
  },
  {
    "objectID": "hands-on/week07.html#attack-dataset",
    "href": "hands-on/week07.html#attack-dataset",
    "title": "Week 05 - Visualising and Analysing Time-oriented Data",
    "section": "",
    "text": "Load attack data\nattacks &lt;- read_csv(\"../data/wk07/eventlog.csv\")\nkable(head(attacks))\n\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nWe can see that there are three columns, the timestamp, source_country and timezone.\n\n\nCreating weekday and hour fields\nmake_hr_weekday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts,\n                        tz = tz[1], \n                        quiet = TRUE) # Transforms dates stored as character vectors in year, month, day, hour, minute, second format to POSIXct objects\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n}\n\nwkday_levels &lt;- c('Saturday', 'Friday', 'Thursday', 'Wednesday', 'Tuesday', 'Monday', 'Sunday')\n\n\n\n\nModifying the attack tibble\nattacks_new &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_weekday(.$timestamp,\n                   .$source_country,\n                   .$tz)) %&gt;%\n  ungroup() %&gt;%\n  mutate(wkday = factor(wkday, levels = wkday_levels),  # To keep the order\n         hour = factor(hour, levels = 0:23)\n)\n\nkable(head(attacks_new))\n\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\nLoading the air dataset\nair &lt;- read_excel(\"../data/wk07/arrivals_by_air.xlsx\")\nkable(head(air))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMonth-Year\nRepublic of South Africa\nCanada\nUSA\nBangladesh\nBrunei\nChina\nHong Kong SAR (China)\nIndia\nIndonesia\nJapan\nSouth Korea\nKuwait\nMalaysia\nMyanmar\nPakistan\nPhilippines\nSaudi Arabia\nSri Lanka\nTaiwan\nThailand\nUnited Arab Emirates\nVietnam\nBelgium & Luxembourg\nCIS\nFinland\nFrance\nGermany\nIreland\nItaly\nNetherlands\nSpain\nSwitzerland\nUnited Kingdom\nAustralia\nNew Zealand\n\n\n\n\n2000-01-01\n3291\n5545\n25906\n2883\n3749\n33895\n13692\n19235\n65151\n59288\n21457\n507\n27472\n1177\n2150\n8404\n1312\n3922\n15766\n12048\n1318\n1527\n1434\n2703\n1634\n4752\n12739\n1292\n3544\n4962\n925\n3731\n28986\n34616\n5034\n\n\n2000-02-01\n2357\n6120\n28262\n2469\n3236\n34344\n19870\n18975\n37105\n58188\n19634\n199\n29084\n1161\n2496\n9128\n623\n3988\n24861\n12745\n899\n2269\n1596\n1182\n1297\n6391\n13093\n1200\n2897\n5054\n747\n3980\n35148\n26030\n3938\n\n\n2000-03-01\n4036\n6255\n30439\n2904\n3342\n27053\n17086\n21049\n44205\n74426\n20719\n386\n30504\n1355\n2429\n11691\n1578\n4259\n18767\n16971\n1474\n2034\n1548\n1088\n1220\n5528\n13645\n1368\n2717\n4950\n935\n3576\n36117\n31119\n4668\n\n\n2000-04-01\n4241\n4521\n25378\n2843\n5117\n30464\n22346\n26160\n45480\n49985\n17489\n221\n34478\n1593\n2711\n14141\n705\n6579\n22735\n20397\n1284\n2420\n1592\n1012\n1208\n5544\n13366\n1345\n2512\n4149\n941\n3850\n33792\n34824\n6890\n\n\n2000-05-01\n2841\n3914\n26163\n2793\n4152\n30775\n16357\n35869\n38350\n48937\n19398\n164\n34795\n1397\n2594\n13305\n679\n4625\n18399\n15769\n1042\n1833\n1167\n660\n743\n4225\n10878\n1067\n2205\n3643\n764\n3025\n23377\n33139\n7006\n\n\n2000-06-01\n2776\n3487\n28179\n3146\n5018\n26720\n18133\n31314\n47982\n53798\n17522\n440\n34660\n1715\n2924\n10555\n2749\n4740\n21042\n17217\n1545\n2480\n1170\n712\n982\n4047\n9054\n1363\n2196\n3544\n855\n2580\n21769\n35731\n7634\n\n\n\n\n\n\n\nCreating MM YY columns\nair$month &lt;- factor(month(air$`Month-Year`),\n                    levels=1:12,\n                    labels=month.abb,\n                    ordered=TRUE)\nair$year &lt;- year(ymd(air$`Month-Year`))\nkable(head(air))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMonth-Year\nRepublic of South Africa\nCanada\nUSA\nBangladesh\nBrunei\nChina\nHong Kong SAR (China)\nIndia\nIndonesia\nJapan\nSouth Korea\nKuwait\nMalaysia\nMyanmar\nPakistan\nPhilippines\nSaudi Arabia\nSri Lanka\nTaiwan\nThailand\nUnited Arab Emirates\nVietnam\nBelgium & Luxembourg\nCIS\nFinland\nFrance\nGermany\nIreland\nItaly\nNetherlands\nSpain\nSwitzerland\nUnited Kingdom\nAustralia\nNew Zealand\nmonth\nyear\n\n\n\n\n2000-01-01\n3291\n5545\n25906\n2883\n3749\n33895\n13692\n19235\n65151\n59288\n21457\n507\n27472\n1177\n2150\n8404\n1312\n3922\n15766\n12048\n1318\n1527\n1434\n2703\n1634\n4752\n12739\n1292\n3544\n4962\n925\n3731\n28986\n34616\n5034\nJan\n2000\n\n\n2000-02-01\n2357\n6120\n28262\n2469\n3236\n34344\n19870\n18975\n37105\n58188\n19634\n199\n29084\n1161\n2496\n9128\n623\n3988\n24861\n12745\n899\n2269\n1596\n1182\n1297\n6391\n13093\n1200\n2897\n5054\n747\n3980\n35148\n26030\n3938\nFeb\n2000\n\n\n2000-03-01\n4036\n6255\n30439\n2904\n3342\n27053\n17086\n21049\n44205\n74426\n20719\n386\n30504\n1355\n2429\n11691\n1578\n4259\n18767\n16971\n1474\n2034\n1548\n1088\n1220\n5528\n13645\n1368\n2717\n4950\n935\n3576\n36117\n31119\n4668\nMar\n2000\n\n\n2000-04-01\n4241\n4521\n25378\n2843\n5117\n30464\n22346\n26160\n45480\n49985\n17489\n221\n34478\n1593\n2711\n14141\n705\n6579\n22735\n20397\n1284\n2420\n1592\n1012\n1208\n5544\n13366\n1345\n2512\n4149\n941\n3850\n33792\n34824\n6890\nApr\n2000\n\n\n2000-05-01\n2841\n3914\n26163\n2793\n4152\n30775\n16357\n35869\n38350\n48937\n19398\n164\n34795\n1397\n2594\n13305\n679\n4625\n18399\n15769\n1042\n1833\n1167\n660\n743\n4225\n10878\n1067\n2205\n3643\n764\n3025\n23377\n33139\n7006\nMay\n2000\n\n\n2000-06-01\n2776\n3487\n28179\n3146\n5018\n26720\n18133\n31314\n47982\n53798\n17522\n440\n34660\n1715\n2924\n10555\n2749\n4740\n21042\n17217\n1545\n2480\n1170\n712\n982\n4047\n9054\n1363\n2196\n3544\n855\n2580\n21769\n35731\n7634\nJun\n2000\n\n\n\n\n\n\n\n\n\n\nLoading the rice dataset\nrice &lt;- read_csv(\"../data/wk07/rice.csv\")\nkable(head(rice))\n\n\n\n\n\nCountry\nYear\nYield\nProduction\n\n\n\n\nChina\n1961\n20787\n56217601\n\n\nChina\n1962\n23700\n65675288\n\n\nChina\n1963\n26833\n76439280\n\n\nChina\n1964\n28289\n85853780\n\n\nChina\n1965\n29667\n90705630\n\n\nChina\n1966\n31445\n98403990\n\n\n\n\n\n\n\n\n\n\nLoading the retail price dataset\naverp &lt;- read_csv(\"../data/wk07/AVERP.csv\") %&gt;%\n  mutate(`Date` = dmy(`Date`))\nkable(head(averp))\n\n\n\n\n\nDate\nConsumer Items\nValues\n\n\n\n\n2014-01-01\nWholemeal Bread (Per 400 Gram)\n2.05\n\n\n2014-02-01\nWholemeal Bread (Per 400 Gram)\n2.05\n\n\n2014-03-01\nWholemeal Bread (Per 400 Gram)\n2.04\n\n\n2014-04-01\nWholemeal Bread (Per 400 Gram)\n2.04\n\n\n2014-05-01\nWholemeal Bread (Per 400 Gram)\n2.05\n\n\n2014-06-01\nWholemeal Bread (Per 400 Gram)\n2.05",
    "crumbs": [
      "Week 07"
    ]
  },
  {
    "objectID": "hands-on/week07.html#calendar-heatmap",
    "href": "hands-on/week07.html#calendar-heatmap",
    "title": "Week 05 - Visualising and Analysing Time-oriented Data",
    "section": "2.1 Calendar Heatmap",
    "text": "2.1 Calendar Heatmap\n\n2.1.1 Single Calendar Heatmap\n\nWithout theme_tufte()With theme_tufte()\n\n\n\n\nBuilding the calendar heatmap\ngrouped &lt;- attacks_new %&gt;%\n  count(wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  na.omit()\n\nggplot(data = grouped,\n       aes(x = hour,\n           y = wkday,\n           fill = n)) + \n  geom_tile(color = \"white\",\n            size = 0.1) +\n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                      low = \"sky blue\",\n                      high = \"dark blue\") +\n  labs(x = NULL,\n       y = NULL,\n       title = \"Attacks by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6))\n\n\n\n\n\n\n\n\n\n\n\nLook closely to see that the background of the plot is gone.\n\n\nBuilding the calendar heatmap\ngrouped &lt;- attacks_new %&gt;%\n  count(wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  na.omit()\n\nggplot(data = grouped,\n       aes(x = hour,\n           y = wkday,\n           fill = n)) + \n  geom_tile(color = \"white\",\n            size = 0.1) +\n  theme_tufte(base_family = \"Helvetica\") +\n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                      low = \"sky blue\",\n                      high = \"dark blue\") +\n  labs(x = NULL,\n       y = NULL,\n       title = \"Attacks by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.1.2 Multiple Calendar Heatmaps\n\n\nData Preparation\nattacks_by_country &lt;- attacks_new %&gt;%\n  count(source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks_new %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(source_country, levels = top4)) %&gt;%\n  na.omit()\n\nkable(head(top4_attacks))\n\n\n\n\n\nsource_country\nwkday\nhour\nn\n\n\n\n\nCN\nSaturday\n0\n438\n\n\nCN\nSaturday\n1\n401\n\n\nCN\nSaturday\n2\n358\n\n\nCN\nSaturday\n3\n487\n\n\nCN\nSaturday\n4\n457\n\n\nCN\nSaturday\n5\n429\n\n\n\n\n\n\n\nPlotting multiple calendar heatmaps\nggplot(data = top4_attacks,\n       aes(x = hour,\n           y = wkday,\n           fill = n)) + \n  geom_tile(color = \"white\",\n            size = 0.1) +\n  facet_wrap(~source_country, ncol = 2) +\n  theme_tufte(base_family = \"Helvetica\") +\n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                      low = \"sky blue\",\n                      high = \"dark blue\") +\n  labs(x = NULL,\n       y = NULL,\n       title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6))",
    "crumbs": [
      "Week 07"
    ]
  },
  {
    "objectID": "hands-on/week07.html#cycle-plot",
    "href": "hands-on/week07.html#cycle-plot",
    "title": "Week 05 - Visualising and Analysing Time-oriented Data",
    "section": "2.2 Cycle Plot",
    "text": "2.2 Cycle Plot\n\n\nPlotting the cycle plot\nsubset_air &lt;- air %&gt;%\n  select(`Vietnam`,\n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\nhline.data &lt;- subset_air %&gt;%\n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\nggplot() +\n  geom_line(data = subset_air,\n            aes(x = year,\n                y = `Vietnam`,\n                group = month),\n            colour = \"black\") +\n  geom_hline(aes(yintercept = avgvalue),\n             data = hline.data,\n             linetype = 6,\n             colour = \"red\",\n             size = 0.5) +\n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Vistor arrivals from Vietnam by air, Jan 2010 - Dec 2019\",\n       x = \"\",\n       y = \"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")",
    "crumbs": [
      "Week 07"
    ]
  },
  {
    "objectID": "hands-on/week07.html#slopegraph",
    "href": "hands-on/week07.html#slopegraph",
    "title": "Week 05 - Visualising and Analysing Time-oriented Data",
    "section": "2.3 Slopegraph",
    "text": "2.3 Slopegraph\n\n\nPlotting the slopegraph\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                  Title = \"Rice Yield of Top 11 Asian Countries\",\n                  SubTitle = \"1961 - 1980\",\n                  Caption = \"Modified\")",
    "crumbs": [
      "Week 07"
    ]
  },
  {
    "objectID": "hands-on/week07.html#horizon-graph",
    "href": "hands-on/week07.html#horizon-graph",
    "title": "Week 05 - Visualising and Analysing Time-oriented Data",
    "section": "2.4 Horizon Graph",
    "text": "2.4 Horizon Graph\n\nLinegraphHorizongraph\n\n\n\n\nLinegraph\naverp %&gt;%\n  filter(Date &gt;= \"2018-01-01\") %&gt;%\n  ggplot() +\n  geom_line(aes(x = Date,\n                y = Values,\n                colour = `Consumer Items`)) +\n  labs(title = \"Average Retail Prices of Selected Consumer Items (Jan 2018 to Dec 20222)\",\n       x = \"Average Price\",\n       y = \"\") +\n  theme_gray() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nHorizongraph\naverp %&gt;%\n  filter(Date &gt;= \"2018-01-01\") %&gt;%\n  ggplot() + \n  geom_horizon(aes(x = Date, y=Values), \n               origin = \"midpoint\", \n               horizonscale = 6)+\n  facet_grid(`Consumer Items`~.) +\n  theme_few() +\n  scale_fill_hcl(palette = 'RdBu') +\n  theme(panel.spacing.y=unit(0, \"lines\"), strip.text.y = element_text(\n    size = 5, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n  scale_x_date(expand=c(0,0), date_breaks = \"3 month\", date_labels = \"%b%y\") +\n  ggtitle(\"Average Retail Prices of Selected Consumer Items (Jan 2018 to Dec 20222)\")",
    "crumbs": [
      "Week 07"
    ]
  },
  {
    "objectID": "hands-on/week04.html",
    "href": "hands-on/week04.html",
    "title": "Week 04 - Fundamentals of Visualization Analytics",
    "section": "",
    "text": "The following section was modified according to https://r4va.netlify.app/chap09.\n\n\nLoading packages & data import\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)\n\nexam_data &lt;- read_csv(\"../data/Exam_data.csv\")\n\n\n\n\nWhen to Use Ridgeline Plots:\n\nWhen you have a medium to high number of groups (more than 5), as it saves space.\nIf there is a clear pattern or ranking among groups, making insights easier to spot.\nWhen you want to efficiently visualize distributions without using separate plots.\n\nWhen Not to Use Ridgeline Plots:\n\nIf there are fewer than 5 groups, other distribution plots (e.g., boxplots) may be better.\nWhen groups lack a clear pattern, as overlapping can make the plot messy.\nIf hiding some data due to overlap reduces clarity rather than improving visualization.\n\n\n\n\n\n\n\nTip\n\n\n\nAdjust bin size/bandwidth and order groups logically for better readability.\n\n\n\n\nThe rdocumentation is here.\n\nBinline-20Binline-40Density\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = ENGLISH, \n           y = CLASS,\n           height = after_stat(count))) +\n  geom_ridgeline(stat = \"binline\", \n                 bins = 20,\n                 scale = 0.9,\n                 alpha = 0.8) + \n  scale_x_continuous(\n    name = \"English grades\",\n    limits = c(0, 100),\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL,\n                   expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = ENGLISH, \n           y = CLASS,\n           height = after_stat(count))) +\n  geom_ridgeline(stat = \"binline\", \n                 bins = 40,\n                 scale = 0.9,\n                 alpha = 0.8) + \n  scale_x_continuous(\n    name = \"English grades\",\n    limits = c(0, 100),\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL,\n                   expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = ENGLISH, \n           y = CLASS,\n           height = after_stat(count))) +\n  geom_ridgeline(stat = \"density\",\n                 alpha = 0.8) + \n  scale_x_continuous(\n    name = \"English grades\",\n    limits = c(0, 100),\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL,\n                   expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"gray\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, \n                   expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefaultWith quantile lines\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    # alpha = 0.8,  # This is not allowed\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Score\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, \n                   expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = factor(stat(quantile)))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_d(name = \"Quartiles\") +  # d: discrete\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, \n                   expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTail ProbabilitySpecifying Cut Points\n\n\n\n\nShow the code\nggplot(data = exam_data,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1,\n                       option = \"magma\") +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = exam_data,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile)))) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = RACE,\n           y = ENGLISH,\n           fill = RACE,\n           color = RACE)) +\n  stat_slab(adjust = 0.5,  # Bandwidth for density estimate; &lt; 1 more \"curvature\"\n            justification = -0.2,  # Without this the boxplot will overlap with the slab\n            scale = 0.5) +  # Used this to prevent overlapping with the dots from previous category\n  geom_boxplot(width = .10,\n               outlier.shape = NA,\n               alpha = 0.5) +\n    stat_dots(side = \"left\", \n            justification = 1.1, \n            # binwidth = .5, \n            dotsize = 2) +\n  coord_flip() +\n  theme_classic() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nThe figure above shows a Raincloud Plot. A Raincloud Plot combines a half-density plot (slab) with a boxplot and dot plot, visually resembling a ‚Äúraincloud.‚Äù It enhances traditional boxplots by showing density distribution and identifying multiple modalities (indicating potential subgroup patterns).\nWhen to Use\n\nBest for smaller datasets to avoid overcrowding.\nUseful for visualizing distribution patterns and density clusters.\nHighlights where data points are concentrated, unlike a standard boxplot.\n\n\n\n\n\n\n\nTip\n\n\n\nIf the dataset is large, consider removing the dot plot (‚Äúrain drops‚Äù) to avoid clutter.\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe don‚Äôt need to use half_eye plot and remove the ‚Äúline & eye portion‚Äù, we can just directly use the slab plot. Refer to https://cran.r-project.org/web/packages/ggdist/vignettes/slabinterval.html.",
    "crumbs": [
      "Week 04"
    ]
  },
  {
    "objectID": "hands-on/week04.html#visualizing-distribution-with-ridgeline-plot",
    "href": "hands-on/week04.html#visualizing-distribution-with-ridgeline-plot",
    "title": "Week 04 - Fundamentals of Visualization Analytics",
    "section": "",
    "text": "When to Use Ridgeline Plots:\n\nWhen you have a medium to high number of groups (more than 5), as it saves space.\nIf there is a clear pattern or ranking among groups, making insights easier to spot.\nWhen you want to efficiently visualize distributions without using separate plots.\n\nWhen Not to Use Ridgeline Plots:\n\nIf there are fewer than 5 groups, other distribution plots (e.g., boxplots) may be better.\nWhen groups lack a clear pattern, as overlapping can make the plot messy.\nIf hiding some data due to overlap reduces clarity rather than improving visualization.\n\n\n\n\n\n\n\nTip\n\n\n\nAdjust bin size/bandwidth and order groups logically for better readability.\n\n\n\n\nThe rdocumentation is here.\n\nBinline-20Binline-40Density\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = ENGLISH, \n           y = CLASS,\n           height = after_stat(count))) +\n  geom_ridgeline(stat = \"binline\", \n                 bins = 20,\n                 scale = 0.9,\n                 alpha = 0.8) + \n  scale_x_continuous(\n    name = \"English grades\",\n    limits = c(0, 100),\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL,\n                   expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = ENGLISH, \n           y = CLASS,\n           height = after_stat(count))) +\n  geom_ridgeline(stat = \"binline\", \n                 bins = 40,\n                 scale = 0.9,\n                 alpha = 0.8) + \n  scale_x_continuous(\n    name = \"English grades\",\n    limits = c(0, 100),\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL,\n                   expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = ENGLISH, \n           y = CLASS,\n           height = after_stat(count))) +\n  geom_ridgeline(stat = \"density\",\n                 alpha = 0.8) + \n  scale_x_continuous(\n    name = \"English grades\",\n    limits = c(0, 100),\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL,\n                   expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"gray\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, \n                   expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefaultWith quantile lines\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    # alpha = 0.8,  # This is not allowed\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Score\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, \n                   expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = factor(stat(quantile)))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_d(name = \"Quartiles\") +  # d: discrete\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, \n                   expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTail ProbabilitySpecifying Cut Points\n\n\n\n\nShow the code\nggplot(data = exam_data,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1,\n                       option = \"magma\") +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = exam_data,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile)))) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()",
    "crumbs": [
      "Week 04"
    ]
  },
  {
    "objectID": "hands-on/week04.html#visualizing-distribution-with-raincloud-plot",
    "href": "hands-on/week04.html#visualizing-distribution-with-raincloud-plot",
    "title": "Week 04 - Fundamentals of Visualization Analytics",
    "section": "",
    "text": "Show the code\nggplot(data = exam_data, \n       aes(x = RACE,\n           y = ENGLISH,\n           fill = RACE,\n           color = RACE)) +\n  stat_slab(adjust = 0.5,  # Bandwidth for density estimate; &lt; 1 more \"curvature\"\n            justification = -0.2,  # Without this the boxplot will overlap with the slab\n            scale = 0.5) +  # Used this to prevent overlapping with the dots from previous category\n  geom_boxplot(width = .10,\n               outlier.shape = NA,\n               alpha = 0.5) +\n    stat_dots(side = \"left\", \n            justification = 1.1, \n            # binwidth = .5, \n            dotsize = 2) +\n  coord_flip() +\n  theme_classic() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nThe figure above shows a Raincloud Plot. A Raincloud Plot combines a half-density plot (slab) with a boxplot and dot plot, visually resembling a ‚Äúraincloud.‚Äù It enhances traditional boxplots by showing density distribution and identifying multiple modalities (indicating potential subgroup patterns).\nWhen to Use\n\nBest for smaller datasets to avoid overcrowding.\nUseful for visualizing distribution patterns and density clusters.\nHighlights where data points are concentrated, unlike a standard boxplot.\n\n\n\n\n\n\n\nTip\n\n\n\nIf the dataset is large, consider removing the dot plot (‚Äúrain drops‚Äù) to avoid clutter.\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe don‚Äôt need to use half_eye plot and remove the ‚Äúline & eye portion‚Äù, we can just directly use the slab plot. Refer to https://cran.r-project.org/web/packages/ggdist/vignettes/slabinterval.html.",
    "crumbs": [
      "Week 04"
    ]
  },
  {
    "objectID": "hands-on/week04.html#visual-statistical-analysis---from-the-data",
    "href": "hands-on/week04.html#visual-statistical-analysis---from-the-data",
    "title": "Week 04 - Fundamentals of Visualization Analytics",
    "section": "2.1 Visual Statistical Analysis - From the Data",
    "text": "2.1 Visual Statistical Analysis - From the Data\n\n2.1.1 One-sample test: gghistostats() method\n\n\nShow the code\nset.seed(1234)\n\ngghistostats(\n  data = exam_data,\n  x = ENGLISH,\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\n\n\nIn the example above, the null hypothesis (\\(H_0\\)) is set to 60. When the test type is not specified, it defaults to a parametric Student‚Äôs t-test.\nThe results indicate a statistically significant difference between the observed mean \\(\\hat{\\mu}_{\\text{mean}} = 67.18\\) and the null hypothesis, with a t-statistic of 8.77 and a p-value of \\(1.04 \\times 10^{-16}\\), strongly rejecting \\(H_0\\).\nThe effect size suggests a moderate difference Source.\nAdditionally, a Bayesian analysis with a Cauchy prior confirms strong evidence against \\(H_0(\\log_e (BF_{01}) = -31.45)\\), further supporting the conclusion that the true mean is significantly different from 60.\n\nAdditionally, if we want to do the same analysis separately for another group, for example, gender, we can use grouped_gghistostats() Reference\n\n\nShow the code\nset.seed(1234)\n\ngrouped_gghistostats(\n  data = exam_data,\n  x = ENGLISH,\n  test.value = 60,\n  xlab = \"English scores\",\n  grouping.var = GENDER,\n  type = \"robust\",\n  annotation.args = list(\n    title = \"Distribution of English scores across genders\"\n  ),\n  plotgrid.args = list(nrow = 2)\n)",
    "crumbs": [
      "Week 04"
    ]
  },
  {
    "objectID": "hands-on/week04.html#comparing-distributions-ggbetweenstats",
    "href": "hands-on/week04.html#comparing-distributions-ggbetweenstats",
    "title": "Week 04 - Fundamentals of Visualization Analytics",
    "section": "2.1.2 Comparing distributions: ggbetweenstats()",
    "text": "2.1.2 Comparing distributions: ggbetweenstats()\nThe example above shows individual analysis by gender. But what if we want to compare the average scores of both genders? In this case, we can use ggbetweenstats() to perform different analyses.\n\nMann-Whitney U testOne-way ANOVA\n\n\n\n\nShow the code\nset.seed(1234)\n\nggbetweenstats(\n  data = exam_data,\n  x = GENDER,\n  y = ENGLISH,\n  type = \"np\",  # Non-parametric\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\n\n\nThe females \\((n=170)\\) have a median score of 73.0, while males \\((n = 152)\\) have a median score of 67.0.\nThe Mann-Whitney test \\((W=15627.50,p=0.00117)\\) confirms a statistically significant difference between the two groups, while the rank biserial correlation \\(0.21, CI [0.09, 0.33]\\) suggests a moderate effect size.\n\n\n\n\n\nShow the code\nset.seed(1234)\n\nggbetweenstats(\n  data = exam_data,\n  x = RACE,  # By levels\n  y = ENGLISH,\n  test.value = 60,\n  type = \"p\",  \n  xlab = \"English scores\",\n  mean.ci = TRUE,\n  pairwise.comparisons = TRUE,\n  pairwise.display = \"s\",  # only display the significant diff \n  p.adjust.method = \"fdr\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.1.3 Significant Test of Correlation: ggscatterstats()\n\n\nShow the code\nggscatterstats(\n  data = exam_data,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n\n\n\n\n2.1.4 Significant Test of Association: ggbarstats()\n\n\nShow the code\nexam_data1 &lt;- exam_data %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nggbarstats(exam_data1, \n           x = MATHS_bins, \n           y = GENDER)",
    "crumbs": [
      "Week 04"
    ]
  },
  {
    "objectID": "hands-on/week04.html#visual-statistical-analysis---model-diagnostic",
    "href": "hands-on/week04.html#visual-statistical-analysis---model-diagnostic",
    "title": "Week 04 - Fundamentals of Visualization Analytics",
    "section": "2.2 Visual Statistical Analysis - Model Diagnostic",
    "text": "2.2 Visual Statistical Analysis - Model Diagnostic\n\n\nLoading packages & data import\npacman::p_load(readxl, performance, parameters, see)\n\ncar_resale &lt;- read_xls(\"../data/ToyotaCorolla.xls\", \n                       \"data\")\n\nknitr::kable(head(car_resale), format = 'html')\n\n\n\n\n\nId\nModel\nPrice\nAge_08_04\nMfg_Month\nMfg_Year\nKM\nQuarterly_Tax\nWeight\nGuarantee_Period\nHP_Bin\nCC_bin\nDoors\nGears\nCylinders\nFuel_Type\nColor\nMet_Color\nAutomatic\nMfr_Guarantee\nBOVAG_Guarantee\nABS\nAirbag_1\nAirbag_2\nAirco\nAutomatic_airco\nBoardcomputer\nCD_Player\nCentral_Lock\nPowered_Windows\nPower_Steering\nRadio\nMistlamps\nSport_Model\nBackseat_Divider\nMetallic_Rim\nRadio_cassette\nTow_Bar\n\n\n\n\n81\nTOYOTA Corolla 1.6 5drs 1 4/5-Doors\n18950\n25\n8\n2002\n20019\n100\n1180\n3\n100-120\n1600\n5\n5\n4\nPetrol\nBlue\n1\n1\n0\n0\n1\n1\n1\n1\n1\n0\n1\n1\n1\n1\n0\n0\n0\n0\n0\n0\n0\n\n\n1\nTOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors\n13500\n23\n10\n2002\n46986\n210\n1165\n3\n&lt; 100\n&gt;1600\n3\n5\n4\nDiesel\nBlue\n1\n0\n0\n1\n1\n1\n1\n0\n0\n1\n0\n1\n1\n1\n0\n0\n0\n1\n0\n0\n0\n\n\n2\nTOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors\n13750\n23\n10\n2002\n72937\n210\n1165\n3\n&lt; 100\n&gt;1600\n3\n5\n4\nDiesel\nSilver\n1\n0\n0\n1\n1\n1\n1\n1\n0\n1\n1\n1\n0\n1\n0\n0\n0\n1\n0\n0\n0\n\n\n3\n¬†TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors\n13950\n24\n9\n2002\n41711\n210\n1165\n3\n&lt; 100\n&gt;1600\n3\n5\n4\nDiesel\nBlue\n1\n0\n1\n1\n1\n1\n1\n0\n0\n1\n0\n0\n0\n1\n0\n0\n0\n1\n0\n0\n0\n\n\n4\nTOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors\n14950\n26\n7\n2002\n48000\n210\n1165\n3\n&lt; 100\n&gt;1600\n3\n5\n4\nDiesel\nBlack\n0\n0\n1\n1\n1\n1\n1\n0\n0\n1\n0\n0\n0\n1\n0\n0\n0\n1\n0\n0\n0\n\n\n5\nTOYOTA Corolla 2.0 D4D HATCHB SOL 2/3-Doors\n13750\n30\n3\n2002\n38500\n210\n1170\n3\n&lt; 100\n&gt;1600\n3\n5\n4\nDiesel\nBlack\n0\n0\n1\n1\n1\n1\n1\n1\n0\n1\n0\n1\n1\n1\n0\n1\n0\n1\n0\n0\n0\n\n\n\n\n\n\n\n\n2.2.1 Multiple Regression Model using lm()\n\n\nShow the code\n# Mfg_Year was excluded due to high collinearity with Age_08_04\nmodel &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04                KM            Weight  \n      -2.186e+03        -1.195e+02        -2.406e-02         1.972e+01  \nGuarantee_Period  \n       2.682e+01  \n\n\n\n\n2.2.2 Performing model diagnostics\n\n\nShow the code\n# Suite of model diagnostics\ncheck_model(model)\n\n\n\n\n\n\n\n\n\n\n\n2.2.3 Visualizing model parameters\n\nUsing plot()Using ggcoefstats()\n\n\n\n\nShow the code\nplot(parameters(model))\n\n\n\n\n\n\n\n\n\n\n\nThe scale here looks different because of the intercept term.\n\n\nShow the code\nggcoefstats(model, \n            output = \"plot\"\n            # exclude.intercept = TRUE\n            )",
    "crumbs": [
      "Week 04"
    ]
  },
  {
    "objectID": "hands-on/week04.html#visualizing-uncertainty-of-point-estimates-using-ggplot2",
    "href": "hands-on/week04.html#visualizing-uncertainty-of-point-estimates-using-ggplot2",
    "title": "Week 04 - Fundamentals of Visualization Analytics",
    "section": "3.1 Visualizing uncertainty of point estimates using ggplot2",
    "text": "3.1 Visualizing uncertainty of point estimates using ggplot2\n\n3.1.1 Creating summary statistics\n\n\nShow the code\nmy_sum &lt;- exam_data %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS) \n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))  # computing the standard error\n\nknitr::kable(head(my_sum), format = 'html')  # to display the summary table\n\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n3.1.2 Plotting SE & CI of point estimates\n\nStandard Error BarsConfidence Intervals\n\n\n\n\nShow the code\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x = RACE,\n        ymin = mean - se,\n        ymax = mean + se),\n    width = 0.2,\n    colour = \"black\",\n    alpha = 0.9,\n    linewidth = 0.5\n  ) +\n  geom_point(aes(\n        x=RACE,\n        y=mean\n      ),\n      stat = \"identity\",\n      color = \"red\",\n      size = 1.5,\n      alpha = 1) +\n  ggtitle(\"Standard Error of Mean Maths Score by Race\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(my_sum) +\n  # The changes are here\n  geom_errorbar(\n    aes(x = reorder(RACE, -mean),\n        ymin = mean - 1.96 * se,\n        ymax = mean + 1.96 * se),\n    # And ends here\n    width = 0.2,\n    colour = \"black\",\n    alpha = 0.9,\n    linewidth = 0.5\n  ) +\n  geom_point(aes(\n        x=RACE,\n        y=mean\n      ),\n      stat = \"identity\",\n      color = \"red\",\n      size = 1.5,\n      alpha = 1) +\n  labs(x = \"Maths Score\",\n       title = \"95% Confidence Interval of Mean Maths Score by Race\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.1.3 Visualizing the uncertainty of point estimates with interactive error bars\n\n\nShow the code\nshared_df = SharedData$new(my_sum)\n\npoint_plot &lt;- ggplot(shared_df) +\n  geom_errorbar(aes(\n           x = reorder(RACE, -mean),\n           ymin = mean - 2.58 * se, \n           ymax = mean + 2.58 * se), \n           width = 0.2, \n           colour = \"black\", \n           alpha = 0.9, \n           size = 0.5) +\n         geom_point(aes(\n           x = RACE, \n           y = mean, \n           text = paste(\"Race:\", `RACE`, \n                        \"&lt;br&gt;N:\", `n`,\n                        \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                        \"&lt;br&gt;95% CI:[\", \n                        round((mean-2.58*se), digits = 2), \",\",\n                        round((mean+2.58*se), digits = 2),\"]\")),\n           stat = \"identity\", \n           color = \"red\", \n           size = 1.5, \n           alpha = 1) + \n         xlab(\"Race\") + \n         ylab(\"Average Scores\") + \n         theme_minimal() + \n         theme(axis.text.x = element_text(\n           angle = 45, vjust = 0.5, hjust=1)) +\n         ggtitle(\"99% CI of average /&lt;br&gt;maths scores by race\")\n\nsummary_tab &lt;- DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class = \"compact\", \n                     width = \"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns = c('mean', 'sd', 'se'),\n                     digits = 2)\n\nbscols(widths = c(4,8),\n       ggplotly(point_plot, tooltip = \"text\"), summary_tab)",
    "crumbs": [
      "Week 04"
    ]
  },
  {
    "objectID": "hands-on/week04.html#visualizing-uncertainty-using-ggdist",
    "href": "hands-on/week04.html#visualizing-uncertainty-using-ggdist",
    "title": "Week 04 - Fundamentals of Visualization Analytics",
    "section": "3.2 Visualizing Uncertainty using ggdist",
    "text": "3.2 Visualizing Uncertainty using ggdist\n\n3.2.1 Using stat_pointinterval()\nThe plot has been modified to show the 95 and 99% confidence intervals.\n\n\nShow the code\nexam_data %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = c(0.99, 0.95),\n                     .point = median,\n                     .interval = \"qi\") + \n  labs(\n    title = \"Visualising confidence intervals of mean math score \",\n    subtitle = \"Median Point + Multiple-interval plot (99% and 95% CIs)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n3.2.2 Using stat_gradientinterval() to display the distribution with colour gradients\n\n\nShow the code\nexam_data %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\") + \n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n3.2.3 Bayes Modelling\nI wanted to try out the posterior predictions (for my own learning), so the graph below shows the actual data, the model‚Äôs posterior predictions, and the posterior distributions of the group means. I referenced and modified this from this article, specifically the section on posterior predictions.\n\n\nShow the code\n# Step 1: Fit the Bayesian model\nbayes_model &lt;- brm(MATHS ~ RACE, data = exam_data,\n                   family = student(),  # Robust t-distribution\n                   prior = c(prior(normal(70, 10), class = Intercept)),\n                   iter = 4000, warmup = 1000, chains = 4, cores = 4)\n\n# Step 2: Data manipulation \n# Create a grid of unique RACE values for predictions\ngrid &lt;- exam_data %&gt;%\n  data_grid(RACE)\n# Expected means (posterior predictive mean)\nmeans &lt;- grid %&gt;%\n  add_epred_draws(bayes_model)  # E(X)\n# Predicted values (posterior predictive distribution)\npreds &lt;- grid %&gt;%\n  add_predicted_draws(bayes_model) # Accounts for individual variability\n\n# Step 3: Final visualization\nexam_data %&gt;%\n  ggplot(aes(y = RACE, x = MATHS)) +\n  stat_interval(aes(x = .prediction), data = preds) +  # Prediction intervals\n  stat_pointinterval(aes(x = .epred), data = means, \n                     .width = c(.66, .95), \n                     position = position_nudge(y = -0.3)) +  # Expectation intervals\n  geom_point(alpha = 0.5) +  # Scatter plot of raw observations\n  scale_color_brewer(palette = \"Blues\") +\n  labs(\n    title = \"Bayesian Prediction and Expectation Intervals for Math Scores by Race\",\n    x = \"Math Score\",\n    y = \"Race\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nTo interpret the plot:\n\nThe prediction intervals (shaded bars from preds) show the range where individual math scores are expected to fall, accounting for both model uncertainty and natural variation.\n\nThe expectation intervals (small bars from means) represent the uncertainty around the estimated group means, giving a sense of how precise those estimates are.\n\nThe raw data points (black dots) show the actual observed values, so we can compare predictions to what really happened.",
    "crumbs": [
      "Week 04"
    ]
  },
  {
    "objectID": "hands-on/week04.html#visualizing-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "hands-on/week04.html#visualizing-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Week 04 - Fundamentals of Visualization Analytics",
    "section": "3.3 Visualizing Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "3.3 Visualizing Uncertainty with Hypothetical Outcome Plots (HOPs)\n\n\nInstallation and loading package\n# devtools::install_github(\"wilkelab/ungeviz\")\n\nlibrary(ungeviz)\n\n\n\n3.3.1 Hypothetical Outcome Plots (HOPs)\nAn additional example was created following the official repo.\n\nUsing sampler()Using bootstrapper()\n\n\nFrom what I understand the algorithm samples 25 points from each group, and plots the median of the sampled data.\n\n\nShow the code\nggplot(data = exam_data, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_minimal() + \n  transition_states(.draw, 1, 3)  # Animation is done here, and .draw is the generated column indicating sample draw.\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nbsr &lt;- bootstrapper(20, GENDER)\n\nggplot(data = exam_data, \n       aes(x = MATHS,\n           y = ENGLISH, \n           color = GENDER)) +\n  geom_smooth(method = \"lm\", color = NA) +\n  geom_point(alpha = 0.3) +\n  # `.row` is a generated column providing a unique row number for all rows\n  geom_point(data = bsr, aes(group = .row)) +\n  geom_smooth(data = bsr, method = \"lm\", fullrange = TRUE, se = FALSE) +\n  facet_wrap(~GENDER, scales = \"free_x\") +\n  scale_color_manual(values = c(Female = \"#D55E00\", Male = \"#0072B2\"), guide = \"none\") +\n  theme_minimal() +\n  transition_states(.draw, 1, 1) + \n  enter_fade() + exit_fade()",
    "crumbs": [
      "Week 04"
    ]
  },
  {
    "objectID": "hands-on/week04.html#generating-funnel-plot-with-funnelplotr",
    "href": "hands-on/week04.html#generating-funnel-plot-with-funnelplotr",
    "title": "Week 04 - Fundamentals of Visualization Analytics",
    "section": "4.1 Generating Funnel Plot with FunnelPlotR",
    "text": "4.1 Generating Funnel Plot with FunnelPlotR\nI will only be generating a single funnel plot. How each attribute modifies the plot is already show in the tutorial link above.\n\n\nShow the code\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,  # Event of interest\n  denominator = Positive,\n  group = \"Sub-district\",  # Level of points plotted \n  data_type = \"PR\",  # Proportions Ratio - Event rates (In this case Death Rates)\n  xrange = c(0, 6500), \n  yrange = c(0, 0.05),\n  # label = NA,  # this is to remove the outlier labels\n  title = str_wrap(\"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", width = 100),          \n  x_label = \"Cumulative COVID-19 Positive Cases\",\n  y_label = \"Cumulative Fatality Rate\"\n)\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion.",
    "crumbs": [
      "Week 04"
    ]
  },
  {
    "objectID": "hands-on/week04.html#funnel-plot-with-ggplot2",
    "href": "hands-on/week04.html#funnel-plot-with-ggplot2",
    "title": "Week 04 - Fundamentals of Visualization Analytics",
    "section": "4.2 Funnel Plot with ggplot2",
    "text": "4.2 Funnel Plot with ggplot2\n\n4.2.1 Computing the statistics\n\n\nShow the code\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nw_mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\nnum_seq &lt;- seq(1, max(df$Positive), 1)\nnum_ll95 &lt;- w_mean - 1.96 * sqrt((w_mean*(1-w_mean)) / (num_seq)) \nnum_ul95 &lt;- w_mean + 1.96 * sqrt((w_mean*(1-w_mean)) / (num_seq)) \nnum_ll999 &lt;- w_mean - 3.29 * sqrt((w_mean*(1-w_mean)) / (num_seq)) \nnum_ul999 &lt;- w_mean + 3.29 * sqrt((w_mean*(1-w_mean)) / (num_seq)) \n\ndfCI &lt;- data.frame(num_ll95, num_ul95, num_ll999, \n                   num_ul999, num_seq, w_mean)\n\nknitr::kable(head(dfCI), format = 'html')\n\n\n\n\n\nnum_ll95\nnum_ul95\nnum_ll999\nnum_ul999\nnum_seq\nw_mean\n\n\n\n\n-0.2230353\n0.2529745\n-0.3845386\n0.4144778\n1\n0.0149696\n\n\n-0.1533253\n0.1832645\n-0.2675254\n0.2974645\n2\n0.0149696\n\n\n-0.1224426\n0.1523818\n-0.2156866\n0.2456257\n3\n0.0149696\n\n\n-0.1040328\n0.1339720\n-0.1847845\n0.2147237\n4\n0.0149696\n\n\n-0.0914694\n0.1214086\n-0.1636959\n0.1936351\n5\n0.0149696\n\n\n-0.0821955\n0.1121347\n-0.1481289\n0.1780681\n6\n0.0149696\n\n\n\n\n\n\n\n\n\n4.2.2 Plotting a static funnel plot\n\n\nShow the code\nlinetypes &lt;- c(\"dashed\", \"dashed\", \"solid\", \"solid\")\nys &lt;- c(\"num_ll95\", \"num_ul95\", \"num_ll999\", \"num_ul999\")\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n      geom_point(aes(label = `Sub-district`), alpha = 0.4)\n      \n# Loop over the linetypes and ys to add corresponding lines\nfor (i in seq_along(linetypes)) {\n  p &lt;- p + geom_line(data = dfCI, aes(x = num_seq, y = !!sym(ys[i])), linetype = linetypes[i], size = 0.4, colour = \"grey40\")\n}\n\np &lt;- p + geom_hline(data = dfCI, aes(yintercept = w_mean), size = 0.4, colour = \"grey40\") +\n      coord_cartesian(ylim = c(0, 0.05)) +\n      annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") +\n      annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") +\n      ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n      xlab(\"Cumulative Number of COVID-19 Cases\") + \n      ylab(\"Cumulative Fatality Rate\") +\n      theme_light() +\n      theme(\n        plot.title = element_text(size = 12),\n        legend.position = c(0.91, 0.85), \n        legend.title = element_text(size = 7),\n        legend.text = element_text(size = 7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\")\n      )\np\n\n\n\n\n\n\n\n\n\n\n\n4.2.3 Converting to an interactive funnel plot\n\n\nShow the code\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly",
    "crumbs": [
      "Week 04"
    ]
  },
  {
    "objectID": "hands-on/week03.html",
    "href": "hands-on/week03.html",
    "title": "Week 03 - Interactivity and Animation",
    "section": "",
    "text": "The following content is created by following the tutorial on this chapter. These are the R packages that are needed for plotting interactive graphs.\n\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse)\n\n\n\nImporting data\nexam_data &lt;- read_csv(\"../data/Exam_data.csv\")\n\n\n\n\n\n\n\n\nUsing tooltipCustomizing tooltip contentCustomizing tooltip style\n\n\nThe code chunk below will generate a dotplot that is interactive such that by hovering the mouse pointer on an data point of interest, the student‚Äôs ID will be displayed.\n\n\nShow the code\n# Step 1: Create an interactive version of ggplot2 geom.\np &lt;- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),  # Here's the tooltip\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\n# Step 2: Generate an svg object to be displayed on an html page.\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\n\n\n\nHover over the data point and the tooltip will display the ID and Class of the student, instead of just the student ID in the previous tab.\n\n\nShow the code\n# Step 1: Creating a new column in the dataset to incorporate the tool tip information\nexam_data$tooltip &lt;- c(paste0(\n  \"Name = \", exam_data$ID,\n  \"\\n Class = \", exam_data$CLASS\n))\n\n# Step 2: Create an interactive version of ggplot2 geom.\np &lt;- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip),  # Here's the tooltip\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\n# Step 3: Generate an svg object to be displayed on an html page.\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\n\n\n\nThis changes the tooltip from a black background + white text to a white background + black, bold text.\n\n\nShow the code\n# Step 1: Define tooltip CSS style\ntooltip_css &lt;- \"background-color:white;\nfont-style:bold; color:black;\"\n\n# Step 2: Create an interactive version of ggplot2 geom.\np &lt;- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),  # Here's the tooltip\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\n# Step 3: Generate an svg object to be displayed on an html page.\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618,\n  options = list(  \n    opts_tooltip(\n      css = tooltip_css  # The tooltip css is incorporated here\n    )\n  )\n)\n\n\n\n\n\n\n\n\n\nThe code chunk below is an example of customizing the tooltip to show the 90% confidence interval.\n\n\nShow the code\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data = exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\n\n\n\nHover effectStyling hover effect\n\n\nElements associated with the data_id (i.e CLASS) will be highlighted upon mouse over.\n\n\nShow the code\np &lt;- ggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),   # Here is the data_id          \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)         \n\n\n\n\n\n\n\n\nThe css codes are used to change the highlighting effect.\n\n\nShow the code\np &lt;- ggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  # The elements associated with the data_id\n    opts_hover_inv(css = \"opacity:0.2;\")  # The ones that are not highlighted\n  )                                        \n)            \n\n\n\n\n\n\n\n\n\nThe code chunk below combines what we have learnt so far - the tooltip + hover effect.\n\n\nShow the code\np &lt;- ggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)            \n\n\n\n\n\n\n\n\n\nThe onclick argument of ggiraph provides hotlink interactivity on the web. The web document link with a data object will be displayed on the web browser upon mouse click.\n\n\nShow the code\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)   \n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\n\n\n\nCoordinated multiple views methods has been implemented in the data visualisation below. When a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too. The steps will be annotated in the code chunk.\n\n\nShow the code\n# Step 1: Plot the first figure\np1 &lt;- ggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID,\n        tooltip = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim = c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\n# Step 2: Plot the second figure\np2 &lt;- ggplot(data = exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID,\n        tooltip = ID),        \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim = c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\n# Step 3: Display the svg object. The code argument runs the patchwork function to create the coordinated multiple views.\ngirafe(code = print(p1 + p2),  # print is needed for the plot to display\n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\n\n\n\n\n\n\n\n\nLast week, we learnt to use the ggrepel to prevent overlapping text labels here. However, the plot was still overwhelming.\n\nWith ggrepelUsing hover instead\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = MATHS, \n           y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm, \n              linewidth = 0.5) +  \n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\np &lt;- ggplot(data = exam_data, \n       aes(x = MATHS, \n           y = ENGLISH)) +\n  geom_point_interactive(\n    aes(tooltip = ID)\n  ) +\n  geom_smooth(method = lm, \n              linewidth = 0.5) +  \n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\ngirafe(                                  \n  ggobj = p) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefaultUsing color\n\n\nWith just three lines of code, we can plot a basic interactive plot.\n\nplot_ly(data = exam_data, \n        x = ~MATHS, \n        y = ~ENGLISH)\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n        x = ~MATHS, \n        y = ~ENGLISH,\n        color = ~RACE)\n\n\n\n\n\n\n\n\n\n\n\nTo create an interactive scatterplot, all we need to do is to wrap the figure using ggplotly().\n\n\nShow the code\np &lt;- ggplot(data = exam_data,\n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size = 1) +\n  coord_cartesian(xlim = c(0, 100),\n                  ylim = c(0, 100))\n\nggplotly(p)\n\n\n\n\n\n\n\n\n\nExpand on the code chunk to see the steps needed to create this plot.\n\n\nShow the code\n# Step 1: Using highlight_key function from plotly package to indicate the shared data\n# This creates an object of class crosstalk::SharedData\nd &lt;- highlight_key(exam_data)\n\n# Step 2: Create both the scatterplots\np1 &lt;- ggplot(data = d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data = d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\n# Step 3: Using subplot to place them side-by-side\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\n\n\nOn combining multiple views, refer to this link to learn more.\n\n\n\n\nThe DT::datatable can be used to render the data objects in R as HTML tables. The interactive table can then be combined with the ggplot graphics using crosstalk. The code chunk below is used to implement the coordinated brushing shown.\n\n\nShow the code\n# Step 1: Indicate shared data\nd &lt;- highlight_key(exam_data) \n\n# Step 2: Define the ggplot graphic\np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\n# Step 3: Using the plotly highlight function\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\n# Step 4: Putting HTML elements side by side.\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe visual analytics method of the week is scatterplot with marginal distribution, we will be exploring methods to create this plot. The following code blocks has content that was generated with the help of LLMs.\n\n\nAs we have learnt patchwork here, I will be using patchwork to combine the plots together. The method that will be introduced here will be plot_spacer(), which will creates an empty transparent patch that can be added to push your other plots apart. Reference.\n\n\nShow the code\n# Scatter plot\nscatter_plot &lt;- ggplot(data = exam_data, \n                       aes(x = MATHS, y = ENGLISH)) +\n  geom_point(alpha = 0.8) +\n  theme_minimal() +\n  labs(title = \"Scatter Plot with Marginal Density Plots\",\n       x = \"Maths Score\",\n       y = \"English Score\")\n\n# Marginal density plot for x-axis (MATHS)\ndensity_x &lt;- ggplot(data = exam_data, \n                    aes(x = MATHS)) +\n  geom_density(fill = \"gray\", alpha = 0.6) +\n  theme_minimal() +\n  theme(axis.title.x = element_blank(),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank())\n\n# Marginal density plot for y-axis (ENGLISH)\ndensity_y &lt;- ggplot(data = exam_data, \n                    aes(x = ENGLISH)) +\n  geom_density(fill = \"gray\", alpha = 0.6) +\n  coord_flip() +  # Flip to make it vertical\n  theme_minimal() +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank())\n\n# Combine plots using patchwork\ncombined_plot &lt;- density_x + \n  plot_spacer() +  # Empty space\n  scatter_plot + \n  density_y +\n  plot_layout(ncol = 2, widths = c(4, 1), heights = c(1, 4))\n\n# Display the combined plot\ncombined_plot\n\n\n\n\n\n\n\n\n\n\n\n\nThere‚Äôs another library that helps to add marginal distributions to the X and Y axis of a ggplot scatterplot. As you‚Äôve seen, using patchwork requires a lengthy code. With the ggMarginal() wrapper, we will be able to shorten the code and still get a similar plot. Reference\n\npacman::p_load(ggExtra)\n\n\nDensityHistogramBoxplot\n\n\n\n\nShow the code\n# Step 1: Create scatter plot\nscatter_plot &lt;- ggplot(data = exam_data, \n                       aes(x = MATHS, y = ENGLISH)) +\n  geom_point(alpha = 0.8) +\n  theme_minimal() +\n  labs(title = \"Scatter Plot with Marginal Density Plots\",\n       x = \"Maths Score\",\n       y = \"English Score\")\n\n# Step 2: Add marginal density plots\nggMarginal(scatter_plot,\n           type = \"density\",\n           fill = \"gray\",\n           alpha = 0.6,\n           color = \"black\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Step 1: Create scatter plot\nscatter_plot &lt;- ggplot(data = exam_data, \n                       aes(x = MATHS, y = ENGLISH)) +\n  geom_point(alpha = 0.8) +\n  theme_minimal() +\n  labs(title = \"Scatter Plot with Marginal Density Plots\",\n       x = \"Maths Score\",\n       y = \"English Score\")\n\n# Step 2: Add marginal density plots\nggMarginal(scatter_plot, \n           type = \"histogram\",\n           color = \"black\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Step 1: Create scatter plot\nscatter_plot &lt;- ggplot(data = exam_data, \n                       aes(x = MATHS, y = ENGLISH)) +\n  geom_point(alpha = 0.8) +\n  theme_minimal() +\n  labs(title = \"Scatter Plot with Marginal Density Plots\",\n       x = \"Maths Score\",\n       y = \"English Score\")\n\n# Step 2: Add marginal density plots\nggMarginal(scatter_plot, \n           type =\"boxplot\", \n           color = \"black\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI tried to combine the plotly with ggExtra but because ggMarginal() returns an object of class ‚ÄúggExtraPlot‚Äù, it is not directly compatible with ggplotly(). We will use the patchwork approach instead.\n\n\nShow the code\n# Scatter plot\nscatter_plot &lt;- ggplot(data = exam_data, \n                       aes(x = MATHS, \n                           y = ENGLISH,\n                           text = paste(\"Student\", ID,\n                                        \"&lt;br&gt;Maths: \", MATHS, \n                                        \"&lt;br&gt;English: \", ENGLISH))) +\n  geom_point(alpha = 0.8) +\n  theme_minimal() +\n  labs(title = \"Scatter Plot with Marginal Density Plots\",\n       x = \"Maths Score\",\n       y = \"English Score\")\n\n# Marginal density plot for x-axis (MATHS)\ndensity_x &lt;- ggplot(data = exam_data, \n                    aes(x = MATHS)) +\n  geom_density(fill = \"gray\", alpha = 0.6) +\n  theme_minimal() +\n  theme(axis.title.x = element_blank(),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank())\n\n# Marginal density plot for y-axis (ENGLISH)\ndensity_y &lt;- ggplot(data = exam_data, \n                    aes(x = ENGLISH)) +\n  geom_density(fill = \"gray\", alpha = 0.6) +\n  coord_flip() +  # Flip to make it vertical\n  theme_minimal() +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank())\n\ninteractive_scatter &lt;- ggplotly(scatter_plot, tooltip = \"text\")\n\n# Convert marginal plots to plotly\ninteractive_x_density &lt;- ggplotly(density_x) %&gt;% hide_legend() \ninteractive_y_density &lt;- ggplotly(density_y) %&gt;% hide_legend()\n\n# Step 3: Arrange all plots together using subplot\nfinal_plot &lt;- subplot(\n  interactive_x_density, \n  plot_spacer(),\n  interactive_scatter, \n  interactive_y_density,\n  nrows = 2, heights = c(0.2, 0.8), widths = c(0.8, 0.2),\n  shareX = TRUE, shareY = TRUE\n)\n\nfinal_plot",
    "crumbs": [
      "Week 03"
    ]
  },
  {
    "objectID": "hands-on/week03.html#introduction",
    "href": "hands-on/week03.html#introduction",
    "title": "Week 03 - Interactivity and Animation",
    "section": "",
    "text": "The following content is created by following the tutorial on this chapter. These are the R packages that are needed for plotting interactive graphs.\n\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse)\n\n\n\nImporting data\nexam_data &lt;- read_csv(\"../data/Exam_data.csv\")",
    "crumbs": [
      "Week 03"
    ]
  },
  {
    "objectID": "hands-on/week03.html#interactivity-with-ggiraph",
    "href": "hands-on/week03.html#interactivity-with-ggiraph",
    "title": "Week 03 - Interactivity and Animation",
    "section": "",
    "text": "Using tooltipCustomizing tooltip contentCustomizing tooltip style\n\n\nThe code chunk below will generate a dotplot that is interactive such that by hovering the mouse pointer on an data point of interest, the student‚Äôs ID will be displayed.\n\n\nShow the code\n# Step 1: Create an interactive version of ggplot2 geom.\np &lt;- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),  # Here's the tooltip\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\n# Step 2: Generate an svg object to be displayed on an html page.\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\n\n\n\nHover over the data point and the tooltip will display the ID and Class of the student, instead of just the student ID in the previous tab.\n\n\nShow the code\n# Step 1: Creating a new column in the dataset to incorporate the tool tip information\nexam_data$tooltip &lt;- c(paste0(\n  \"Name = \", exam_data$ID,\n  \"\\n Class = \", exam_data$CLASS\n))\n\n# Step 2: Create an interactive version of ggplot2 geom.\np &lt;- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip),  # Here's the tooltip\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\n# Step 3: Generate an svg object to be displayed on an html page.\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\n\n\n\nThis changes the tooltip from a black background + white text to a white background + black, bold text.\n\n\nShow the code\n# Step 1: Define tooltip CSS style\ntooltip_css &lt;- \"background-color:white;\nfont-style:bold; color:black;\"\n\n# Step 2: Create an interactive version of ggplot2 geom.\np &lt;- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),  # Here's the tooltip\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\n# Step 3: Generate an svg object to be displayed on an html page.\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618,\n  options = list(  \n    opts_tooltip(\n      css = tooltip_css  # The tooltip css is incorporated here\n    )\n  )\n)\n\n\n\n\n\n\n\n\n\nThe code chunk below is an example of customizing the tooltip to show the 90% confidence interval.\n\n\nShow the code\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data = exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\n\n\n\nHover effectStyling hover effect\n\n\nElements associated with the data_id (i.e CLASS) will be highlighted upon mouse over.\n\n\nShow the code\np &lt;- ggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),   # Here is the data_id          \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)         \n\n\n\n\n\n\n\n\nThe css codes are used to change the highlighting effect.\n\n\nShow the code\np &lt;- ggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  # The elements associated with the data_id\n    opts_hover_inv(css = \"opacity:0.2;\")  # The ones that are not highlighted\n  )                                        \n)            \n\n\n\n\n\n\n\n\n\nThe code chunk below combines what we have learnt so far - the tooltip + hover effect.\n\n\nShow the code\np &lt;- ggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)            \n\n\n\n\n\n\n\n\n\nThe onclick argument of ggiraph provides hotlink interactivity on the web. The web document link with a data object will be displayed on the web browser upon mouse click.\n\n\nShow the code\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)   \n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\n\n\n\nCoordinated multiple views methods has been implemented in the data visualisation below. When a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too. The steps will be annotated in the code chunk.\n\n\nShow the code\n# Step 1: Plot the first figure\np1 &lt;- ggplot(data = exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID,\n        tooltip = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim = c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\n# Step 2: Plot the second figure\np2 &lt;- ggplot(data = exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID,\n        tooltip = ID),        \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim = c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\n# Step 3: Display the svg object. The code argument runs the patchwork function to create the coordinated multiple views.\ngirafe(code = print(p1 + p2),  # print is needed for the plot to display\n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\n\n\n\n\n\n\n\n\nLast week, we learnt to use the ggrepel to prevent overlapping text labels here. However, the plot was still overwhelming.\n\nWith ggrepelUsing hover instead\n\n\n\n\nShow the code\nggplot(data = exam_data, \n       aes(x = MATHS, \n           y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = lm, \n              linewidth = 0.5) +  \n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\np &lt;- ggplot(data = exam_data, \n       aes(x = MATHS, \n           y = ENGLISH)) +\n  geom_point_interactive(\n    aes(tooltip = ID)\n  ) +\n  geom_smooth(method = lm, \n              linewidth = 0.5) +  \n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\ngirafe(                                  \n  ggobj = p)",
    "crumbs": [
      "Week 03"
    ]
  },
  {
    "objectID": "hands-on/week03.html#interactivity-with-plotly",
    "href": "hands-on/week03.html#interactivity-with-plotly",
    "title": "Week 03 - Interactivity and Animation",
    "section": "",
    "text": "DefaultUsing color\n\n\nWith just three lines of code, we can plot a basic interactive plot.\n\nplot_ly(data = exam_data, \n        x = ~MATHS, \n        y = ~ENGLISH)\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n        x = ~MATHS, \n        y = ~ENGLISH,\n        color = ~RACE)\n\n\n\n\n\n\n\n\n\n\n\nTo create an interactive scatterplot, all we need to do is to wrap the figure using ggplotly().\n\n\nShow the code\np &lt;- ggplot(data = exam_data,\n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size = 1) +\n  coord_cartesian(xlim = c(0, 100),\n                  ylim = c(0, 100))\n\nggplotly(p)\n\n\n\n\n\n\n\n\n\nExpand on the code chunk to see the steps needed to create this plot.\n\n\nShow the code\n# Step 1: Using highlight_key function from plotly package to indicate the shared data\n# This creates an object of class crosstalk::SharedData\nd &lt;- highlight_key(exam_data)\n\n# Step 2: Create both the scatterplots\np1 &lt;- ggplot(data = d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data = d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\n# Step 3: Using subplot to place them side-by-side\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\n\n\nOn combining multiple views, refer to this link to learn more.",
    "crumbs": [
      "Week 03"
    ]
  },
  {
    "objectID": "hands-on/week03.html#interactivity-with-crosstalk",
    "href": "hands-on/week03.html#interactivity-with-crosstalk",
    "title": "Week 03 - Interactivity and Animation",
    "section": "",
    "text": "The DT::datatable can be used to render the data objects in R as HTML tables. The interactive table can then be combined with the ggplot graphics using crosstalk. The code chunk below is used to implement the coordinated brushing shown.\n\n\nShow the code\n# Step 1: Indicate shared data\nd &lt;- highlight_key(exam_data) \n\n# Step 2: Define the ggplot graphic\np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\n# Step 3: Using the plotly highlight function\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\n# Step 4: Putting HTML elements side by side.\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)",
    "crumbs": [
      "Week 03"
    ]
  },
  {
    "objectID": "hands-on/week03.html#extra-scatterplot-with-marginal-distribution",
    "href": "hands-on/week03.html#extra-scatterplot-with-marginal-distribution",
    "title": "Week 03 - Interactivity and Animation",
    "section": "",
    "text": "The visual analytics method of the week is scatterplot with marginal distribution, we will be exploring methods to create this plot. The following code blocks has content that was generated with the help of LLMs.\n\n\nAs we have learnt patchwork here, I will be using patchwork to combine the plots together. The method that will be introduced here will be plot_spacer(), which will creates an empty transparent patch that can be added to push your other plots apart. Reference.\n\n\nShow the code\n# Scatter plot\nscatter_plot &lt;- ggplot(data = exam_data, \n                       aes(x = MATHS, y = ENGLISH)) +\n  geom_point(alpha = 0.8) +\n  theme_minimal() +\n  labs(title = \"Scatter Plot with Marginal Density Plots\",\n       x = \"Maths Score\",\n       y = \"English Score\")\n\n# Marginal density plot for x-axis (MATHS)\ndensity_x &lt;- ggplot(data = exam_data, \n                    aes(x = MATHS)) +\n  geom_density(fill = \"gray\", alpha = 0.6) +\n  theme_minimal() +\n  theme(axis.title.x = element_blank(),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank())\n\n# Marginal density plot for y-axis (ENGLISH)\ndensity_y &lt;- ggplot(data = exam_data, \n                    aes(x = ENGLISH)) +\n  geom_density(fill = \"gray\", alpha = 0.6) +\n  coord_flip() +  # Flip to make it vertical\n  theme_minimal() +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank())\n\n# Combine plots using patchwork\ncombined_plot &lt;- density_x + \n  plot_spacer() +  # Empty space\n  scatter_plot + \n  density_y +\n  plot_layout(ncol = 2, widths = c(4, 1), heights = c(1, 4))\n\n# Display the combined plot\ncombined_plot\n\n\n\n\n\n\n\n\n\n\n\n\nThere‚Äôs another library that helps to add marginal distributions to the X and Y axis of a ggplot scatterplot. As you‚Äôve seen, using patchwork requires a lengthy code. With the ggMarginal() wrapper, we will be able to shorten the code and still get a similar plot. Reference\n\npacman::p_load(ggExtra)\n\n\nDensityHistogramBoxplot\n\n\n\n\nShow the code\n# Step 1: Create scatter plot\nscatter_plot &lt;- ggplot(data = exam_data, \n                       aes(x = MATHS, y = ENGLISH)) +\n  geom_point(alpha = 0.8) +\n  theme_minimal() +\n  labs(title = \"Scatter Plot with Marginal Density Plots\",\n       x = \"Maths Score\",\n       y = \"English Score\")\n\n# Step 2: Add marginal density plots\nggMarginal(scatter_plot,\n           type = \"density\",\n           fill = \"gray\",\n           alpha = 0.6,\n           color = \"black\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Step 1: Create scatter plot\nscatter_plot &lt;- ggplot(data = exam_data, \n                       aes(x = MATHS, y = ENGLISH)) +\n  geom_point(alpha = 0.8) +\n  theme_minimal() +\n  labs(title = \"Scatter Plot with Marginal Density Plots\",\n       x = \"Maths Score\",\n       y = \"English Score\")\n\n# Step 2: Add marginal density plots\nggMarginal(scatter_plot, \n           type = \"histogram\",\n           color = \"black\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Step 1: Create scatter plot\nscatter_plot &lt;- ggplot(data = exam_data, \n                       aes(x = MATHS, y = ENGLISH)) +\n  geom_point(alpha = 0.8) +\n  theme_minimal() +\n  labs(title = \"Scatter Plot with Marginal Density Plots\",\n       x = \"Maths Score\",\n       y = \"English Score\")\n\n# Step 2: Add marginal density plots\nggMarginal(scatter_plot, \n           type =\"boxplot\", \n           color = \"black\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI tried to combine the plotly with ggExtra but because ggMarginal() returns an object of class ‚ÄúggExtraPlot‚Äù, it is not directly compatible with ggplotly(). We will use the patchwork approach instead.\n\n\nShow the code\n# Scatter plot\nscatter_plot &lt;- ggplot(data = exam_data, \n                       aes(x = MATHS, \n                           y = ENGLISH,\n                           text = paste(\"Student\", ID,\n                                        \"&lt;br&gt;Maths: \", MATHS, \n                                        \"&lt;br&gt;English: \", ENGLISH))) +\n  geom_point(alpha = 0.8) +\n  theme_minimal() +\n  labs(title = \"Scatter Plot with Marginal Density Plots\",\n       x = \"Maths Score\",\n       y = \"English Score\")\n\n# Marginal density plot for x-axis (MATHS)\ndensity_x &lt;- ggplot(data = exam_data, \n                    aes(x = MATHS)) +\n  geom_density(fill = \"gray\", alpha = 0.6) +\n  theme_minimal() +\n  theme(axis.title.x = element_blank(),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank())\n\n# Marginal density plot for y-axis (ENGLISH)\ndensity_y &lt;- ggplot(data = exam_data, \n                    aes(x = ENGLISH)) +\n  geom_density(fill = \"gray\", alpha = 0.6) +\n  coord_flip() +  # Flip to make it vertical\n  theme_minimal() +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank())\n\ninteractive_scatter &lt;- ggplotly(scatter_plot, tooltip = \"text\")\n\n# Convert marginal plots to plotly\ninteractive_x_density &lt;- ggplotly(density_x) %&gt;% hide_legend() \ninteractive_y_density &lt;- ggplotly(density_y) %&gt;% hide_legend()\n\n# Step 3: Arrange all plots together using subplot\nfinal_plot &lt;- subplot(\n  interactive_x_density, \n  plot_spacer(),\n  interactive_scatter, \n  interactive_y_density,\n  nrows = 2, heights = c(0.2, 0.8), widths = c(0.8, 0.2),\n  shareX = TRUE, shareY = TRUE\n)\n\nfinal_plot",
    "crumbs": [
      "Week 03"
    ]
  },
  {
    "objectID": "hands-on/week03.html#introduction-1",
    "href": "hands-on/week03.html#introduction-1",
    "title": "Week 03 - Interactivity and Animation",
    "section": "4.1 Introduction",
    "text": "4.1 Introduction\nThe basic concepts of animation and the terminologies are covered in the chapter here. For me, the two key takeaways are:\n\nWhat We Can Do with Animated Graphics  Animated graphics help create engaging and impactful data visualizations by showing changes over time or across categories. They are built by stitching together multiple frames, much like a flipbook, using tools like gganimate and plotly in R. Additionally, data reshaping (tidyr) and transformation (dplyr) are essential for preparing data for animation. Animation attributes, such as frame duration and easing functions, allow further customization of how the animation flows.\nWhen to Use Animated Graphics  Animated graphics are most effective in presentations or storytelling when visualizing trends or patterns over time. Their ability to guide audience attention makes them more engaging than static visuals. However, they may not be necessary for exploratory data analysis, where static charts might suffice. Always consider whether animation adds value before investing time in creating it.\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\n\nImporting data\n# Step 1: Select the columns to be converted into factor (levels)\ncol &lt;- c(\"Country\", \"Continent\")\n\n# Step 2: Read xls from readxl to import excel worksheet\n# Step 3: Piping the operators together, using mutate_at & mutate for datatype conversion\nglobalPop &lt;- read_xls(\"../data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%  # mutate(across(col, as.factor)) can also be used\n  mutate(Year = as.integer(Year))",
    "crumbs": [
      "Week 03"
    ]
  },
  {
    "objectID": "hands-on/week03.html#animated-data-visualisation-gganimate-methods",
    "href": "hands-on/week03.html#animated-data-visualisation-gganimate-methods",
    "title": "Week 03 - Interactivity and Animation",
    "section": "4.2 Animated Data Visualisation: gganimate methods",
    "text": "4.2 Animated Data Visualisation: gganimate methods\n\nStaticAnimated\n\n\n\n\nShow the code\nggplot(data = globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data = globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +  # Transition through distinct states in time   \n  ease_aes('linear')  # Control of easing of aesthetics",
    "crumbs": [
      "Week 03"
    ]
  },
  {
    "objectID": "hands-on/week03.html#animated-data-visualisation-plotly",
    "href": "hands-on/week03.html#animated-data-visualisation-plotly",
    "title": "Week 03 - Interactivity and Animation",
    "section": "4.3 Animated Data Visualisation: plotly",
    "text": "4.3 Animated Data Visualisation: plotly\n\n4.3.1 Animated bubble plot with ggplotly() method\n\nDefaultRemoving the legend\n\n\n\n\nShow the code\ngg &lt;- ggplot(data = globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +  # The legend is still displayed\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\n\n\n\nThe animated bubble plot above includes a play/pause button and a slider component for controlling the animation.\n\n\nAlthough show.legend = FALSE argument was used in the default plot, the legend still appears.. To overcome this problem, theme(legend.position='none') should be used as shown in the plot and code chunk below.\n\n\nShow the code\ngg &lt;- ggplot(data = globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') +\n  theme(legend.position = 'none')\n\nggplotly(gg)\n\n\n\n\n\n\n\n\n\n\n\n4.3.2 Animated bubble plot with plot_ly() method\n\n\nShow the code\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers') %&gt;%\n  layout(showlegend = FALSE)\nbp",
    "crumbs": [
      "Week 03"
    ]
  }
]